# ä¸­æ–‡æ³¨é‡Šï¼šå¯¼å…¥å¸¸ç”¨åº“å’Œè‡ªå®šä¹‰æ¨¡å—
import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np
import pandas as pd
import matplotlib.ticker as mtick
import os
import warnings
import matplotlib
from Function_ import *
from Class_ import *
import math
import math
from create_dataset import series_to_supervised
from sklearn import preprocessing
import torch
import torch.nn as nn
import torch.optim as optim
#from sklearn.datasets import load_boston
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import scipy.io as scio
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torch.nn.functional as F
from torch import nn
from torchvision import transforms as tfs
import scipy.stats as stats
import seaborn as sns
import pickle
from scipy import ndimage  # æ·»åŠ ç”¨äºæ—¶åºå¹³æ»‘çš„å¯¼å…¥

# å¯¼å…¥æ–°çš„æ•°æ®åŠ è½½å™¨
from data_loader_transformer import TransformerBatteryDataset, create_transformer_dataloader

# å†…å­˜ç›‘æ§å‡½æ•°
def print_gpu_memory():
    """æ‰“å°GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            allocated = torch.cuda.memory_allocated(i) / 1024**3
            cached = torch.cuda.memory_reserved(i) / 1024**3
            total = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   GPU {i}: {allocated:.1f}GB / {cached:.1f}GB / {total:.1f}GB (å·²ç”¨/ç¼“å­˜/æ€»è®¡)")

# GPUè®¾å¤‡é…ç½® - ä½¿ç”¨GPU0å’ŒGPU1è¿›è¡Œæ•°æ®å¹¶è¡Œ
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # ä½¿ç”¨GPU0å’ŒGPU1
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

# æ‰“å°GPUä¿¡æ¯
if torch.cuda.is_available():
    print(f"\nğŸ–¥ï¸ åŒGPUå¹¶è¡Œé…ç½®:")
    print(f"   å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        props = torch.cuda.get_device_properties(i)
        print(f"   GPU {i} ({props.name}): {props.total_memory/1024**3:.1f}GB")
    print(f"   ä¸»GPUè®¾å¤‡: cuda:0")
    print(f"   æ•°æ®å¹¶è¡Œæ¨¡å¼: å¯ç”¨")
else:
    print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUè®­ç»ƒ")

# ä¸­æ–‡æ³¨é‡Šï¼šå¿½ç•¥è­¦å‘Šä¿¡æ¯
warnings.filterwarnings('ignore')

# Linuxç¯å¢ƒå­—ä½“è®¾ç½®
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'Noto Sans CJK SC', 'Liberation Sans']
plt.rcParams['axes.unicode_minus'] = False

# Linuxç¯å¢ƒmatplotlibé…ç½®
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.size'] = 10

#----------------------------------------é‡è¦è¯´æ˜ï¼šä½¿ç”¨é¢„è®¡ç®—çœŸå®å€¼------------------------------
# æ–°ç­–ç•¥ï¼šç›´æ¥ä½¿ç”¨é¢„è®¡ç®—çš„çœŸå®Terminal Voltageå’ŒPack SOCå€¼è¿›è¡Œè®­ç»ƒ
# 
# æ•°æ®æµç¨‹ï¼š
# 1. è¾“å…¥ï¼švin_1å‰5ç»´ + å½“å‰æ—¶åˆ»çœŸå®ç”µå‹ + å½“å‰æ—¶åˆ»çœŸå®SOC (7ç»´)
# 2. è¾“å‡ºï¼šä¸‹ä¸€æ—¶åˆ»çœŸå®ç”µå‹ + ä¸‹ä¸€æ—¶åˆ»çœŸå®SOC (2ç»´)
# 3. æ— éœ€æ•°å€¼è½¬æ¢ï¼Œç›´æ¥é¢„æµ‹ç‰©ç†å€¼
#
# ä¼˜åŠ¿ï¼š
# - é¿å…äº†å¤æ‚çš„æ•°å€¼èŒƒå›´è½¬æ¢
# - ç›´æ¥å­¦ä¹ ç‰©ç†é‡ä¹‹é—´çš„å…³ç³»
# - è®­ç»ƒç›®æ ‡æ˜ç¡®ï¼Œæ”¶æ•›æ›´å¿«

#----------------------------------------Transformeræ¨¡å‹å®šä¹‰------------------------------
class TransformerPredictor(nn.Module):
    """æ—¶åºé¢„æµ‹Transformeræ¨¡å‹ - ç›´æ¥é¢„æµ‹çœŸå®ç‰©ç†å€¼"""
    def __init__(self, input_size=7, d_model=128, nhead=8, num_layers=3, output_size=2):
        super(TransformerPredictor, self).__init__()
        self.input_size = input_size
        self.d_model = d_model
        
        # è¾“å…¥æŠ•å½±å±‚
        self.input_projection = nn.Linear(input_size, d_model)
        
        # ä½ç½®ç¼–ç 
        self.pos_encoding = nn.Parameter(torch.randn(1000, d_model, dtype=torch.float32))
        
        # Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model, 
            nhead=nhead,
            dim_feedforward=d_model*4,
            dropout=0.1,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # è¾“å‡ºå±‚ - ç›´æ¥è¾“å‡ºç‰©ç†å€¼ï¼Œä¸ä½¿ç”¨Sigmoid
        self.output_layer = nn.Sequential(
            nn.Linear(d_model, d_model//2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(d_model//2, output_size)
            # ç§»é™¤Sigmoidï¼Œç›´æ¥è¾“å‡ºç‰©ç†å€¼
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
    
    def forward(self, x):
        # x: [batch, input_size] - 2ç»´è¾“å…¥
        if len(x.shape) == 2:
            # æ·»åŠ åºåˆ—ç»´åº¦ï¼š[batch, input_size] -> [batch, 1, input_size]
            x = x.unsqueeze(1)
        
        batch_size, seq_len, _ = x.shape
        
        # è¾“å…¥æŠ•å½±
        x = self.input_projection(x)  # [batch, seq_len, d_model]
        
        # æ·»åŠ ä½ç½®ç¼–ç 
        pos_enc = self.pos_encoding[:seq_len, :].unsqueeze(0).expand(batch_size, -1, -1)
        x = x + pos_enc
        
        # Transformerç¼–ç 
        transformer_out = self.transformer(x)  # [batch, seq_len, d_model]
        
        # è¾“å‡ºå±‚ï¼ˆä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥ï¼‰
        output = self.output_layer(transformer_out[:, -1, :])  # [batch, output_size]
        
        return output  # [batch, output_size] ç›´æ¥è¿”å›2ç»´

def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("="*60)
    print("ğŸš€ Transformerè®­ç»ƒ - Linuxç¯å¢ƒç‰ˆæœ¬")
    print("="*60)
    
    # Linuxç¯å¢ƒæ£€æŸ¥
    import platform
    print(f"ğŸ–¥ï¸  è¿è¡Œç¯å¢ƒ: {platform.system()} {platform.release()}")
    print(f"ğŸ Pythonç‰ˆæœ¬: {platform.python_version()}")
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"ğŸš€ GPUå¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ”¢ GPUæ•°é‡: {torch.cuda.device_count()}")
    else:
        print("âš ï¸  GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
    
    #----------------------------------------æ•°æ®åŠ è½½------------------------------
    # è®­ç»ƒæ ·æœ¬IDï¼ˆä½¿ç”¨QAS 0-200æ ·æœ¬ï¼‰
    def load_train_samples():
        """ä»Labels.xlsåŠ è½½è®­ç»ƒæ ·æœ¬ID"""
        try:
            import pandas as pd
            labels_path = '/mnt/bz25t/bzhy/zhanglikang/project/QAS/Labels.xls'
            df = pd.read_excel(labels_path)
            
            # æå–0-200èŒƒå›´çš„æ ·æœ¬
            all_samples = df['Num'].tolist()
            train_samples = [i for i in all_samples if 0 <= i <= 200]
            
            print(f"ğŸ“‹ ä»Labels.xlsåŠ è½½è®­ç»ƒæ ·æœ¬:")
            print(f"   è®­ç»ƒæ ·æœ¬èŒƒå›´: 0-200")
            print(f"   å®é™…å¯ç”¨æ ·æœ¬: {len(train_samples)} ä¸ª")
            
            return train_samples
        except Exception as e:
            print(f"âŒ åŠ è½½Labels.xlså¤±è´¥: {e}")
            print("âš ï¸  ä½¿ç”¨é»˜è®¤æ ·æœ¬èŒƒå›´ 0-20")
            return list(range(21))
    
    train_samples = load_train_samples()
    print(f"ğŸ“Š ä½¿ç”¨QASç›®å½•ä¸­çš„{len(train_samples)}ä¸ªæ ·æœ¬")
    
    # è®¾å¤‡é…ç½®
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    if torch.cuda.is_available():
        print(f"ğŸ”§ GPUæ•°é‡: {torch.cuda.device_count()}")
        print(f"ğŸ”§ å½“å‰GPU: {torch.cuda.get_device_name(0)}")
    
    # ä½¿ç”¨æ–°çš„æ•°æ®åŠ è½½å™¨
    print("\nğŸ“¥ åŠ è½½é¢„è®¡ç®—æ•°æ®...")
    try:
        # åˆ›å»ºæ•°æ®é›†
        dataset = TransformerBatteryDataset(data_path='/mnt/bz25t/bzhy/zhanglikang/project/QAS', sample_ids=train_samples)
        
        if len(dataset) == 0:
            print("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•è®­ç»ƒæ•°æ®")
            print("è¯·ç¡®ä¿å·²è¿è¡Œ precompute_targets.py ç”Ÿæˆé¢„è®¡ç®—æ•°æ®")
            return
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(dataset)} ä¸ªè®­ç»ƒæ•°æ®å¯¹")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        BATCH_SIZE = 2000  # ä»1000å¢åŠ åˆ°2000
        train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)
        print(f"ğŸ“¦ æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆï¼Œæ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
        
        # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
        sample_input, sample_target = dataset[0]
        print(f"ğŸ“Š æ•°æ®æ ¼å¼:")
        print(f"   è¾“å…¥ç»´åº¦: {sample_input.shape} (å‰5ç»´vin_1 + ç”µå‹ + SOC)")
        print(f"   ç›®æ ‡ç»´åº¦: {sample_target.shape} (ä¸‹ä¸€æ—¶åˆ»ç”µå‹ + SOC)")
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿å·²è¿è¡Œ precompute_targets.py ç”Ÿæˆé¢„è®¡ç®—æ•°æ®")
        return
    
    #----------------------------------------æ¨¡å‹åˆå§‹åŒ–------------------------------
    # åˆå§‹åŒ–Transformeræ¨¡å‹
    transformer = TransformerPredictor(
        input_size=7,      # vin_1å‰5ç»´ + ç”µå‹ + SOC
        d_model=128,       # æ¨¡å‹ç»´åº¦
        nhead=8,           # æ³¨æ„åŠ›å¤´æ•°
        num_layers=3,      # Transformerå±‚æ•°
        output_size=2      # è¾“å‡ºï¼šç”µå‹ + SOC
    ).to(device).float()
    
    # å¯ç”¨æ•°æ®å¹¶è¡Œ
    if torch.cuda.device_count() > 1:
        transformer = torch.nn.DataParallel(transformer)
        print(f"âœ… å¯ç”¨æ•°æ®å¹¶è¡Œï¼Œä½¿ç”¨ {torch.cuda.device_count()} å¼ GPU")
    else:
        print("âš ï¸  å•GPUæ¨¡å¼")
    
    print(f"ğŸ§  Transformeræ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    print(f"ğŸ“ˆ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in transformer.parameters()):,}")
    
    #----------------------------------------è®­ç»ƒå‚æ•°è®¾ç½®------------------------------
    LR = 1.5e-3            # å­¦ä¹ ç‡ä»1e-3å¢åŠ åˆ°1.5e-3
    EPOCH = 40             # è®­ç»ƒè½®æ•°ä»30å¢åŠ åˆ°40
    lr_decay_freq = 15     # å­¦ä¹ ç‡è¡°å‡é¢‘ç‡ä»10å¢åŠ åˆ°15
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = torch.optim.Adam(transformer.parameters(), lr=LR)
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_decay_freq, gamma=0.9)
    criterion = nn.MSELoss()
    
    print(f"âš™ï¸  è®­ç»ƒå‚æ•°ï¼ˆä¿å®ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰:")
    print(f"   å­¦ä¹ ç‡: {LR} (ä»1e-3å¢åŠ åˆ°1.5e-3)")
    print(f"   è®­ç»ƒè½®æ•°: {EPOCH} (ä»30å¢åŠ åˆ°40)")
    print(f"   æ‰¹æ¬¡å¤§å°: {BATCH_SIZE} (ä»1000å¢åŠ åˆ°2000)")
    print(f"   å­¦ä¹ ç‡è¡°å‡é¢‘ç‡: {lr_decay_freq} (ä»10å¢åŠ åˆ°15)")
    print(f"   é¢„æµ‹æ‰¹æ¬¡å¤§å°: 15000 (ä»10000å¢åŠ åˆ°15000)")
    print(f"   MC-AEæ‰¹æ¬¡å¤§å°: 3000 (ä»2000å¢åŠ åˆ°3000)")
    print(f"   MC-AEè®­ç»ƒè½®æ•°: 250 (ä»300å‡å°‘åˆ°250)")
    print(f"   MC-AEå­¦ä¹ ç‡: 7e-4 (ä»5e-4å¢åŠ åˆ°7e-4)")
    
    #----------------------------------------å¼€å§‹è®­ç»ƒ------------------------------
    print("\n" + "="*60)
    print("ğŸ¯ å¼€å§‹Transformerè®­ç»ƒ")
    print("="*60)
    
    transformer.train()
    train_losses = []
    
    for epoch in range(EPOCH):
        epoch_loss = 0
        batch_count = 0
        
        for batch_input, batch_target in train_loader:
            # æ•°æ®ç§»åˆ°è®¾å¤‡
            batch_input = batch_input.to(device)
            batch_target = batch_target.to(device)
            
            # æ¢¯åº¦æ¸…é›¶
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            pred_output = transformer(batch_input)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(pred_output, batch_target)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
            batch_count += 1
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = epoch_loss / batch_count
        train_losses.append(avg_loss)
        
        # æ‰“å°è®­ç»ƒè¿›åº¦
        if epoch % 5 == 0 or epoch == EPOCH - 1:
            current_lr = optimizer.param_groups[0]['lr']
            print(f'Epoch: {epoch:3d} | Loss: {avg_loss:.6f} | LR: {current_lr:.6f}')
    
    print("\nâœ… Transformerè®­ç»ƒå®Œæˆ!")
    
    #----------------------------------------è®­ç»ƒç»“æœåˆ†æ------------------------------
    print("\n" + "="*60)
    print("ğŸ“Š è®­ç»ƒç»“æœåˆ†æ")
    print("="*60)
    
    # æœ€ç»ˆæŸå¤±
    final_loss = train_losses[-1]
    print(f"ğŸ¯ æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_loss:.6f}")
    
    # æŸå¤±æ”¹å–„
    initial_loss = train_losses[0]
    improvement = (initial_loss - final_loss) / initial_loss * 100
    print(f"ğŸ“ˆ æŸå¤±æ”¹å–„: {improvement:.2f}% (ä» {initial_loss:.6f} åˆ° {final_loss:.6f})")
    
    # è¯„ä¼°æ¨¡å‹æ€§èƒ½
    transformer.eval()
    with torch.no_grad():
        total_samples = 0
        total_loss = 0
        voltage_errors = []
        soc_errors = []
        
        for batch_input, batch_target in train_loader:
            batch_input = batch_input.to(device)
            batch_target = batch_target.to(device)
            
            pred_output = transformer(batch_input)
            
            # è®¡ç®—æ€»æŸå¤±
            loss = criterion(pred_output, batch_target)
            total_loss += loss.item()
            total_samples += batch_input.size(0)
            
            # åˆ†åˆ«è®¡ç®—ç”µå‹å’ŒSOCè¯¯å·®
            voltage_error = torch.abs(pred_output[:, 0] - batch_target[:, 0])
            soc_error = torch.abs(pred_output[:, 1] - batch_target[:, 1])
            
            voltage_errors.extend(voltage_error.cpu().numpy())
            soc_errors.extend(soc_error.cpu().numpy())
        
        avg_test_loss = total_loss / len(train_loader)
        avg_voltage_error = np.mean(voltage_errors)
        avg_soc_error = np.mean(soc_errors)
        
        print(f"ğŸ” æ¨¡å‹è¯„ä¼°ç»“æœ:")
        print(f"   å¹³å‡æµ‹è¯•æŸå¤±: {avg_test_loss:.6f}")
        print(f"   å¹³å‡ç”µå‹è¯¯å·®: {avg_voltage_error:.4f} V")
        print(f"   å¹³å‡SOCè¯¯å·®: {avg_soc_error:.4f}")
        print(f"   ç”µå‹è¯¯å·®æ ‡å‡†å·®: {np.std(voltage_errors):.4f} V")
        print(f"   SOCè¯¯å·®æ ‡å‡†å·®: {np.std(soc_errors):.4f}")
    
    #----------------------------------------ä¿å­˜æ¨¡å‹------------------------------
    print("\n" + "="*60)
    print("ğŸ’¾ ä¿å­˜æ¨¡å‹")
    print("="*60)
    
    # ç¡®ä¿modelsç›®å½•å­˜åœ¨
    if not os.path.exists('models'):
        os.makedirs('models')
    
    # ä¿å­˜Transformeræ¨¡å‹
    model_path = 'models/transformer_model.pth'
    torch.save(transformer.state_dict(), model_path)
    print(f"âœ… Transformeræ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    # ä¿å­˜è®­ç»ƒå†å²
    training_history = {
        'train_losses': train_losses,
        'final_loss': final_loss,
        'avg_voltage_error': avg_voltage_error,
        'avg_soc_error': avg_soc_error,
        'training_samples': train_samples,
        'model_params': {
            'input_size': 7,
            'd_model': 128,
            'nhead': 8,
            'num_layers': 3,
            'output_size': 2
        }
    }
    
    history_path = 'models/transformer_training_history.pkl'
    with open(history_path, 'wb') as f:
        pickle.dump(training_history, f)
    print(f"âœ… è®­ç»ƒå†å²å·²ä¿å­˜: {history_path}")
    
    #----------------------------------------ç»˜åˆ¶è®­ç»ƒæ›²çº¿------------------------------
    print("\nğŸ“ˆ ç»˜åˆ¶è®­ç»ƒæ›²çº¿...")
    
    plt.figure(figsize=(12, 4))
    
    # è®­ç»ƒæŸå¤±æ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, 'b-', linewidth=2)
    plt.title('Transformerè®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14)
    plt.xlabel('è®­ç»ƒè½®æ•°', fontsize=12)
    plt.ylabel('MSEæŸå¤±', fontsize=12)
    plt.grid(True, alpha=0.3)
    plt.yscale('log')  # ä½¿ç”¨å¯¹æ•°åæ ‡
    
    # è¯¯å·®åˆ†å¸ƒ
    plt.subplot(1, 2, 2)
    plt.hist(voltage_errors, bins=50, alpha=0.7, label=f'ç”µå‹è¯¯å·® (å‡å€¼: {avg_voltage_error:.4f}V)', color='red')
    plt.hist(soc_errors, bins=50, alpha=0.7, label=f'SOCè¯¯å·® (å‡å€¼: {avg_soc_error:.4f})', color='blue')
    plt.title('é¢„æµ‹è¯¯å·®åˆ†å¸ƒ', fontsize=14)
    plt.xlabel('ç»å¯¹è¯¯å·®', fontsize=12)
    plt.ylabel('é¢‘æ¬¡', fontsize=12)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plot_path = 'models/transformer_training_results.png'
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    plt.show()
    print(f"âœ… è®­ç»ƒç»“æœå›¾å·²ä¿å­˜: {plot_path}")
    
    #----------------------------------------è®­ç»ƒå®Œæˆæ€»ç»“------------------------------
    print("\n" + "="*60)
    print("ğŸ‰ Transformerè®­ç»ƒå®Œæˆæ€»ç»“")
    print("="*60)
    print("âœ… ä¸»è¦æˆæœ:")
    print("   1. ä½¿ç”¨é¢„è®¡ç®—çš„çœŸå®Terminal Voltageå’ŒPack SOCæ•°æ®")
    print("   2. 7ç»´è¾“å…¥ â†’ 2ç»´ç‰©ç†å€¼è¾“å‡ºï¼Œæ— éœ€æ•°å€¼è½¬æ¢")
    print("   3. ç›´æ¥å­¦ä¹ ç‰©ç†é‡ä¹‹é—´çš„æ—¶åºå…³ç³»")
    print("   4. æ¨¡å‹å’Œè®­ç»ƒå†å²å·²ä¿å­˜åˆ°models/ç›®å½•")
    print("")
    print("ğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
    print(f"   æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_loss:.6f}")
    print(f"   å¹³å‡ç”µå‹é¢„æµ‹è¯¯å·®: {avg_voltage_error:.4f} V")
    print(f"   å¹³å‡SOCé¢„æµ‹è¯¯å·®: {avg_soc_error:.4f}")
    print("")
    print("ğŸ”„ ä¸‹ä¸€æ­¥:")
    print("   1. å¯ä»¥è¿è¡ŒTest_combine.pyè¿›è¡Œæ€§èƒ½å¯¹æ¯”")
    print("   2. æ£€æŸ¥é¢„æµ‹ç»“æœçš„ç‰©ç†åˆç†æ€§")
    print("   3. ä¸BiLSTMåŸºå‡†è¿›è¡Œè¯¦ç»†å¯¹æ¯”")
    
    #----------------------------------------é˜¶æ®µ2: åŠ è½½vin_2å’Œvin_3æ•°æ®ï¼Œè¿›è¡ŒTransformeré¢„æµ‹æ›¿æ¢------------------------
    print("\n" + "="*60)
    print("ğŸ”„ é˜¶æ®µ2: åŠ è½½vin_2å’Œvin_3æ•°æ®ï¼Œè¿›è¡ŒTransformeré¢„æµ‹æ›¿æ¢")
    print("="*60)
    
    # åŠ è½½æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„vin_2å’Œvin_3æ•°æ®
    all_vin1_data = []
    all_vin2_data = []
    all_vin3_data = []
    
    print("ğŸ“¥ åŠ è½½åŸå§‹vin_2å’Œvin_3æ•°æ®...")
    for sample_id in train_samples:
        # åŠ è½½vin_1æ•°æ®ï¼ˆç”¨äºTransformeré¢„æµ‹ï¼‰
        vin1_path = f'/mnt/bz25t/bzhy/zhanglikang/project/QAS/{sample_id}/vin_1.pkl'
        with open(vin1_path, 'rb') as file:
            vin1_data = pickle.load(file)
            if isinstance(vin1_data, torch.Tensor):
                vin1_data = vin1_data.cpu()
            else:
                vin1_data = torch.tensor(vin1_data)
            all_vin1_data.append(vin1_data)
        
        # åŠ è½½vin_2æ•°æ®
        vin2_path = f'/mnt/bz25t/bzhy/zhanglikang/project/QAS/{sample_id}/vin_2.pkl'
        with open(vin2_path, 'rb') as file:
            vin2_data = pickle.load(file)
            if isinstance(vin2_data, torch.Tensor):
                vin2_data = vin2_data.cpu()
            else:
                vin2_data = torch.tensor(vin2_data)
            all_vin2_data.append(vin2_data)
        
        # åŠ è½½vin_3æ•°æ®
        vin3_path = f'/mnt/bz25t/bzhy/zhanglikang/project/QAS/{sample_id}/vin_3.pkl'
        with open(vin3_path, 'rb') as file:
            vin3_data = pickle.load(file)
            if isinstance(vin3_data, torch.Tensor):
                vin3_data = vin3_data.cpu()
            else:
                vin3_data = torch.tensor(vin3_data)
            all_vin3_data.append(vin3_data)
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    combined_vin1 = torch.cat(all_vin1_data, dim=0).float()
    combined_vin2 = torch.cat(all_vin2_data, dim=0).float()
    combined_vin3 = torch.cat(all_vin3_data, dim=0).float()
    
    print(f"ğŸ“Š åˆå¹¶åæ•°æ®å½¢çŠ¶:")
    print(f"   vin_1: {combined_vin1.shape}")
    print(f"   vin_2: {combined_vin2.shape}")
    print(f"   vin_3: {combined_vin3.shape}")
    
    # ä½¿ç”¨Transformerè¿›è¡Œé¢„æµ‹å’Œæ›¿æ¢
    print("\nğŸ”„ ä½¿ç”¨Transformeré¢„æµ‹æ›¿æ¢vin_2[:,0]å’Œvin_3[:,0]...")
    transformer.eval()
    
    # é¢„å…ˆåŠ è½½æ‰€æœ‰targetsæ•°æ®ï¼ˆä¼˜åŒ–I/Oï¼‰
    print("ğŸ“¥ é¢„å…ˆåŠ è½½æ‰€æœ‰targetsæ•°æ®...")
    all_targets = {}
    for sample_id in train_samples:
        targets_path = f'/mnt/bz25t/bzhy/zhanglikang/project/QAS/{sample_id}/targets.pkl'
        with open(targets_path, 'rb') as f:
            all_targets[sample_id] = pickle.load(f)
    print(f"âœ… å·²åŠ è½½ {len(all_targets)} ä¸ªæ ·æœ¬çš„targetsæ•°æ®")
    
    # æ‰¹é‡æ„å»ºTransformerè¾“å…¥æ•°æ®
    print("ğŸ”§ æ‰¹é‡æ„å»ºTransformerè¾“å…¥æ•°æ®...")
    transformer_inputs = torch.zeros(len(combined_vin1), 7, dtype=torch.float32)
    
    # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„èµ·å§‹å’Œç»“æŸç´¢å¼•
    sample_indices = []
    current_idx = 0
    for sample_idx, sample_id in enumerate(train_samples):
        sample_len = len(all_vin1_data[sample_idx])
        sample_indices.append((current_idx, current_idx + sample_len, sample_id))
        current_idx += sample_len
    
    # æ‰¹é‡å¡«å……è¾“å…¥æ•°æ®
    for start_idx, end_idx, sample_id in sample_indices:
        targets = all_targets[sample_id]
        terminal_voltages = np.array(targets['terminal_voltages'])
        pack_socs = np.array(targets['pack_socs'])
        
        # å¡«å……vin_1å‰5ç»´
        transformer_inputs[start_idx:end_idx, 0:5] = combined_vin1[start_idx:end_idx, 0, 0:5]
        # å¡«å……å½“å‰æ—¶åˆ»çœŸå®ç”µå‹
        transformer_inputs[start_idx:end_idx, 5] = torch.tensor(terminal_voltages[:end_idx-start_idx], dtype=torch.float32)
        # å¡«å……å½“å‰æ—¶åˆ»çœŸå®SOC
        transformer_inputs[start_idx:end_idx, 6] = torch.tensor(pack_socs[:end_idx-start_idx], dtype=torch.float32)
    
    print(f"âœ… è¾“å…¥æ•°æ®æ„å»ºå®Œæˆ: {transformer_inputs.shape}")
    
    # æ˜¾ç¤ºGPUå†…å­˜ä½¿ç”¨æƒ…å†µ
    print("ğŸ“Š GPUå†…å­˜ä½¿ç”¨æƒ…å†µ:")
    print_gpu_memory()
    
    # æ‰¹é‡é¢„æµ‹ï¼ˆä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡å¤§å°ï¼‰
    print("ğŸš€ å¼€å§‹æ‰¹é‡é¢„æµ‹...")
    transformer_inputs = transformer_inputs.to(device)
    
    with torch.no_grad():
        # ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡å¤§å°ä»¥æé«˜GPUåˆ©ç”¨ç‡
        batch_size = 15000  # ä»10000å¢åŠ åˆ°15000
        predictions = []
        total_batches = (len(transformer_inputs) + batch_size - 1) // batch_size
        
        for i in range(0, len(transformer_inputs), batch_size):
            batch_idx = i // batch_size + 1
            batch_data = transformer_inputs[i:i+batch_size]
            batch_pred = transformer(batch_data)
            predictions.append(batch_pred.cpu())
            
            # æ˜¾ç¤ºè¿›åº¦
            if batch_idx % 10 == 0 or batch_idx == total_batches:
                print(f"   è¿›åº¦: {batch_idx}/{total_batches} ({batch_idx/total_batches*100:.1f}%)")
        
        transformer_predictions = torch.cat(predictions, dim=0)
    
    print(f"âœ… Transformeré¢„æµ‹å®Œæˆ: {transformer_predictions.shape}")
    
    # æ¸…ç†GPUå†…å­˜
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        print(f"ğŸ§¹ GPUå†…å­˜å·²æ¸…ç†ï¼Œå½“å‰ä½¿ç”¨: {torch.cuda.memory_allocated()/1024**3:.1f}GB")
    
    # æ›¿æ¢vin_2[:,0]å’Œvin_3[:,0]
    vin2_modified = combined_vin2.clone()
    vin3_modified = combined_vin3.clone()
    
    # ç¡®ä¿é•¿åº¦åŒ¹é…
    min_len = min(len(transformer_predictions), len(vin2_modified), len(vin3_modified))
    
    # æ›¿æ¢BiLSTMé¢„æµ‹å€¼ä¸ºTransformeré¢„æµ‹å€¼
    vin2_modified[:min_len, 0] = transformer_predictions[:min_len, 0]  # ç”µå‹é¢„æµ‹
    vin3_modified[:min_len, 0] = transformer_predictions[:min_len, 1]  # SOCé¢„æµ‹
    
    print(f"ğŸ”„ æ›¿æ¢å®Œæˆ:")
    print(f"   åŸå§‹vin_2[:,0]èŒƒå›´: [{combined_vin2[:, 0].min():.4f}, {combined_vin2[:, 0].max():.4f}]")
    print(f"   Transformer vin_2[:,0]èŒƒå›´: [{vin2_modified[:, 0].min():.4f}, {vin2_modified[:, 0].max():.4f}]")
    print(f"   åŸå§‹vin_3[:,0]èŒƒå›´: [{combined_vin3[:, 0].min():.4f}, {combined_vin3[:, 0].max():.4f}]")
    print(f"   Transformer vin_3[:,0]èŒƒå›´: [{vin3_modified[:, 0].min():.4f}, {vin3_modified[:, 0].max():.4f}]")
    
    #----------------------------------------é˜¶æ®µ3: è®­ç»ƒMC-AEå¼‚å¸¸æ£€æµ‹æ¨¡å‹------------------------
    print("\n" + "="*60)
    print("ğŸ§  é˜¶æ®µ3: è®­ç»ƒMC-AEå¼‚å¸¸æ£€æµ‹æ¨¡å‹ï¼ˆä½¿ç”¨Transformerå¢å¼ºæ•°æ®ï¼‰")
    print("="*60)
    
    # å‚è€ƒTrain_BILSTM.pyçš„MC-AEè®­ç»ƒé€»è¾‘
    from Function_ import custom_activation
    
    # å®šä¹‰ç‰¹å¾åˆ‡ç‰‡ç»´åº¦ï¼ˆä¸Train_BILSTM.pyä¸€è‡´ï¼‰
    # vin_2.pkl
    dim_x = 2
    dim_y = 110
    dim_z = 110
    dim_q = 3
    
    # åˆ†å‰²vin_2ç‰¹å¾å¼ é‡
    x_recovered = vin2_modified[:, :dim_x]
    y_recovered = vin2_modified[:, dim_x:dim_x + dim_y]
    z_recovered = vin2_modified[:, dim_x + dim_y: dim_x + dim_y + dim_z]
    q_recovered = vin2_modified[:, dim_x + dim_y + dim_z:]
    
    # vin_3.pkl
    dim_x2 = 2
    dim_y2 = 110
    dim_z2 = 110
    dim_q2 = 4
    
    x_recovered2 = vin3_modified[:, :dim_x2]
    y_recovered2 = vin3_modified[:, dim_x2:dim_x2 + dim_y2]
    z_recovered2 = vin3_modified[:, dim_x2 + dim_y2: dim_x2 + dim_y2 + dim_z2]
    q_recovered2 = vin3_modified[:, dim_x2 + dim_y2 + dim_z2:]
    
    print(f"ğŸ“Š MC-AEè®­ç»ƒæ•°æ®å‡†å¤‡:")
    print(f"   vin_2ç‰¹å¾: x{x_recovered.shape}, y{y_recovered.shape}, z{z_recovered.shape}, q{q_recovered.shape}")
    print(f"   vin_3ç‰¹å¾: x{x_recovered2.shape}, y{y_recovered2.shape}, z{z_recovered2.shape}, q{q_recovered2.shape}")
    
    # MC-AEè®­ç»ƒå‚æ•°ï¼ˆä¿å®ˆä¼˜åŒ–ï¼‰
    EPOCH_MCAE = 250       # ä»300å‡å°‘åˆ°250
    LR_MCAE = 7e-4         # ä»5e-4å¢åŠ åˆ°7e-4
    BATCHSIZE_MCAE = 3000  # ä»2000å¢åŠ åˆ°3000
    
    # è‡ªå®šä¹‰å¤šè¾“å…¥æ•°æ®é›†ç±»
    class MCDataset(Dataset):
        def __init__(self, x, y, z, q):
            self.x = x.to(torch.double)
            self.y = y.to(torch.double)
            self.z = z.to(torch.double)
            self.q = q.to(torch.double)
        def __len__(self):
            return len(self.x)
        def __getitem__(self, idx):
            return self.x[idx], self.y[idx], self.z[idx], self.q[idx]
    
    # ç¬¬ä¸€ç»„ç‰¹å¾ï¼ˆvin_2ï¼‰çš„MC-AEè®­ç»ƒ
    print("\nğŸ”§ è®­ç»ƒç¬¬ä¸€ç»„MC-AEæ¨¡å‹ï¼ˆvin_2ï¼‰...")
    train_loader_u = DataLoader(MCDataset(x_recovered, y_recovered, z_recovered, q_recovered), 
                               batch_size=BATCHSIZE_MCAE, shuffle=False)
    
    net = CombinedAE(input_size=2, encode2_input_size=3, output_size=110, 
                    activation_fn=custom_activation, use_dx_in_forward=True).to(device)
    
    optimizer_mcae = torch.optim.Adam(net.parameters(), lr=LR_MCAE)
    loss_f = nn.MSELoss()
    
    # è®°å½•è®­ç»ƒæŸå¤±
    train_losses_mcae1 = []
    
    for epoch in range(EPOCH_MCAE):
        total_loss = 0
        num_batches = 0
        for iteration, (x, y, z, q) in enumerate(train_loader_u):
            x = x.to(device)
            y = y.to(device)
            z = z.to(device)
            q = q.to(device)
            net = net.double()
            recon_im, recon_p = net(x, z, q)
            loss_u = loss_f(y, recon_im)
            total_loss += loss_u.item()
            num_batches += 1
            optimizer_mcae.zero_grad()
            loss_u.backward()
            optimizer_mcae.step()
        avg_loss = total_loss / num_batches
        train_losses_mcae1.append(avg_loss)
        if epoch % 50 == 0:
            print(f'MC-AE1 Epoch: {epoch:3d} | Average Loss: {avg_loss:.6f}')
    
    # è·å–ç¬¬ä¸€ç»„é‡æ„è¯¯å·®
    train_loader2 = DataLoader(MCDataset(x_recovered, y_recovered, z_recovered, q_recovered), 
                              batch_size=len(x_recovered), shuffle=False)
    for iteration, (x, y, z, q) in enumerate(train_loader2):
        x = x.to(device)
        y = y.to(device)
        z = z.to(device)
        q = q.to(device)
        net = net.double()
        recon_imtest, recon = net(x, z, q)
    
    AA = recon_imtest.cpu().detach().numpy()
    yTrainU = y_recovered.cpu().detach().numpy()
    ERRORU = AA - yTrainU
    
    # ç¬¬äºŒç»„ç‰¹å¾ï¼ˆvin_3ï¼‰çš„MC-AEè®­ç»ƒ
    print("\nğŸ”§ è®­ç»ƒç¬¬äºŒç»„MC-AEæ¨¡å‹ï¼ˆvin_3ï¼‰...")
    train_loader_soc = DataLoader(MCDataset(x_recovered2, y_recovered2, z_recovered2, q_recovered2), 
                                 batch_size=BATCHSIZE_MCAE, shuffle=False)
    
    netx = CombinedAE(input_size=2, encode2_input_size=4, output_size=110, 
                     activation_fn=torch.sigmoid, use_dx_in_forward=True).to(device)
    
    optimizer_mcae2 = torch.optim.Adam(netx.parameters(), lr=LR_MCAE)
    
    # è®°å½•è®­ç»ƒæŸå¤±
    train_losses_mcae2 = []
    
    for epoch in range(EPOCH_MCAE):
        total_loss = 0
        num_batches = 0
        for iteration, (x, y, z, q) in enumerate(train_loader_soc):
            x = x.to(device)
            y = y.to(device)
            z = z.to(device)
            q = q.to(device)
            netx = netx.double()
            recon_im, z = netx(x, z, q)
            loss_x = loss_f(y, recon_im)
            total_loss += loss_x.item()
            num_batches += 1
            optimizer_mcae2.zero_grad()
            loss_x.backward()
            optimizer_mcae2.step()
        avg_loss = total_loss / num_batches
        train_losses_mcae2.append(avg_loss)
        if epoch % 50 == 0:
            print(f'MC-AE2 Epoch: {epoch:3d} | Average Loss: {avg_loss:.6f}')
    
    # è·å–ç¬¬äºŒç»„é‡æ„è¯¯å·®
    train_loaderx2 = DataLoader(MCDataset(x_recovered2, y_recovered2, z_recovered2, q_recovered2), 
                               batch_size=len(x_recovered2), shuffle=False)
    for iteration, (x, y, z, q) in enumerate(train_loaderx2):
        x = x.to(device)
        y = y.to(device)
        z = z.to(device)
        q = q.to(device)
        netx = netx.double()
        recon_imtestx, z = netx(x, z, q)
    
    BB = recon_imtestx.cpu().detach().numpy()
    yTrainX = y_recovered2.cpu().detach().numpy()
    ERRORX = BB - yTrainX
    
    print("âœ… MC-AEè®­ç»ƒå®Œæˆ!")
    
    #----------------------------------------MC-AEè®­ç»ƒç»“æœå¯è§†åŒ–------------------------
    print("\nğŸ“ˆ ç»˜åˆ¶MC-AEè®­ç»ƒç»“æœ...")
    
    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # å­å›¾1: MC-AE1è®­ç»ƒæŸå¤±æ›²çº¿
    ax1 = axes[0, 0]
    epochs = range(1, len(train_losses_mcae1) + 1)
    ax1.plot(epochs, train_losses_mcae1, 'b-', linewidth=2, label='MC-AE1 Training Loss')
    ax1.set_xlabel('è®­ç»ƒè½®æ•°')
    ax1.set_ylabel('MSEæŸå¤±')
    ax1.set_title('MC-AE1è®­ç»ƒæŸå¤±æ›²çº¿')
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    ax1.set_yscale('log')
    
    # å­å›¾2: MC-AE2è®­ç»ƒæŸå¤±æ›²çº¿ 
    ax2 = axes[0, 1]
    ax2.plot(epochs, train_losses_mcae2, 'r-', linewidth=2, label='MC-AE2 Training Loss')
    ax2.set_xlabel('è®­ç»ƒè½®æ•°')
    ax2.set_ylabel('MSEæŸå¤±')
    ax2.set_title('MC-AE2è®­ç»ƒæŸå¤±æ›²çº¿')
    ax2.grid(True, alpha=0.3)
    ax2.legend()
    ax2.set_yscale('log')
    
    # å­å›¾3: MC-AE1é‡æ„è¯¯å·®åˆ†å¸ƒ
    ax3 = axes[1, 0]
    reconstruction_errors_1 = ERRORU.flatten()
    ax3.hist(np.abs(reconstruction_errors_1), bins=50, alpha=0.7, color='blue', 
             label=f'MC-AE1é‡æ„è¯¯å·® (å‡å€¼: {np.mean(np.abs(reconstruction_errors_1)):.4f})')
    ax3.set_xlabel('ç»å¯¹é‡æ„è¯¯å·®')
    ax3.set_ylabel('é¢‘æ•°')
    ax3.set_title('MC-AE1é‡æ„è¯¯å·®åˆ†å¸ƒ')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # å­å›¾4: MC-AE2é‡æ„è¯¯å·®åˆ†å¸ƒ
    ax4 = axes[1, 1]
    reconstruction_errors_2 = ERRORX.flatten()
    ax4.hist(np.abs(reconstruction_errors_2), bins=50, alpha=0.7, color='red',
             label=f'MC-AE2é‡æ„è¯¯å·® (å‡å€¼: {np.mean(np.abs(reconstruction_errors_2)):.4f})')
    ax4.set_xlabel('ç»å¯¹é‡æ„è¯¯å·®')
    ax4.set_ylabel('é¢‘æ•°')
    ax4.set_title('MC-AE2é‡æ„è¯¯å·®åˆ†å¸ƒ')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plot_path = f'models/transformer_mcae_training_results.png'
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… MC-AEè®­ç»ƒç»“æœå›¾å·²ä¿å­˜: {plot_path}")
    
    #----------------------------------------é˜¶æ®µ4: PCAåˆ†æå’Œä¿å­˜æ¨¡å‹------------------------
    print("\n" + "="*60)
    print("ğŸ“Š é˜¶æ®µ4: PCAåˆ†æï¼Œä¿å­˜æ¨¡å‹å’Œå‚æ•°")
    print("="*60)
    
    # è¯Šæ–­ç‰¹å¾æå–ä¸PCAåˆ†æ
    from Function_ import DiagnosisFeature, PCA
    
    print("ğŸ” æå–è¯Šæ–­ç‰¹å¾...")
    df_data = DiagnosisFeature(ERRORU, ERRORX)
    print(f"   è¯Šæ–­ç‰¹å¾æ•°æ®å½¢çŠ¶: {df_data.shape}")
    
    print("ğŸ” è¿›è¡ŒPCAåˆ†æ...")
    v_I, v, v_ratio, p_k, data_mean, data_std, T_95_limit, T_99_limit, SPE_95_limit, SPE_99_limit, P, k, P_t, X, data_nor = PCA(df_data, 0.95, 0.95)
    
    print(f"âœ… PCAåˆ†æå®Œæˆ:")
    print(f"   ä¸»æˆåˆ†æ•°é‡: {k}")
    print(f"   è§£é‡Šæ–¹å·®æ¯”: {v_ratio}")
    print(f"   TÂ²æ§åˆ¶é™: 95%={T_95_limit:.4f}, 99%={T_99_limit:.4f}")
    print(f"   SPEæ§åˆ¶é™: 95%={SPE_95_limit:.4f}, 99%={SPE_99_limit:.4f}")
    
    # ä¿å­˜æ‰€æœ‰æ¨¡å‹å’Œåˆ†æç»“æœ
    print("\nğŸ’¾ ä¿å­˜Transformerå¢å¼ºè®­ç»ƒç»“æœ...")
    model_suffix = "_transformer"
    
    # 1. ä¿å­˜Transformeræ¨¡å‹ï¼ˆå·²ä¿å­˜ï¼‰
    
    # 2. ä¿å­˜MC-AEæ¨¡å‹
    torch.save(net.state_dict(), f'models/net_model{model_suffix}.pth')
    torch.save(netx.state_dict(), f'models/netx_model{model_suffix}.pth')
    print(f"âœ… MC-AEæ¨¡å‹å·²ä¿å­˜: models/net_model{model_suffix}.pth, models/netx_model{model_suffix}.pth")
    
    # 3. ä¿å­˜è¯Šæ–­ç‰¹å¾
    df_data.to_excel(f'models/diagnosis_feature{model_suffix}.xlsx', index=False)
    df_data.to_csv(f'models/diagnosis_feature{model_suffix}.csv', index=False)
    print(f"âœ… è¯Šæ–­ç‰¹å¾å·²ä¿å­˜: models/diagnosis_feature{model_suffix}.xlsx/csv")
    
    # 4. ä¿å­˜PCAåˆ†æç»“æœ
    np.save(f'models/v_I{model_suffix}.npy', v_I)
    np.save(f'models/v{model_suffix}.npy', v)
    np.save(f'models/v_ratio{model_suffix}.npy', v_ratio)
    np.save(f'models/p_k{model_suffix}.npy', p_k)
    np.save(f'models/data_mean{model_suffix}.npy', data_mean)
    np.save(f'models/data_std{model_suffix}.npy', data_std)
    np.save(f'models/T_95_limit{model_suffix}.npy', T_95_limit)
    np.save(f'models/T_99_limit{model_suffix}.npy', T_99_limit)
    np.save(f'models/SPE_95_limit{model_suffix}.npy', SPE_95_limit)
    np.save(f'models/SPE_99_limit{model_suffix}.npy', SPE_99_limit)
    np.save(f'models/P{model_suffix}.npy', P)
    np.save(f'models/k{model_suffix}.npy', k)
    np.save(f'models/P_t{model_suffix}.npy', P_t)
    np.save(f'models/X{model_suffix}.npy', X)
    np.save(f'models/data_nor{model_suffix}.npy', data_nor)
    print(f"âœ… PCAåˆ†æç»“æœå·²ä¿å­˜: models/*{model_suffix}.npy")
    
    # 5. ä¿å­˜MC-AEè®­ç»ƒå†å²
    mcae_training_history = {
        'mcae1_losses': train_losses_mcae1,
        'mcae2_losses': train_losses_mcae2,
        'final_mcae1_loss': train_losses_mcae1[-1],
        'final_mcae2_loss': train_losses_mcae2[-1],
        'mcae1_reconstruction_error_mean': np.mean(np.abs(ERRORU)),
        'mcae1_reconstruction_error_std': np.std(np.abs(ERRORU)),
        'mcae2_reconstruction_error_mean': np.mean(np.abs(ERRORX)),
        'mcae2_reconstruction_error_std': np.std(np.abs(ERRORX)),
        'training_samples': len(train_samples),
        'epochs': EPOCH_MCAE,
        'learning_rate': LR_MCAE,
        'batch_size': BATCHSIZE_MCAE
    }
    
    with open(f'models/transformer_mcae_training_history.pkl', 'wb') as f:
        pickle.dump(mcae_training_history, f)
    print(f"âœ… MC-AEè®­ç»ƒå†å²å·²ä¿å­˜: models/transformer_mcae_training_history.pkl")
    
    #----------------------------------------æœ€ç»ˆè®­ç»ƒå®Œæˆæ€»ç»“------------------------------
    print("\n" + "="*60)
    print("ğŸ‰ Transformerå®Œæ•´è®­ç»ƒæµç¨‹å®Œæˆï¼")
    print("="*60)
    print("âœ… è®­ç»ƒæµç¨‹æ€»ç»“:")
    print("   1. âœ… è®­ç»ƒTransformeræ—¶åºé¢„æµ‹æ¨¡å‹")
    print("   2. âœ… ä½¿ç”¨Transformeré¢„æµ‹æ›¿æ¢vin_2[:,0]å’Œvin_3[:,0]")
    print("   3. âœ… ä¿æŒPack Modelingè¾“å‡ºvin_2[:,1]å’Œvin_3[:,1]ä¸å˜")
    print("   4. âœ… MC-AEä½¿ç”¨Transformerå¢å¼ºæ•°æ®è¿›è¡Œè®­ç»ƒ")
    print("   5. âœ… å®Œæ•´çš„PCAåˆ†æå’Œè¯Šæ–­ç‰¹å¾æå–")
    print("   6. âœ… æ‰€æœ‰æ¨¡å‹å’Œç»“æœæ–‡ä»¶æ·»åŠ '_transformer'åç¼€")
    print("   7. âœ… MC-AEè®­ç»ƒç»“æœå¯è§†åŒ–å›¾è¡¨")
    print("")
    print("ğŸ“Š å…³é”®æ”¹è¿›:")
    print("   - Transformeræ›¿æ¢BiLSTMè¿›è¡Œæ—¶åºé¢„æµ‹")
    print("   - ç›´æ¥ä½¿ç”¨çœŸå®ç‰©ç†å€¼è®­ç»ƒï¼Œæ— å¤æ‚è½¬æ¢")
    print("   - ä¿æŒä¸åŸå§‹MC-AEè®­ç»ƒæµç¨‹å®Œå…¨å…¼å®¹")
    print("   - ä¾¿äºä¸BiLSTMåŸºå‡†è¿›è¡Œå…¬å¹³å¯¹æ¯”")
    print("   - ä¿å®ˆä¼˜åŒ–ï¼šæ‰¹æ¬¡å¤§å°å¢åŠ 50-100%ï¼Œå­¦ä¹ ç‡æå‡50%")
    print("   - åŒGPUæ•°æ®å¹¶è¡Œï¼Œå……åˆ†åˆ©ç”¨A100æ˜¾å­˜")
    print("")
    print("ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
    print(f"   Transformerç”µå‹é¢„æµ‹è¯¯å·®: {avg_voltage_error:.4f} V")
    print(f"   Transformer SOCé¢„æµ‹è¯¯å·®: {avg_soc_error:.4f}")
    print(f"   PCAä¸»æˆåˆ†æ•°é‡: {k}")
    print("")
    print("ğŸ”„ ä¸‹ä¸€æ­¥å¯ä»¥:")
    print("   1. è¿è¡ŒTest_combine.pyè¿›è¡Œè¯¦ç»†æ€§èƒ½å¯¹æ¯”")
    print("   2. åˆ†æTransformer vs BiLSTMçš„æ•…éšœæ£€æµ‹æ•ˆæœ")
    print("   3. æ£€æŸ¥ä¸‰çª—å£æ£€æµ‹æœºåˆ¶çš„æ”¹è¿›æ•ˆæœ")

if __name__ == "__main__":
    main() 