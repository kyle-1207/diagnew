#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿å­˜Transformerè®­ç»ƒç»“æœçš„è„šæœ¬
ç”¨äºåœ¨è®­ç»ƒä¸­æ–­åä¿å­˜å‰©ä½™çš„æ•°æ®
"""

import numpy as np
import pandas as pd
import pickle
import os

def save_transformer_results():
    """ä¿å­˜Transformerè®­ç»ƒç»“æœ"""
    print("="*60)
    print("ğŸ’¾ ä¿å­˜Transformerè®­ç»ƒç»“æœ")
    print("="*60)
    
    # æ£€æŸ¥modelsç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists('models'):
        os.makedirs('models')
        print("âœ… åˆ›å»ºmodelsç›®å½•")
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦åœ¨å†…å­˜ä¸­
    try:
        # è¿™äº›å˜é‡åº”è¯¥åœ¨è®­ç»ƒè„šæœ¬çš„å†…å­˜ä¸­
        print("ğŸ” æ£€æŸ¥æ•°æ®çŠ¶æ€...")
        
        # æ£€æŸ¥å…³é”®å˜é‡æ˜¯å¦å­˜åœ¨
        if 'ERRORU' in globals():
            print(f"âœ… ERRORU shape: {ERRORU.shape}")
        else:
            print("âŒ ERRORU ä¸åœ¨å†…å­˜ä¸­")
            return
            
        if 'ERRORX' in globals():
            print(f"âœ… ERRORX shape: {ERRORX.shape}")
        else:
            print("âŒ ERRORX ä¸åœ¨å†…å­˜ä¸­")
            return
            
        if 'df_data' in globals():
            print(f"âœ… df_data shape: {df_data.shape}")
        else:
            print("âŒ df_data ä¸åœ¨å†…å­˜ä¸­")
            return
        
        # ä¿å­˜è¯Šæ–­ç‰¹å¾ï¼ˆåˆ†å—ä¿å­˜ï¼Œé¿å…Excelæ–‡ä»¶è¿‡å¤§ï¼‰
        model_suffix = "_transformer"
        print(f"\nğŸ’¾ ä¿å­˜è¯Šæ–­ç‰¹å¾ï¼ˆæ•°æ®é‡: {df_data.shape}ï¼‰...")
        
        # CSVæ–‡ä»¶ä¿å­˜ï¼ˆæ— å¤§å°é™åˆ¶ï¼‰
        csv_path = f'models/diagnosis_feature{model_suffix}.csv'
        df_data.to_csv(csv_path, index=False)
        print(f"âœ… è¯Šæ–­ç‰¹å¾CSVå·²ä¿å­˜: {csv_path}")
        
        # Excelæ–‡ä»¶åˆ†å—ä¿å­˜ï¼ˆé¿å…è¶…è¿‡Excelè¡Œæ•°é™åˆ¶ï¼‰
        excel_path = f'models/diagnosis_feature{model_suffix}.xlsx'
        max_rows_per_sheet = 1000000  # Excelé™åˆ¶çº¦104ä¸‡è¡Œï¼Œç•™äº›ä½™é‡
        
        if len(df_data) > max_rows_per_sheet:
            print(f"âš ï¸  æ•°æ®é‡è¿‡å¤§({len(df_data)}è¡Œ)ï¼Œè¿›è¡Œåˆ†å—ä¿å­˜...")
            
            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                # è®¡ç®—éœ€è¦å¤šå°‘ä¸ªå·¥ä½œè¡¨
                num_sheets = (len(df_data) + max_rows_per_sheet - 1) // max_rows_per_sheet
                
                for i in range(num_sheets):
                    start_idx = i * max_rows_per_sheet
                    end_idx = min((i + 1) * max_rows_per_sheet, len(df_data))
                    chunk = df_data.iloc[start_idx:end_idx]
                    
                    sheet_name = f'Sheet_{i+1}' if i > 0 else 'Sheet_1'
                    chunk.to_excel(writer, sheet_name=sheet_name, index=False)
                    print(f"   å·¥ä½œè¡¨ {i+1}/{num_sheets}: {start_idx+1}-{end_idx} è¡Œ")
            
            print(f"âœ… è¯Šæ–­ç‰¹å¾Excelå·²åˆ†å—ä¿å­˜: {excel_path} ({num_sheets}ä¸ªå·¥ä½œè¡¨)")
        else:
            # æ•°æ®é‡ä¸å¤§ï¼Œç›´æ¥ä¿å­˜
            df_data.to_excel(excel_path, index=False)
            print(f"âœ… è¯Šæ–­ç‰¹å¾Excelå·²ä¿å­˜: {excel_path}")
        
        # ä¿å­˜PCAåˆ†æç»“æœ
        print(f"\nğŸ’¾ ä¿å­˜PCAåˆ†æç»“æœ...")
        np.save(f'models/v_I{model_suffix}.npy', v_I)
        np.save(f'models/v{model_suffix}.npy', v)
        np.save(f'models/v_ratio{model_suffix}.npy', v_ratio)
        np.save(f'models/p_k{model_suffix}.npy', p_k)
        np.save(f'models/data_mean{model_suffix}.npy', data_mean)
        np.save(f'models/data_std{model_suffix}.npy', data_std)
        np.save(f'models/T_95_limit{model_suffix}.npy', T_95_limit)
        np.save(f'models/T_99_limit{model_suffix}.npy', T_99_limit)
        np.save(f'models/SPE_95_limit{model_suffix}.npy', SPE_95_limit)
        np.save(f'models/SPE_99_limit{model_suffix}.npy', SPE_99_limit)
        np.save(f'models/P{model_suffix}.npy', P)
        np.save(f'models/k{model_suffix}.npy', k)
        np.save(f'models/P_t{model_suffix}.npy', P_t)
        np.save(f'models/X{model_suffix}.npy', X)
        np.save(f'models/data_nor{model_suffix}.npy', data_nor)
        print(f"âœ… PCAåˆ†æç»“æœå·²ä¿å­˜: models/*{model_suffix}.npy")
        
        # ä¿å­˜MC-AEè®­ç»ƒå†å²
        print(f"\nğŸ’¾ ä¿å­˜MC-AEè®­ç»ƒå†å²...")
        mcae_training_history = {
            'mcae1_losses': train_losses_mcae1,
            'mcae2_losses': train_losses_mcae2,
            'final_mcae1_loss': train_losses_mcae1[-1],
            'final_mcae2_loss': train_losses_mcae2[-1],
            'mcae1_reconstruction_error_mean': np.mean(np.abs(ERRORU)),
            'mcae1_reconstruction_error_std': np.std(np.abs(ERRORU)),
            'mcae2_reconstruction_error_mean': np.mean(np.abs(ERRORX)),
            'mcae2_reconstruction_error_std': np.std(np.abs(ERRORX)),
            'training_samples': len(train_samples),
            'epochs': EPOCH_MCAE,
            'learning_rate': LR_MCAE,
            'batch_size': BATCHSIZE_MCAE
        }
        
        with open(f'models/transformer_mcae_training_history.pkl', 'wb') as f:
            pickle.dump(mcae_training_history, f)
        print(f"âœ… MC-AEè®­ç»ƒå†å²å·²ä¿å­˜: models/transformer_mcae_training_history.pkl")
        
        print("\nğŸ‰ æ‰€æœ‰æ•°æ®ä¿å­˜å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿åœ¨Train_Transformer.pyè¿è¡Œç¯å¢ƒä¸­æ‰§è¡Œæ­¤è„šæœ¬")

if __name__ == "__main__":
    save_transformer_results() 