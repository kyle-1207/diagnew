# FAIå¯è§†åŒ–åˆ†æè„šæœ¬
# ç”ŸæˆFAIæ—¶åºå›¾å’Œé˜ˆå€¼åˆ†æå›¾

import numpy as np
import matplotlib.pyplot as plt
import pickle
import torch
import os
import warnings
from Function_ import *
from Class_ import *
from Comprehensive_calculation import Comprehensive_calculation

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®è®¾å¤‡
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

def load_sample_data(sample_id):
    """åŠ è½½æ ·æœ¬æ•°æ®"""
    base_path = f'/mnt/bz25t/bzhy/zhanglikang/project/QAS/{sample_id}'
    
    with open(f'{base_path}/vin_1.pkl', 'rb') as f:
        vin1_data = pickle.load(f)
    with open(f'{base_path}/vin_2.pkl', 'rb') as f:
        vin2_data = pickle.load(f) 
    with open(f'{base_path}/vin_3.pkl', 'rb') as f:
        vin3_data = pickle.load(f)
        
    return vin1_data, vin2_data, vin3_data

def load_models():
    """åŠ è½½æ¨¡å‹å’ŒPCAå‚æ•°"""
    models = {}
    
    # åŠ è½½MC-AEæ¨¡å‹
    models['net'] = CombinedAE(input_size=2, encode2_input_size=3, output_size=110,
                              activation_fn=custom_activation, use_dx_in_forward=True).to(device)
    models['netx'] = CombinedAE(input_size=2, encode2_input_size=4, output_size=110, 
                               activation_fn=torch.sigmoid, use_dx_in_forward=True).to(device)
    
    # åŠ è½½æ¨¡å‹æƒé‡
    net_path = "/mnt/bz25t/bzhy/datasave/Three_model/BILSTM/net_model_bilstm_baseline.pth"
    netx_path = "/mnt/bz25t/bzhy/datasave/Three_model/BILSTM/netx_model_bilstm_baseline.pth"
    
    models['net'].load_state_dict(torch.load(net_path, map_location=device), strict=False)
    models['netx'].load_state_dict(torch.load(netx_path, map_location=device), strict=False)
    
    # åŠ è½½PCAå‚æ•°
    pca_params_path = "/mnt/bz25t/bzhy/datasave/Three_model/BILSTM/pca_params_bilstm_baseline.pkl"
    with open(pca_params_path, 'rb') as f:
        models['pca_params'] = pickle.load(f)
    
    return models

def compute_fai_for_sample(sample_id, models):
    """è®¡ç®—æ ·æœ¬çš„FAIå€¼"""
    # åŠ è½½æ•°æ®
    vin1_data, vin2_data, vin3_data = load_sample_data(sample_id)
    
    # æ•°æ®é¢„å¤„ç†
    if len(vin1_data.shape) == 2:
        vin1_data = vin1_data.unsqueeze(1)
    vin1_data = vin1_data.to(torch.float32).to(device)

    # å®šä¹‰ç»´åº¦
    dim_x, dim_y, dim_z, dim_q = 2, 110, 110, 3
    dim_x2, dim_y2, dim_z2, dim_q2 = 2, 110, 110, 4
    
    # åˆ†ç¦»æ•°æ®
    x_recovered = vin2_data[:, :dim_x]
    y_recovered = vin2_data[:, dim_x:dim_x + dim_y]
    z_recovered = vin2_data[:, dim_x + dim_y: dim_x + dim_y + dim_z]
    q_recovered = vin2_data[:, dim_x + dim_y + dim_z:]
    
    x_recovered2 = vin3_data[:, :dim_x2]
    y_recovered2 = vin3_data[:, dim_x2:dim_x2 + dim_y2]
    z_recovered2 = vin3_data[:, dim_x2 + dim_y2: dim_x2 + dim_y2 + dim_z2]
    q_recovered2 = vin3_data[:, dim_x2 + dim_y2 + dim_z2:]
    
    # MC-AEæ¨ç†
    models['net'].eval()
    models['netx'].eval()
    
    with torch.no_grad():
        x_recovered = x_recovered.float()
        z_recovered = z_recovered.float()
        q_recovered = q_recovered.float()
        x_recovered2 = x_recovered2.float()
        z_recovered2 = z_recovered2.float()
        q_recovered2 = q_recovered2.float()
        
        recon_imtest = models['net'](x_recovered, z_recovered, q_recovered)
        reconx_imtest = models['netx'](x_recovered2, z_recovered2, q_recovered2)
    
    # è®¡ç®—é‡æ„è¯¯å·®
    AA = recon_imtest[0].cpu().detach().numpy()
    yTrainU = y_recovered.cpu().detach().numpy()
    ERRORU = AA - yTrainU

    BB = reconx_imtest[0].cpu().detach().numpy()
    yTrainX = y_recovered2.cpu().detach().numpy()
    ERRORX = BB - yTrainX

    # è¯Šæ–­ç‰¹å¾æå–
    df_data = DiagnosisFeature(ERRORU, ERRORX)
    
    # ç»¼åˆè®¡ç®—è·å–FAI
    pca_params = models['pca_params']
    time = np.arange(df_data.shape[0])
    
    result = Comprehensive_calculation(
        df_data.values, 
        pca_params['data_mean'], 
        pca_params['data_std'], 
        pca_params['v'].reshape(len(pca_params['v']), 1), 
        pca_params['p_k'], 
        pca_params['v_I'], 
        pca_params['T_99_limit'], 
        pca_params['SPE_99_limit'], 
        pca_params['X'], 
        time
    )
    
    fai = result[9]  # FAIæ˜¯ç¬¬10ä¸ªè¿”å›å€¼
    
    return fai

def plot_fai_analysis(fai_normal, fai_fault, sample_id_normal, sample_id_fault):
    """ç»˜åˆ¶FAIåˆ†æå›¾"""
    
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    
    # è®¡ç®—é˜ˆå€¼
    def calc_thresholds(fai, sigma_mult):
        nm = 3000
        mm = len(fai)
        if mm > nm:
            baseline = fai[nm:mm]
        else:
            baseline = fai
        mean_val = np.mean(baseline)
        std_val = np.std(baseline)
        return mean_val + sigma_mult * std_val
    
    # å­å›¾1: æ­£å¸¸æ ·æœ¬FAIæ—¶åº
    ax1 = axes[0, 0]
    time_normal = np.arange(len(fai_normal))
    ax1.plot(time_normal, fai_normal, 'b-', linewidth=1, alpha=0.8, label=f'æ ·æœ¬{sample_id_normal} (æ­£å¸¸)')
    
    # æ·»åŠ ä¸åŒé˜ˆå€¼çº¿
    thresholds_normal = {
        '3Ïƒ': calc_thresholds(fai_normal, 3),
        '2Ïƒ': calc_thresholds(fai_normal, 2),
        '1.5Ïƒ': calc_thresholds(fai_normal, 1.5)
    }
    
    colors = ['red', 'orange', 'green']
    for i, (name, thresh) in enumerate(thresholds_normal.items()):
        ax1.axhline(y=thresh, color=colors[i], linestyle='--', alpha=0.7, label=f'{name}é˜ˆå€¼')
        above_count = np.sum(fai_normal > thresh)
        ax1.text(0.02, 0.98-i*0.05, f'{name}: {above_count}ç‚¹ ({above_count/len(fai_normal)*100:.2f}%)', 
                transform=ax1.transAxes, fontsize=10, verticalalignment='top')
    
    ax1.set_title(f'æ­£å¸¸æ ·æœ¬{sample_id_normal} - FAIæ—¶åºåˆ†æ')
    ax1.set_xlabel('æ—¶é—´æ­¥é•¿')
    ax1.set_ylabel('FAIå€¼')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # å­å›¾2: æ•…éšœæ ·æœ¬FAIæ—¶åº
    ax2 = axes[0, 1]
    time_fault = np.arange(len(fai_fault))
    ax2.plot(time_fault, fai_fault, 'r-', linewidth=1, alpha=0.8, label=f'æ ·æœ¬{sample_id_fault} (æ•…éšœ)')
    
    # æ·»åŠ ä¸åŒé˜ˆå€¼çº¿
    thresholds_fault = {
        '3Ïƒ': calc_thresholds(fai_fault, 3),
        '2Ïƒ': calc_thresholds(fai_fault, 2),
        '1.5Ïƒ': calc_thresholds(fai_fault, 1.5)
    }
    
    for i, (name, thresh) in enumerate(thresholds_fault.items()):
        ax2.axhline(y=thresh, color=colors[i], linestyle='--', alpha=0.7, label=f'{name}é˜ˆå€¼')
        above_count = np.sum(fai_fault > thresh)
        ax2.text(0.02, 0.98-i*0.05, f'{name}: {above_count}ç‚¹ ({above_count/len(fai_fault)*100:.2f}%)', 
                transform=ax2.transAxes, fontsize=10, verticalalignment='top')
    
    ax2.set_title(f'æ•…éšœæ ·æœ¬{sample_id_fault} - FAIæ—¶åºåˆ†æ')
    ax2.set_xlabel('æ—¶é—´æ­¥é•¿')
    ax2.set_ylabel('FAIå€¼')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # å­å›¾3: FAIåˆ†å¸ƒç›´æ–¹å›¾å¯¹æ¯”
    ax3 = axes[1, 0]
    ax3.hist(fai_normal, bins=50, alpha=0.6, color='blue', label=f'æ­£å¸¸æ ·æœ¬{sample_id_normal}', density=True)
    ax3.hist(fai_fault, bins=50, alpha=0.6, color='red', label=f'æ•…éšœæ ·æœ¬{sample_id_fault}', density=True)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    ax3.axvline(np.mean(fai_normal), color='blue', linestyle='-', alpha=0.8, label=f'æ­£å¸¸å‡å€¼: {np.mean(fai_normal):.4f}')
    ax3.axvline(np.mean(fai_fault), color='red', linestyle='-', alpha=0.8, label=f'æ•…éšœå‡å€¼: {np.mean(fai_fault):.4f}')
    
    ax3.set_title('FAIå€¼åˆ†å¸ƒå¯¹æ¯”')
    ax3.set_xlabel('FAIå€¼')
    ax3.set_ylabel('å¯†åº¦')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # å­å›¾4: é˜ˆå€¼æ•æ„Ÿæ€§åˆ†æ
    ax4 = axes[1, 1]
    
    sigma_range = np.arange(1.0, 4.1, 0.1)
    ratios_normal = []
    ratios_fault = []
    
    for sigma in sigma_range:
        thresh_normal = calc_thresholds(fai_normal, sigma)
        thresh_fault = calc_thresholds(fai_fault, sigma)
        
        ratio_normal = np.sum(fai_normal > thresh_normal) / len(fai_normal)
        ratio_fault = np.sum(fai_fault > thresh_fault) / len(fai_fault)
        
        ratios_normal.append(ratio_normal)
        ratios_fault.append(ratio_fault)
    
    ax4.plot(sigma_range, ratios_normal, 'b-', linewidth=2, label=f'æ­£å¸¸æ ·æœ¬{sample_id_normal}')
    ax4.plot(sigma_range, ratios_fault, 'r-', linewidth=2, label=f'æ•…éšœæ ·æœ¬{sample_id_fault}')
    
    # æ ‡è®°å…³é”®ç‚¹
    ax4.axvline(3.0, color='gray', linestyle='--', alpha=0.7, label='åŸç‰ˆ3Ïƒ')
    ax4.axvline(2.0, color='orange', linestyle='--', alpha=0.7, label='å®½æ¾2Ïƒ')
    ax4.axhline(0.05, color='green', linestyle=':', alpha=0.7, label='ç›®æ ‡5%å¼‚å¸¸ç‡')
    
    ax4.set_title('é˜ˆå€¼æ•æ„Ÿæ€§åˆ†æ')
    ax4.set_xlabel('é˜ˆå€¼å€æ•° (Ïƒ)')
    ax4.set_ylabel('è¶…è¿‡é˜ˆå€¼çš„æ¯”ä¾‹')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.set_ylim(0, 0.2)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_path = "Linux/fai_analysis_comparison.png"
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š åˆ†æå›¾ä¿å­˜è‡³: {save_path}")
    plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ğŸ¨ FAIå¯è§†åŒ–åˆ†æå·¥å…·")
    print("="*80)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ”§ åŠ è½½æ¨¡å‹å’Œå‚æ•°...")
    models = load_models()
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # è®¡ç®—FAI
    print("\nğŸ”¬ è®¡ç®—æ ·æœ¬FAIå€¼...")
    fai_normal = compute_fai_for_sample('10', models)
    fai_fault = compute_fai_for_sample('335', models)
    
    print(f"   æ­£å¸¸æ ·æœ¬10: é•¿åº¦={len(fai_normal)}, å‡å€¼={np.mean(fai_normal):.6f}, æ ‡å‡†å·®={np.std(fai_normal):.6f}")
    print(f"   æ•…éšœæ ·æœ¬335: é•¿åº¦={len(fai_fault)}, å‡å€¼={np.mean(fai_fault):.6f}, æ ‡å‡†å·®={np.std(fai_fault):.6f}")
    
    # ç”Ÿæˆå¯è§†åŒ–
    print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–åˆ†æ...")
    plot_fai_analysis(fai_normal, fai_fault, '10', '335')
    
    print("\nğŸ‰ åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()