#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»å·²ä¿å­˜çš„Transformeræ¨¡å‹ç»§ç»­è®¡ç®—å‰©ä½™ç»“æœ
é¿å…é‡æ–°è®­ç»ƒï¼Œç›´æ¥åŠ è½½æ¨¡å‹å’Œä¸­é—´ç»“æœ
"""

import numpy as np
import pandas as pd
import pickle
import os
import torch
from Function_ import DiagnosisFeature, PCA

def continue_transformer_calculation():
    """ä»å·²ä¿å­˜çš„æ¨¡å‹ç»§ç»­è®¡ç®—"""
    print("="*60)
    print("ğŸ”„ ä»å·²ä¿å­˜çš„Transformeræ¨¡å‹ç»§ç»­è®¡ç®—")
    print("="*60)
    
    # æ£€æŸ¥modelsç›®å½•
    if not os.path.exists('models'):
        print("âŒ modelsç›®å½•ä¸å­˜åœ¨")
        return
    
    # æ£€æŸ¥å·²ä¿å­˜çš„æ–‡ä»¶
    model_suffix = "_transformer"
    required_files = [
        f'net_model{model_suffix}.pth',
        f'netx_model{model_suffix}.pth',
        f'transformer_model.pth'
    ]
    
    print("ğŸ” æ£€æŸ¥å·²ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶...")
    for file in required_files:
        if os.path.exists(f'models/{file}'):
            print(f"âœ… {file}")
        else:
            print(f"âŒ {file} ä¸å­˜åœ¨")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­é—´ç»“æœæ–‡ä»¶
    print("\nğŸ” æ£€æŸ¥ä¸­é—´ç»“æœæ–‡ä»¶...")
    intermediate_files = [
        f'ERRORU{model_suffix}.npy',
        f'ERRORX{model_suffix}.npy',
        f'vin2_modified{model_suffix}.npy',
        f'vin3_modified{model_suffix}.npy'
    ]
    
    has_intermediate = False
    for file in intermediate_files:
        if os.path.exists(f'models/{file}'):
            print(f"âœ… {file}")
            has_intermediate = True
        else:
            print(f"âŒ {file} ä¸å­˜åœ¨")
    
    if not has_intermediate:
        print("\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°ä¸­é—´ç»“æœæ–‡ä»¶")
        print("å°è¯•ä»å·²ä¿å­˜çš„æ¨¡å‹é‡æ–°è®¡ç®—ä¸­é—´ç»“æœ...")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¯ç”¨çš„æ•°æ®æ–‡ä»¶
        alternative_files = [
            'vin2_modified.npy',
            'vin3_modified.npy',
            'combined_vin2.npy',
            'combined_vin3.npy'
        ]
        
        has_alternative = False
        for file in alternative_files:
            if os.path.exists(f'models/{file}'):
                print(f"âœ… æ‰¾åˆ°æ›¿ä»£æ–‡ä»¶: {file}")
                has_alternative = True
        
        if not has_alternative:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ•°æ®æ–‡ä»¶")
            print("è¯·å…ˆè¿è¡ŒTrain_Transformer.pyåˆ°MC-AEè®­ç»ƒå®Œæˆé˜¶æ®µ")
            return
        
        # å°è¯•ä»æ›¿ä»£æ–‡ä»¶é‡æ–°è®¡ç®—
        print("ğŸ”„ å°è¯•ä»æ›¿ä»£æ–‡ä»¶é‡æ–°è®¡ç®—ä¸­é—´ç»“æœ...")
        try:
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…å¯ç”¨çš„æ–‡ä»¶æ¥è°ƒæ•´
            # æš‚æ—¶è¿”å›ï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨å¤„ç†
            print("âš ï¸  éœ€è¦æ‰‹åŠ¨æä¾›ERRORUå’ŒERRORXæ•°æ®")
            print("å»ºè®®è¿è¡ŒTrain_Transformer.pyåˆ°MC-AEè®­ç»ƒå®Œæˆ")
            return
        except Exception as e:
            print(f"âŒ é‡æ–°è®¡ç®—å¤±è´¥: {e}")
            return
    
    # åŠ è½½ä¸­é—´ç»“æœ
    print("\nğŸ“¥ åŠ è½½ä¸­é—´ç»“æœ...")
    try:
        ERRORU = np.load(f'models/ERRORU{model_suffix}.npy')
        ERRORX = np.load(f'models/ERRORX{model_suffix}.npy')
        print(f"âœ… åŠ è½½ERRORU: {ERRORU.shape}")
        print(f"âœ… åŠ è½½ERRORX: {ERRORX.shape}")
    except Exception as e:
        print(f"âŒ åŠ è½½ä¸­é—´ç»“æœå¤±è´¥: {e}")
        return
    
    # æå–è¯Šæ–­ç‰¹å¾
    print("\nğŸ” æå–è¯Šæ–­ç‰¹å¾...")
    try:
        df_data = DiagnosisFeature(ERRORU, ERRORX)
        print(f"âœ… è¯Šæ–­ç‰¹å¾æå–å®Œæˆ: {df_data.shape}")
    except Exception as e:
        print(f"âŒ è¯Šæ–­ç‰¹å¾æå–å¤±è´¥: {e}")
        return
    
    # è¿›è¡ŒPCAåˆ†æ
    print("\nğŸ” è¿›è¡ŒPCAåˆ†æ...")
    try:
        v_I, v, v_ratio, p_k, data_mean, data_std, T_95_limit, T_99_limit, SPE_95_limit, SPE_99_limit, P, k, P_t, X, data_nor = PCA(df_data, 0.95, 0.95)
        print(f"âœ… PCAåˆ†æå®Œæˆ:")
        print(f"   ä¸»æˆåˆ†æ•°é‡: {k}")
        print(f"   è§£é‡Šæ–¹å·®æ¯”: {v_ratio}")
        print(f"   TÂ²æ§åˆ¶é™: 95%={T_95_limit:.4f}, 99%={T_99_limit:.4f}")
        print(f"   SPEæ§åˆ¶é™: 95%={SPE_95_limit:.4f}, 99%={SPE_99_limit:.4f}")
    except Exception as e:
        print(f"âŒ PCAåˆ†æå¤±è´¥: {e}")
        return
    
    # ä¿å­˜è¯Šæ–­ç‰¹å¾ï¼ˆåˆ†å—ä¿å­˜ï¼Œé¿å…æ–‡ä»¶è¿‡å¤§ï¼‰
    print("\nğŸ’¾ ä¿å­˜è¯Šæ–­ç‰¹å¾...")
    try:
        # åˆ†å—ä¿å­˜ä¸ºCSVï¼ˆæ¯å—50ä¸‡è¡Œï¼Œé¿å…å†…å­˜é—®é¢˜ï¼‰
        chunk_size = 500000
        total_rows = len(df_data)
        num_chunks = (total_rows + chunk_size - 1) // chunk_size
        
        print(f"   æ•°æ®æ€»è¡Œæ•°: {total_rows:,}")
        print(f"   åˆ†å—å¤§å°: {chunk_size:,} è¡Œ")
        print(f"   åˆ†å—æ•°é‡: {num_chunks}")
        
        # ä¿å­˜åˆ†å—CSVæ–‡ä»¶
        for i in range(num_chunks):
            start_idx = i * chunk_size
            end_idx = min((i + 1) * chunk_size, total_rows)
            chunk = df_data.iloc[start_idx:end_idx]
            
            if num_chunks == 1:
                csv_filename = f'models/diagnosis_feature{model_suffix}.csv'
            else:
                csv_filename = f'models/diagnosis_feature{model_suffix}_chunk_{i+1:02d}.csv'
            
            chunk.to_csv(csv_filename, index=False)
            print(f"   ä¿å­˜CSVåˆ†å— {i+1}/{num_chunks}: è¡Œ {start_idx+1:,}-{end_idx:,} -> {csv_filename}")
        
        # åˆ†å—ä¿å­˜ä¸ºExcelï¼ˆæ¯å—100ä¸‡è¡Œï¼‰
        excel_chunk_size = 1000000
        excel_num_chunks = (total_rows + excel_chunk_size - 1) // excel_chunk_size
        
        with pd.ExcelWriter(f'models/diagnosis_feature{model_suffix}.xlsx', engine='openpyxl') as writer:
            for i in range(excel_num_chunks):
                start_idx = i * excel_chunk_size
                end_idx = min((i + 1) * excel_chunk_size, total_rows)
                chunk = df_data.iloc[start_idx:end_idx]
                sheet_name = f'chunk_{i+1}' if excel_num_chunks > 1 else 'data'
                chunk.to_excel(writer, sheet_name=sheet_name, index=False)
                print(f"   ä¿å­˜Excelåˆ†å— {i+1}/{excel_num_chunks}: è¡Œ {start_idx+1:,}-{end_idx:,}")
        
        print(f"âœ… è¯Šæ–­ç‰¹å¾å·²ä¿å­˜:")
        print(f"   - CSVæ–‡ä»¶: {num_chunks}ä¸ªåˆ†å—")
        print(f"   - Excelæ–‡ä»¶: {excel_num_chunks}ä¸ªåˆ†å—")
        if num_chunks > 1:
            print(f"   - ä¸»æ–‡ä»¶: models/diagnosis_feature{model_suffix}_chunk_01.csv")
        else:
            print(f"   - ä¸»æ–‡ä»¶: models/diagnosis_feature{model_suffix}.csv")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜è¯Šæ–­ç‰¹å¾å¤±è´¥: {e}")
        return
    
    # ä¿å­˜PCAåˆ†æç»“æœ
    print("\nğŸ’¾ ä¿å­˜PCAåˆ†æç»“æœ...")
    try:
        np.save(f'models/v_I{model_suffix}.npy', v_I)
        np.save(f'models/v{model_suffix}.npy', v)
        np.save(f'models/v_ratio{model_suffix}.npy', v_ratio)
        np.save(f'models/p_k{model_suffix}.npy', p_k)
        np.save(f'models/data_mean{model_suffix}.npy', data_mean)
        np.save(f'models/data_std{model_suffix}.npy', data_std)
        np.save(f'models/T_95_limit{model_suffix}.npy', T_95_limit)
        np.save(f'models/T_99_limit{model_suffix}.npy', T_99_limit)
        np.save(f'models/SPE_95_limit{model_suffix}.npy', SPE_95_limit)
        np.save(f'models/SPE_99_limit{model_suffix}.npy', SPE_99_limit)
        np.save(f'models/P{model_suffix}.npy', P)
        np.save(f'models/k{model_suffix}.npy', k)
        np.save(f'models/P_t{model_suffix}.npy', P_t)
        np.save(f'models/X{model_suffix}.npy', X)
        np.save(f'models/data_nor{model_suffix}.npy', data_nor)
        print(f"âœ… PCAåˆ†æç»“æœå·²ä¿å­˜: models/*{model_suffix}.npy")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜PCAåˆ†æç»“æœå¤±è´¥: {e}")
        return
    
    # ä¿å­˜è®­ç»ƒå†å²ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    print("\nğŸ’¾ ä¿å­˜è®­ç»ƒå†å²...")
    try:
        # å°è¯•åŠ è½½å·²æœ‰çš„è®­ç»ƒå†å²
        if os.path.exists(f'models/transformer_mcae_training_history.pkl'):
            with open(f'models/transformer_mcae_training_history.pkl', 'rb') as f:
                mcae_training_history = pickle.load(f)
            print("âœ… å·²åŠ è½½ç°æœ‰è®­ç»ƒå†å²")
        else:
            # åˆ›å»ºåŸºæœ¬çš„è®­ç»ƒå†å²
            mcae_training_history = {
                'mcae1_reconstruction_error_mean': np.mean(np.abs(ERRORU)),
                'mcae1_reconstruction_error_std': np.std(np.abs(ERRORU)),
                'mcae2_reconstruction_error_mean': np.mean(np.abs(ERRORX)),
                'mcae2_reconstruction_error_std': np.std(np.abs(ERRORX)),
                'pca_components': k,
                'explained_variance_ratio': v_ratio,
                't2_limits': {'95%': T_95_limit, '99%': T_99_limit},
                'spe_limits': {'95%': SPE_95_limit, '99%': SPE_99_limit}
            }
            print("âœ… åˆ›å»ºæ–°çš„è®­ç»ƒå†å²")
        
        # æ›´æ–°è®­ç»ƒå†å²
        mcae_training_history.update({
            'diagnosis_feature_shape': df_data.shape,
            'pca_analysis_completed': True,
            'calculation_completed': True
        })
        
        with open(f'models/transformer_mcae_training_history.pkl', 'wb') as f:
            pickle.dump(mcae_training_history, f)
        print(f"âœ… è®­ç»ƒå†å²å·²ä¿å­˜: models/transformer_mcae_training_history.pkl")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜è®­ç»ƒå†å²å¤±è´¥: {e}")
        return
    
    print("\nğŸ‰ æ‰€æœ‰è®¡ç®—å®Œæˆï¼")
    print("="*60)
    print("ğŸ“Š è®¡ç®—ç»“æœæ€»ç»“:")
    print(f"   è¯Šæ–­ç‰¹å¾æ•°æ®: {df_data.shape}")
    print(f"   PCAä¸»æˆåˆ†æ•°: {k}")
    print(f"   è§£é‡Šæ–¹å·®æ¯”: {v_ratio}")
    print(f"   TÂ²æ§åˆ¶é™: 95%={T_95_limit:.4f}, 99%={T_99_limit:.4f}")
    print(f"   SPEæ§åˆ¶é™: 95%={SPE_95_limit:.4f}, 99%={SPE_99_limit:.4f}")
    print("")
    print("ğŸ“ ä¿å­˜çš„æ–‡ä»¶:")
    if num_chunks > 1:
        print(f"   - diagnosis_feature{model_suffix}_chunk_*.csv (åˆ†å—CSVæ•°æ®)")
    else:
        print(f"   - diagnosis_feature{model_suffix}.csv (å®Œæ•´CSVæ•°æ®)")
    print(f"   - diagnosis_feature{model_suffix}.xlsx (åˆ†å—Excelæ•°æ®)")
    print(f"   - æ‰€æœ‰PCAåˆ†æç»“æœ (*{model_suffix}.npy)")
    print(f"   - è®­ç»ƒå†å² (transformer_mcae_training_history.pkl)")

if __name__ == "__main__":
    continue_transformer_calculation() 