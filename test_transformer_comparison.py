#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ–°æ·»åŠ çš„Transformeræ¨¡å‹å¯¹æ¯”åŠŸèƒ½
éªŒè¯é›·è¾¾å›¾å’ŒROCåˆ†æå›¾çš„ç”Ÿæˆ
"""

import os
import sys
import tempfile
import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np

# Linuxç¯å¢ƒé…ç½®
mpl.use('Agg')

def test_transformer_comparison():
    """æµ‹è¯•Transformerå¯¹æ¯”åŠŸèƒ½"""
    print("ğŸ§ª Testing Transformer comparison functionality...")
    
    # å¯¼å…¥ä¿®æ”¹åçš„å¯è§†åŒ–æ¨¡å—
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    
    try:
        from Run_Complete_Visualization import CompleteVisualizationRunner
        
        # ä½¿ç”¨ä¸´æ—¶ç›®å½•è¿›è¡Œæµ‹è¯•
        with tempfile.TemporaryDirectory() as temp_dir:
            print(f"ğŸ“ Using temporary directory: {temp_dir}")
            
            # åˆ›å»ºå¯è§†åŒ–è¿è¡Œå™¨å®ä¾‹
            runner = CompleteVisualizationRunner(base_dir=temp_dir)
            
            # æµ‹è¯•å•ç‹¬çš„Transformerå¯¹æ¯”åŠŸèƒ½
            print("\nğŸ”„ Testing _run_transformer_comparison_analysis()...")
            result = runner._run_transformer_comparison_analysis()
            
            if result['status'] == 'success':
                print("âœ… Transformer comparison analysis succeeded")
                
                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
                output_file = result.get('transformer_comparison_charts')
                if output_file and os.path.exists(output_file):
                    file_size = os.path.getsize(output_file)
                    print(f"âœ… Output file generated: {os.path.basename(output_file)} ({file_size} bytes)")
                    
                    # éªŒè¯å›¾åƒæ–‡ä»¶å®Œæ•´æ€§
                    if file_size > 0:
                        print("âœ… Output file has valid size")
                    else:
                        print("âŒ Output file is empty")
                        return False
                else:
                    print("âŒ Output file not found")
                    return False
            else:
                print(f"âŒ Transformer comparison analysis failed: {result.get('error', 'Unknown error')}")
                return False
            
            # æµ‹è¯•å®Œæ•´åˆ†ææµç¨‹ä¸­çš„é›†æˆ
            print("\nğŸ”„ Testing integration in complete analysis...")
            try:
                analysis_results, report_path = runner.run_complete_analysis()
                
                if 'transformer_comparison' in analysis_results:
                    comp_result = analysis_results['transformer_comparison']
                    if comp_result and comp_result.get('status') == 'success':
                        print("âœ… Transformer comparison integrated successfully in complete analysis")
                    else:
                        print("âš ï¸  Transformer comparison had issues in complete analysis")
                else:
                    print("âŒ Transformer comparison not found in complete analysis results")
                    return False
                    
            except Exception as e:
                print(f"âŒ Complete analysis integration test failed: {e}")
                return False
            
            print("\nğŸ‰ All tests passed!")
            return True
            
    except ImportError as e:
        print(f"âŒ Import error: {e}")
        return False
    except Exception as e:
        print(f"âŒ Unexpected error: {e}")
        return False

def test_individual_chart_functions():
    """æµ‹è¯•å•ç‹¬çš„å›¾è¡¨ç”Ÿæˆå‡½æ•°"""
    print("\nğŸ§ª Testing individual chart generation functions...")
    
    try:
        from Run_Complete_Visualization import CompleteVisualizationRunner
        
        with tempfile.TemporaryDirectory() as temp_dir:
            runner = CompleteVisualizationRunner(base_dir=temp_dir)
            
            # æ¨¡æ‹Ÿæ€§èƒ½æŒ‡æ ‡æ•°æ®
            metrics1 = {
                'accuracy': 0.92, 'precision': 0.88, 'recall': 0.95,
                'f1_score': 0.91, 'specificity': 0.89, 'tpr': 0.95, 'fpr': 0.11, 'auc': 0.94
            }
            metrics2 = {
                'accuracy': 0.94, 'precision': 0.91, 'recall': 0.93,
                'f1_score': 0.92, 'specificity': 0.95, 'tpr': 0.93, 'fpr': 0.05, 'auc': 0.96
            }
            
            # æµ‹è¯•å„ä¸ªå›¾è¡¨ç”Ÿæˆå‡½æ•°
            fig, axes = plt.subplots(2, 3, figsize=(15, 10))
            
            # æµ‹è¯•é›·è¾¾å›¾
            try:
                ax1 = plt.subplot(2, 3, 1, projection='polar')
                runner._create_radar_comparison(ax1, metrics1, metrics2)
                print("âœ… Radar chart generation works")
            except Exception as e:
                print(f"âŒ Radar chart failed: {e}")
                return False
            
            # æµ‹è¯•ROCæ›²çº¿
            try:
                ax2 = plt.subplot(2, 3, 2)
                runner._create_roc_comparison(ax2, metrics1, metrics2)
                print("âœ… ROC curve generation works")
            except Exception as e:
                print(f"âŒ ROC curve failed: {e}")
                return False
            
            # æµ‹è¯•æ€§èƒ½æŒ‡æ ‡æ¡å½¢å›¾
            try:
                ax3 = plt.subplot(2, 3, 3)
                runner._create_metrics_comparison_bar(ax3, metrics1, metrics2)
                print("âœ… Metrics bar chart generation works")
            except Exception as e:
                print(f"âŒ Metrics bar chart failed: {e}")
                return False
            
            # æµ‹è¯•å·¥ä½œç‚¹å¯¹æ¯”
            try:
                ax4 = plt.subplot(2, 3, 4)
                runner._create_working_point_comparison(ax4, metrics1, metrics2)
                print("âœ… Working point comparison works")
            except Exception as e:
                print(f"âŒ Working point comparison failed: {e}")
                return False
            
            # æµ‹è¯•ç²¾åº¦-å¬å›ç‡æ›²çº¿
            try:
                ax5 = plt.subplot(2, 3, 5)
                runner._create_precision_recall_comparison(ax5, metrics1, metrics2)
                print("âœ… Precision-recall curve generation works")
            except Exception as e:
                print(f"âŒ Precision-recall curve failed: {e}")
                return False
            
            # æµ‹è¯•æ··æ·†çŸ©é˜µ
            try:
                ax6 = plt.subplot(2, 3, 6)
                runner._create_confusion_matrix_comparison(ax6)
                print("âœ… Confusion matrix comparison works")
            except Exception as e:
                print(f"âŒ Confusion matrix comparison failed: {e}")
                return False
            
            # ä¿å­˜æµ‹è¯•å›¾è¡¨
            test_output = os.path.join(temp_dir, "test_charts.png")
            plt.tight_layout()
            plt.savefig(test_output, dpi=150, bbox_inches='tight')
            plt.close()
            
            if os.path.exists(test_output) and os.path.getsize(test_output) > 0:
                print(f"âœ… Test chart saved successfully: {os.path.basename(test_output)}")
            else:
                print("âŒ Test chart save failed")
                return False
            
            print("ğŸ‰ All individual chart functions work correctly!")
            return True
            
    except Exception as e:
        print(f"âŒ Individual chart test failed: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Starting Transformer Comparison Feature Tests")
    print("="*60)
    
    # æµ‹è¯•1: æ•´ä½“åŠŸèƒ½æµ‹è¯•
    test1_passed = test_transformer_comparison()
    
    # æµ‹è¯•2: å•ç‹¬å‡½æ•°æµ‹è¯•
    test2_passed = test_individual_chart_functions()
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print("\nğŸ“Š Test Summary:")
    print("="*60)
    print(f"ğŸ§ª Overall functionality test: {'âœ… PASSED' if test1_passed else 'âŒ FAILED'}")
    print(f"ğŸ”§ Individual functions test: {'âœ… PASSED' if test2_passed else 'âŒ FAILED'}")
    
    if test1_passed and test2_passed:
        print("\nğŸ‰ All tests PASSED! The new Transformer comparison feature is working correctly.")
        return True
    else:
        print("\nâŒ Some tests FAILED. Please check the error messages above.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
