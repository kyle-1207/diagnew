# ä¸­æ–‡æ³¨é‡Šï¼šå¯¼å…¥å¸¸ç”¨åº“å’Œè‡ªå®šä¹‰æ¨¡å—
import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np
import pandas as pd
import matplotlib.ticker as mtick
import os
import warnings
import matplotlib
from Function_ import *
from Class_ import *
from Comprehensive_calculation import Comprehensive_calculation
import math
from create_dataset import series_to_supervised
from sklearn import preprocessing
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import scipy.io as scio
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torch.nn.functional as F
from torch import nn
from torchvision import transforms as tfs
import scipy.stats as stats
import seaborn as sns
import pickle
from scipy import ndimage
from tqdm import tqdm
import json
import time
from datetime import datetime
from sklearn.metrics import roc_curve, auc, confusion_matrix
from Comprehensive_calculation import Comprehensive_calculation

# å¯¼å…¥æ–°çš„æ•°æ®åŠ è½½å™¨
from data_loader_transformer import TransformerBatteryDataset, create_transformer_dataloader

# å†…å­˜ç›‘æ§å‡½æ•°
def print_gpu_memory():
    """æ‰“å°GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            allocated = torch.cuda.memory_allocated(i) / 1024**3
            cached = torch.cuda.memory_reserved(i) / 1024**3
            total = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   GPU {i}: {allocated:.1f}GB / {cached:.1f}GB / {total:.1f}GB (å·²ç”¨/ç¼“å­˜/æ€»è®¡)")

# æ··åˆç²¾åº¦è®­ç»ƒé…ç½®
def setup_mixed_precision():
    """è®¾ç½®æ··åˆç²¾åº¦è®­ç»ƒ"""
    scaler = torch.cuda.amp.GradScaler()
    print("âœ… å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP)")
    return scaler

# GPUè®¾å¤‡é…ç½®
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'  # ä½¿ç”¨GPU0å’ŒGPU1
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

# æ‰“å°GPUä¿¡æ¯
if torch.cuda.is_available():
    print(f"\nğŸ–¥ï¸ åŒGPUå¹¶è¡Œé…ç½®:")
    print(f"   å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        props = torch.cuda.get_device_properties(i)
        print(f"   GPU {i} ({props.name}): {props.total_memory/1024**3:.1f}GB")
    print(f"   ä¸»GPUè®¾å¤‡: cuda:0")
    print(f"   æ•°æ®å¹¶è¡Œæ¨¡å¼: å¯ç”¨")
else:
    print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUè®­ç»ƒ")

# ä¸­æ–‡æ³¨é‡Šï¼šå¿½ç•¥è­¦å‘Šä¿¡æ¯
warnings.filterwarnings('ignore')

# Linuxç¯å¢ƒmatplotlibé…ç½®
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯

# Linuxç¯å¢ƒå­—ä½“è®¾ç½® - ä¿®å¤ä¸­æ–‡æ˜¾ç¤ºé—®é¢˜
import matplotlib.font_manager as fm
import os

# æ›´å…¨é¢çš„å­—ä½“æ£€æµ‹å’Œè®¾ç½®
def setup_chinese_fonts():
    """è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨è‹±æ–‡"""
    try:
        # å°è¯•å¤šç§ä¸­æ–‡å­—ä½“
        chinese_fonts = [
            'SimHei', 'Microsoft YaHei', 'WenQuanYi Micro Hei', 'Noto Sans CJK SC',
            'Noto Sans CJK JP', 'Noto Sans CJK TC', 'Source Han Sans CN',
            'Droid Sans Fallback', 'WenQuanYi Zen Hei', 'AR PL UMing CN'
        ]
        
        # æ£€æŸ¥ç³»ç»Ÿå­—ä½“
        try:
            system_fonts = [f.name for f in fm.fontManager.ttflist]
            print(f"ğŸ” ç³»ç»Ÿå¯ç”¨å­—ä½“æ•°é‡: {len(system_fonts)}")
        except:
            system_fonts = []
            print("âš ï¸  æ— æ³•è·å–ç³»ç»Ÿå­—ä½“åˆ—è¡¨")
        
        # æŸ¥æ‰¾å¯ç”¨çš„ä¸­æ–‡å­—ä½“
        available_chinese = []
        for font in chinese_fonts:
            if font in system_fonts:
                available_chinese.append(font)
                print(f"âœ… æ‰¾åˆ°ä¸­æ–‡å­—ä½“: {font}")
        
        if available_chinese:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„ä¸­æ–‡å­—ä½“
            plt.rcParams['font.sans-serif'] = available_chinese
            plt.rcParams['axes.unicode_minus'] = False
            print(f"ğŸ¨ ä½¿ç”¨ä¸­æ–‡å­—ä½“: {available_chinese[0]}")
            return True
        else:
            # æ²¡æœ‰ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨è‹±æ–‡
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Liberation Sans', 'Arial']
            plt.rcParams['axes.unicode_minus'] = False
            print("âš ï¸  æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨è‹±æ–‡æ ‡ç­¾")
            return False
    except Exception as e:
        print(f"âš ï¸  å­—ä½“è®¾ç½®å‡ºç°é—®é¢˜: {e}")
        # ä½¿ç”¨æœ€åŸºæœ¬çš„å­—ä½“è®¾ç½®
        plt.rcParams['font.family'] = 'sans-serif'
        plt.rcParams['axes.unicode_minus'] = False
        return False

# è®¾ç½®å­—ä½“
use_chinese = setup_chinese_fonts()
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.size'] = 10

#----------------------------------------å®éªŒé…ç½®------------------------------
# è®­ç»ƒå’Œæµ‹è¯•æ ·æœ¬é…ç½®
TRAIN_SAMPLES = list(range(10))  # è®­ç»ƒé›†ï¼šQAS 0-9ï¼ˆ10ä¸ªæ­£å¸¸æ ·æœ¬ï¼‰
TEST_SAMPLES = {
    'normal': ['10', '11'],      # æµ‹è¯•æ­£å¸¸æ ·æœ¬
    'fault': ['335', '336']      # æµ‹è¯•æ•…éšœæ ·æœ¬
}
ALL_TEST_SAMPLES = TEST_SAMPLES['normal'] + TEST_SAMPLES['fault']

# ä¸‰çª—å£å›ºå®šå‚æ•°
WINDOW_CONFIG = {
    "detection_window": 100,     # æ£€æµ‹çª—å£ï¼š100ä¸ªé‡‡æ ·ç‚¹
    "verification_window": 50,   # éªŒè¯çª—å£ï¼š50ä¸ªé‡‡æ ·ç‚¹  
    "marking_window": 50        # æ ‡è®°çª—å£ï¼šå‰åå„50ä¸ªé‡‡æ ·ç‚¹
}

# ä¸¤ç§å®éªŒé…ç½®
EXPERIMENT_CONFIGS = {
    'original': {
        'name': 'åŸå§‹å‚æ•°è§„æ¨¡',
        'd_model': 128,
        'n_heads': 8,
        'n_layers': 6,
        'd_ff': 512,
        'dropout': 0.1,
        'save_suffix': '_original'
    },
    'enhanced': {
        'name': 'å¢å¼ºå‚æ•°è§„æ¨¡(+50%)',
        'd_model': 192,      # 128 * 1.5
        'n_heads': 12,       # 8 * 1.5
        'n_layers': 6,       # ä¿æŒä¸å˜
        'd_ff': 768,         # 512 * 1.5
        'dropout': 0.2,      # å¢åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆ
        'save_suffix': '_enhanced'
    }
}

# åå‘ä¼ æ’­æœºåˆ¶å‚æ•°
FEEDBACK_CONFIG = {
    'use_feedback': True,
    'feedback_frequency': 5,     # æ¯5ä¸ªepochæ‰§è¡Œä¸€æ¬¡åé¦ˆ
    'feedback_alpha': 0.1,       # åé¦ˆæŸå¤±æƒé‡
    'diagnosis_threshold': 0.5,  # è¯Šæ–­é˜ˆå€¼
    'min_false_positives': 10    # æœ€å°‘å‡é˜³æ€§æ ·æœ¬æ•°æ‰æ‰§è¡Œåé¦ˆ
}

print("="*60)
print("ğŸš€ Transformeré›†æˆè®­ç»ƒæµ‹è¯•ç³»ç»Ÿ")
print("="*60)
print(f"ğŸ“Š å®éªŒé…ç½®:")
print(f"   è®­ç»ƒæ ·æœ¬: {TRAIN_SAMPLES} (å…±{len(TRAIN_SAMPLES)}ä¸ª)")
print(f"   æµ‹è¯•æ ·æœ¬: {ALL_TEST_SAMPLES} (æ­£å¸¸:{len(TEST_SAMPLES['normal'])}, æ•…éšœ:{len(TEST_SAMPLES['fault'])})")
print(f"   ä¸‰çª—å£å‚æ•°: {WINDOW_CONFIG}")
print(f"   åå‘ä¼ æ’­: {'å¯ç”¨' if FEEDBACK_CONFIG['use_feedback'] else 'ç¦ç”¨'}")
for config_name, config in EXPERIMENT_CONFIGS.items():
    print(f"   {config['name']}: d_model={config['d_model']}, n_heads={config['n_heads']}")

#----------------------------------------Transformeræ¨¡å‹å®šä¹‰------------------------------
class TransformerPredictor(nn.Module):
    """æ—¶åºé¢„æµ‹Transformeræ¨¡å‹ - æ”¯æŒå¯é…ç½®å‚æ•°"""
    def __init__(self, input_size=7, d_model=128, nhead=8, num_layers=3, d_ff=None, dropout=0.1, output_size=2):
        super(TransformerPredictor, self).__init__()
        self.input_size = input_size
        self.d_model = d_model
        if d_ff is None:
            d_ff = d_model * 4  # é»˜è®¤ä¸ºd_modelçš„4å€
        
        # è¾“å…¥æŠ•å½±å±‚
        self.input_projection = nn.Linear(input_size, d_model)
        
        # ä½ç½®ç¼–ç 
        self.pos_encoding = nn.Parameter(torch.randn(1000, d_model, dtype=torch.float32))
        
        # Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model, 
            nhead=nhead,
            dim_feedforward=d_ff,
            dropout=dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # è¾“å‡ºå±‚ - ç›´æ¥è¾“å‡ºç‰©ç†å€¼ï¼Œä¸ä½¿ç”¨Sigmoid
        self.output_layer = nn.Sequential(
            nn.Linear(d_model, d_model//2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model//2, output_size)
        )
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
    
    def _init_weights(self):
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
    
    def forward(self, x):
        # x: [batch, input_size] - 2ç»´è¾“å…¥
        if len(x.shape) == 2:
            # æ·»åŠ åºåˆ—ç»´åº¦ï¼š[batch, input_size] -> [batch, 1, input_size]
            x = x.unsqueeze(1)
        
        batch_size, seq_len, _ = x.shape
        
        # è¾“å…¥æŠ•å½±
        x = self.input_projection(x)  # [batch, seq_len, d_model]
        
        # æ·»åŠ ä½ç½®ç¼–ç 
        pos_enc = self.pos_encoding[:seq_len, :].unsqueeze(0).expand(batch_size, -1, -1)
        x = x + pos_enc
        
        # Transformerç¼–ç 
        transformer_out = self.transformer(x)  # [batch, seq_len, d_model]
        
        # è¾“å‡ºå±‚ï¼ˆä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥ï¼‰
        output = self.output_layer(transformer_out[:, -1, :])  # [batch, output_size]
        
        return output  # [batch, output_size] ç›´æ¥è¿”å›2ç»´

#----------------------------------------åå‘ä¼ æ’­æœºåˆ¶è®¾è®¡------------------------------
def compute_feedback_loss(transformer_output, false_positive_mask, normal_center):
    """è®¡ç®—åå‘ä¼ æ’­çš„åé¦ˆæŸå¤±"""
    if not false_positive_mask.any():
        return torch.tensor(0.0, device=transformer_output.device, requires_grad=True)
    
    false_positive_features = transformer_output[false_positive_mask]
    
    # è·ç¦»æŸå¤±ï¼šè®©å‡é˜³æ€§æ ·æœ¬çš„ç‰¹å¾å‘é‡æ›´æ¥è¿‘æ­£å¸¸æ ·æœ¬çš„å¹³å‡ç‰¹å¾
    if len(false_positive_features) > 0:
        distance_loss = F.mse_loss(
            false_positive_features, 
            normal_center.expand_as(false_positive_features)
        )
        
        # å¯¹æ¯”æŸå¤±ï¼šå¢å¼ºæ­£å¸¸æ ·æœ¬ä¸å¼‚å¸¸æ ·æœ¬çš„åŒºåˆ†åº¦
        # ç®€åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨L2è·ç¦»
        contrastive_loss = torch.mean(torch.norm(false_positive_features - normal_center, dim=1))
        
        return distance_loss + 0.1 * contrastive_loss
    else:
        return torch.tensor(0.0, device=transformer_output.device, requires_grad=True)

#----------------------------------------ä¸‰çª—å£æ•…éšœæ£€æµ‹æœºåˆ¶------------------------------
def three_window_fault_detection(fai_values, threshold1, sample_id):
    """
    ä¸‰çª—å£æ•…éšœæ£€æµ‹æœºåˆ¶ï¼šæ£€æµ‹â†’éªŒè¯â†’æ ‡è®°
    
    Args:
        fai_values: ç»¼åˆè¯Šæ–­æŒ‡æ ‡åºåˆ—
        threshold1: ä¸€çº§é¢„è­¦é˜ˆå€¼
        sample_id: æ ·æœ¬IDï¼ˆç”¨äºè°ƒè¯•ï¼‰
    
    Returns:
        fault_labels: æ•…éšœæ ‡ç­¾åºåˆ— (0=æ­£å¸¸, 1=æ•…éšœ)
        detection_info: æ£€æµ‹è¿‡ç¨‹è¯¦ç»†ä¿¡æ¯
    """
    detection_window = WINDOW_CONFIG["detection_window"]
    verification_window = WINDOW_CONFIG["verification_window"] 
    marking_window = WINDOW_CONFIG["marking_window"]
    
    fault_labels = np.zeros(len(fai_values), dtype=int)
    detection_info = {
        'candidate_points': [],
        'verified_points': [],
        'marked_regions': [],
        'window_stats': {}
    }
    
    # é˜¶æ®µ1ï¼šæ£€æµ‹çª—å£ - å¯»æ‰¾å€™é€‰æ•…éšœç‚¹
    candidate_points = []
    for i in range(len(fai_values)):
        if fai_values[i] > threshold1:
            candidate_points.append(i)
    
    detection_info['candidate_points'] = candidate_points
    
    if len(candidate_points) == 0:
        # æ²¡æœ‰å€™é€‰ç‚¹ï¼Œç›´æ¥è¿”å›
        return fault_labels, detection_info
    
    # é˜¶æ®µ2ï¼šéªŒè¯çª—å£ - æ£€æŸ¥æŒç»­æ€§
    verified_points = []
    for candidate in candidate_points:
        # å®šä¹‰éªŒè¯çª—å£èŒƒå›´
        start_verify = max(0, candidate - verification_window//2)
        end_verify = min(len(fai_values), candidate + verification_window//2)
        verify_data = fai_values[start_verify:end_verify]
        
        # æŒç»­æ€§åˆ¤æ–­ï¼šéªŒè¯çª—å£å†…è¶…é˜ˆå€¼ç‚¹æ¯”ä¾‹
        continuous_ratio = np.sum(verify_data > threshold1) / len(verify_data)
        
        # 30%ä»¥ä¸Šè¶…é˜ˆå€¼è®¤ä¸ºæŒç»­å¼‚å¸¸
        if continuous_ratio >= 0.3:
            verified_points.append({
                'point': candidate,
                'continuous_ratio': continuous_ratio,
                'verify_range': (start_verify, end_verify)
            })
    
    detection_info['verified_points'] = verified_points
    
    # é˜¶æ®µ3ï¼šæ ‡è®°çª—å£ - æ ‡è®°æ•…éšœåŒºåŸŸ
    marked_regions = []
    for verified in verified_points:
        candidate = verified['point']
        
        # å®šä¹‰æ ‡è®°çª—å£èŒƒå›´
        start_mark = max(0, candidate - marking_window)
        end_mark = min(len(fai_values), candidate + marking_window)
        
        # æ ‡è®°æ•…éšœåŒºåŸŸ
        fault_labels[start_mark:end_mark] = 1
        
        marked_regions.append({
            'center': candidate,
            'range': (start_mark, end_mark),
            'length': end_mark - start_mark
        })
    
    detection_info['marked_regions'] = marked_regions
    
    # ç»Ÿè®¡ä¿¡æ¯
    detection_info['window_stats'] = {
        'total_candidates': len(candidate_points),
        'verified_candidates': len(verified_points),
        'total_fault_points': np.sum(fault_labels),
        'fault_ratio': np.sum(fault_labels) / len(fault_labels)
    }
    
    return fault_labels, detection_info

#----------------------------------------è¯Šæ–­é˜ˆå€¼è®¡ç®—------------------------------
def calculate_thresholds(fai):
    """æŒ‰ç…§Test_combine_transonly.pyçš„æ–¹æ³•è®¡ç®—è¯Šæ–­é˜ˆå€¼"""
    nm = 3000  # å›ºå®šå€¼ï¼Œä¸æºä»£ç ä¸€è‡´
    mm = len(fai)  # æ•°æ®æ€»é•¿åº¦
    
    # ç¡®ä¿æ•°æ®é•¿åº¦è¶³å¤Ÿ
    if mm > nm:
        # ä½¿ç”¨ååŠæ®µæ•°æ®è®¡ç®—é˜ˆå€¼
        threshold1 = np.mean(fai[nm:mm]) + 3*np.std(fai[nm:mm])
        threshold2 = np.mean(fai[nm:mm]) + 4.5*np.std(fai[nm:mm])
        threshold3 = np.mean(fai[nm:mm]) + 6*np.std(fai[nm:mm])
    else:
        # æ•°æ®å¤ªçŸ­ï¼Œä½¿ç”¨å…¨éƒ¨æ•°æ®
        threshold1 = np.mean(fai) + 3*np.std(fai)
        threshold2 = np.mean(fai) + 4.5*np.std(fai)
        threshold3 = np.mean(fai) + 6*np.std(fai)
    
    return threshold1, threshold2, threshold3

#----------------------------------------æ•°æ®åŠ è½½å‡½æ•°------------------------------
def load_train_samples():
    """åŠ è½½è®­ç»ƒæ ·æœ¬ID"""
    try:
        import pandas as pd
        labels_path = '/mnt/bz25t/bzhy/zhanglikang/project/data/QAS/Labels.xls'
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(labels_path):
            print(f"âš ï¸  Labels.xlsæ–‡ä»¶ä¸å­˜åœ¨: {labels_path}")
            print("âš ï¸  ä½¿ç”¨é»˜è®¤æ ·æœ¬èŒƒå›´ 0-9")
            return TRAIN_SAMPLES
        
        df = pd.read_excel(labels_path)
        print(f"ğŸ“‹ æˆåŠŸè¯»å–Labels.xls, å…±{len(df)}è¡Œæ•°æ®")
        
        # æ£€æŸ¥DataFrameåˆ—å
        print(f"ğŸ“‹ å¯ç”¨åˆ—å: {df.columns.tolist()}")
        
        # å°è¯•ä¸åŒçš„åˆ—å
        if 'Num' in df.columns:
            all_samples = df['Num'].tolist()
        elif 'num' in df.columns:
            all_samples = df['num'].tolist()
        elif df.columns.size > 0:
            # ä½¿ç”¨ç¬¬ä¸€åˆ—
            all_samples = df.iloc[:, 0].tolist()
        else:
            raise ValueError("æ— æ³•æ‰¾åˆ°æ ·æœ¬IDåˆ—")
        
        # æå–0-9èŒƒå›´çš„æ ·æœ¬
        train_samples = [i for i in all_samples if i in TRAIN_SAMPLES]
        
        print(f"ğŸ“‹ ä»Labels.xlsåŠ è½½è®­ç»ƒæ ·æœ¬:")
        print(f"   è®­ç»ƒæ ·æœ¬èŒƒå›´: 0-9")
        print(f"   å®é™…å¯ç”¨æ ·æœ¬: {len(train_samples)} ä¸ª")
        print(f"   æ ·æœ¬åˆ—è¡¨: {train_samples}")
        
        return train_samples if train_samples else TRAIN_SAMPLES
    except Exception as e:
        print(f"âŒ åŠ è½½Labels.xlså¤±è´¥: {e}")
        print("âš ï¸  ä½¿ç”¨é»˜è®¤æ ·æœ¬èŒƒå›´ 0-9")
        return TRAIN_SAMPLES

def load_test_sample(sample_id):
    """åŠ è½½æµ‹è¯•æ ·æœ¬"""
    base_path = f'/mnt/bz25t/bzhy/zhanglikang/project/data/QAS/{sample_id}'
    
    # æ£€æŸ¥æ ·æœ¬ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(base_path):
        raise FileNotFoundError(f"æµ‹è¯•æ ·æœ¬ç›®å½•ä¸å­˜åœ¨: {base_path}")
    
    # åŠ è½½vin_1, vin_2, vin_3æ•°æ®
    try:
        with open(f'{base_path}/vin_1.pkl', 'rb') as f:
            vin1_data = pickle.load(f)
        with open(f'{base_path}/vin_2.pkl', 'rb') as f:
            vin2_data = pickle.load(f) 
        with open(f'{base_path}/vin_3.pkl', 'rb') as f:
            vin3_data = pickle.load(f)
    except FileNotFoundError as e:
        raise FileNotFoundError(f"æ ·æœ¬ {sample_id} æ•°æ®æ–‡ä»¶ç¼ºå¤±: {e}")
        
    return vin1_data, vin2_data, vin3_data

#----------------------------------------ä¸»è®­ç»ƒå‡½æ•°------------------------------
def train_experiment(config_name, config):
    """è®­ç»ƒå•ä¸ªå®éªŒé…ç½®"""
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒå®éªŒ: {config['name']}")
    print(f"{'='*60}")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    save_suffix = config['save_suffix']
    save_dir = f"modelsfl{save_suffix}"
    os.makedirs(save_dir, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸­é—´ç»“æœï¼Œæ”¯æŒæ–­ç‚¹ç»­ç®—
    checkpoint_path = f"{save_dir}/checkpoint.pkl"
    if os.path.exists(checkpoint_path):
        print(f"ğŸ”„ å‘ç°æ–­ç‚¹æ–‡ä»¶ï¼Œå°è¯•æ¢å¤è®­ç»ƒ...")
        try:
            with open(checkpoint_path, 'rb') as f:
                checkpoint = pickle.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½æ–­ç‚¹ï¼Œé˜¶æ®µ: {checkpoint.get('stage', 'unknown')}")
            if checkpoint.get('stage') == 'completed':
                print(f"âš ï¸  å®éªŒå·²å®Œæˆï¼Œè·³è¿‡è®­ç»ƒ")
                return checkpoint
        except Exception as e:
            print(f"âŒ æ–­ç‚¹æ–‡ä»¶æŸå: {e}ï¼Œé‡æ–°å¼€å§‹è®­ç»ƒ")
    
    # åˆå§‹åŒ–ç»“æœå­—å…¸
    experiment_results = {
        'config': config,
        'stage': 'starting',
        'transformer_results': {},
        'mcae_results': {},
        'pca_results': {},
        'test_results': {},
        'timing': {}
    }
    
    # é˜¶æ®µ1: è®­ç»ƒTransformer
    print(f"\nğŸ¯ é˜¶æ®µ1: è®­ç»ƒTransformeræ¨¡å‹")
    start_time = time.time()
    
    try:
        # åŠ è½½è®­ç»ƒæ ·æœ¬
        train_samples = load_train_samples()
        print(f"ğŸ“Š ä½¿ç”¨{len(train_samples)}ä¸ªè®­ç»ƒæ ·æœ¬")
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = TransformerBatteryDataset(
            data_path='/mnt/bz25t/bzhy/zhanglikang/project/QAS', 
            sample_ids=train_samples
        )
        
        if len(dataset) == 0:
            raise ValueError("æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•è®­ç»ƒæ•°æ®")
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(dataset)} ä¸ªè®­ç»ƒæ•°æ®å¯¹")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        BATCH_SIZE = 4000
        train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, 
                                num_workers=4, pin_memory=True)
        
        # åˆå§‹åŒ–Transformeræ¨¡å‹
        transformer = TransformerPredictor(
            input_size=7,
            d_model=config['d_model'],
            nhead=config['n_heads'],
            num_layers=config['n_layers'],
            d_ff=config['d_ff'],
            dropout=config['dropout'],
            output_size=2
        ).to(device).float()
        
        # å¯ç”¨æ•°æ®å¹¶è¡Œ
        if torch.cuda.device_count() > 1:
            transformer = torch.nn.DataParallel(transformer)
            print(f"âœ… å¯ç”¨æ•°æ®å¹¶è¡Œï¼Œä½¿ç”¨ {torch.cuda.device_count()} å¼ GPU")
        
        print(f"ğŸ§  Transformeræ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ˆ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in transformer.parameters()):,}")
        
        # è®­ç»ƒå‚æ•°
        LR = 1.5e-3
        EPOCH = 40
        lr_decay_freq = 15
        
        optimizer = torch.optim.Adam(transformer.parameters(), lr=LR)
        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_decay_freq, gamma=0.9)
        criterion = nn.MSELoss()
        scaler = setup_mixed_precision()
        
        # è®­ç»ƒå¾ªç¯
        transformer.train()
        train_losses = []
        
        for epoch in range(EPOCH):
            epoch_loss = 0
            batch_count = 0
            
            for batch_input, batch_target in train_loader:
                batch_input = batch_input.to(device)
                batch_target = batch_target.to(device)
                
                optimizer.zero_grad()
                
                # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
                with torch.cuda.amp.autocast():
                    pred_output = transformer(batch_input)
                    loss = criterion(pred_output, batch_target)
                
                # åå‘ä¼ æ’­æœºåˆ¶ï¼ˆæ¯5ä¸ªepochæ‰§è¡Œä¸€æ¬¡ï¼‰
                if FEEDBACK_CONFIG['use_feedback'] and epoch % FEEDBACK_CONFIG['feedback_frequency'] == 0:
                    # ç®€åŒ–çš„åé¦ˆæœºåˆ¶ï¼šè¿™é‡Œæˆ‘ä»¬æš‚æ—¶è·³è¿‡ï¼Œå› ä¸ºéœ€è¦MC-AEçš„ç»“æœ
                    pass
                
                # æ··åˆç²¾åº¦åå‘ä¼ æ’­
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
                
                epoch_loss += loss.item()
                batch_count += 1
            
            scheduler.step()
            avg_loss = epoch_loss / batch_count
            train_losses.append(avg_loss)
            
            if epoch % 5 == 0 or epoch == EPOCH - 1:
                current_lr = optimizer.param_groups[0]['lr']
                print(f'Epoch: {epoch:3d} | Loss: {avg_loss:.6f} | LR: {current_lr:.6f}')
        
        # ä¿å­˜Transformeræ¨¡å‹
        transformer_path = f'{save_dir}/transformer_model.pth'
        torch.save(transformer.state_dict(), transformer_path)
        print(f"âœ… Transformeræ¨¡å‹å·²ä¿å­˜: {transformer_path}")
        
        # è®°å½•Transformerè®­ç»ƒç»“æœ
        experiment_results['transformer_results'] = {
            'train_losses': train_losses,
            'final_loss': train_losses[-1],
            'model_path': transformer_path,
            'config': config
        }
        experiment_results['timing']['transformer'] = time.time() - start_time
        experiment_results['stage'] = 'transformer_completed'
        
        # ä¿å­˜ä¸­é—´ç»“æœ
        with open(checkpoint_path, 'wb') as f:
            pickle.dump(experiment_results, f)
        
        print(f"âœ… Transformerè®­ç»ƒå®Œæˆï¼Œç”¨æ—¶: {experiment_results['timing']['transformer']:.2f}ç§’")
        
    except Exception as e:
        print(f"âŒ Transformerè®­ç»ƒå¤±è´¥: {e}")
        raise e
    
    return experiment_results

# ç»§ç»­æ·»åŠ MC-AEè®­ç»ƒå’Œæµ‹è¯•å‡½æ•°
# ç”±äºç¯‡å¹…é™åˆ¶ï¼Œè¿™é‡Œå…ˆå®ç°ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬çš„å®Œæ•´æµç¨‹

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    
    print("\nğŸš€ å¼€å§‹é›†æˆè®­ç»ƒæµ‹è¯•å®éªŒ...")
    
    all_results = {}
    
    # æ‰§è¡Œä¸¤ä¸ªå®éªŒé…ç½®
    for config_name, config in EXPERIMENT_CONFIGS.items():
        print(f"\n{'='*80}")
        print(f"ğŸ”¬ å®éªŒé…ç½®: {config['name']}")
        print(f"{'='*80}")
        
        try:
            # è®­ç»ƒå®éªŒï¼ˆè¿™é‡Œåªæ˜¯Transformeréƒ¨åˆ†ï¼Œå®Œæ•´ç‰ˆæœ¬éœ€è¦æ·»åŠ MC-AEè®­ç»ƒï¼‰
            experiment_results = train_experiment(config_name, config)
            
            # TODO: æ·»åŠ MC-AEè®­ç»ƒå’ŒPCAåˆ†æ
            # TODO: æ·»åŠ æµ‹è¯•åŠŸèƒ½
            # TODO: æ·»åŠ å¯è§†åŒ–åŠŸèƒ½
            
            all_results[config_name] = experiment_results
            
            print(f"âœ… {config['name']} å®éªŒé˜¶æ®µ1å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ å®éªŒ {config['name']} å¤±è´¥: {e}")
            continue
    
    print(f"\nğŸ‰ Transformerè®­ç»ƒé˜¶æ®µå®Œæˆï¼")
    print(f"ğŸ“ æ³¨æ„: è¿™æ˜¯ç®€åŒ–ç‰ˆæœ¬ï¼Œå®Œæ•´ç‰ˆæœ¬éœ€è¦æ·»åŠ :")
    print(f"   1. MC-AEè®­ç»ƒåŠŸèƒ½")
    print(f"   2. PCAåˆ†æåŠŸèƒ½") 
    print(f"   3. æµ‹è¯•å’Œä¸‰çª—å£æ£€æµ‹åŠŸèƒ½")
    print(f"   4. å¯è§†åŒ–å¯¹æ¯”åŠŸèƒ½")
    print(f"   5. åå‘ä¼ æ’­æœºåˆ¶çš„å®Œæ•´å®ç°")

if __name__ == "__main__":
    main()