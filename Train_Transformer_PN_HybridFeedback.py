#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ­£è´Ÿåé¦ˆæ··åˆè®­ç»ƒè„šæœ¬ (Positive-Negative Hybrid Feedback Training)
åŸºäºTransformerçš„ç”µæ± æ•…éšœæ£€æµ‹ç³»ç»Ÿ

è®­ç»ƒæ ·æœ¬é…ç½®ï¼š
- è®­ç»ƒæ ·æœ¬ï¼š0-100 (åŸºç¡€è®­ç»ƒæ•°æ®)
- æ­£åé¦ˆæ ·æœ¬ï¼š101-120 (æ­£å¸¸æ ·æœ¬ï¼Œç”¨äºé™ä½å‡é˜³æ€§)
- è´Ÿåé¦ˆæ ·æœ¬ï¼š340-350 (æ•…éšœæ ·æœ¬ï¼Œç”¨äºå¢å¼ºåŒºåˆ†åº¦)

æ¨¡å‹ä¿å­˜è·¯å¾„ï¼š/mnt/bz25t/bzhy/datasave/Transformer/models/PN_model/
"""

import os
import sys
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pickle
import warnings
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éGUIåç«¯ï¼Œé¿å…åœ¨æœåŠ¡å™¨ç¯å¢ƒä¸­å¡ä½
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import platform
from datetime import datetime
import time
from tqdm import tqdm
import json
import pandas as pd

# æ·»åŠ æºä»£ç è·¯å¾„
sys.path.append('./æºä»£ç å¤‡ä»½')
sys.path.append('.')

# å¯¼å…¥å¿…è¦æ¨¡å—
from Function_ import *
from Class_ import *
from create_dataset import series_to_supervised
from sklearn import preprocessing
import scipy.io as scio
import torch.nn.functional as F
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')
warnings.filterwarnings('ignore', message='.*findfont.*')
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
os.environ['PYTHONWARNINGS'] = 'ignore'

# æŠ‘åˆ¶matplotlibå­—ä½“è­¦å‘Š
import matplotlib
matplotlib.rcParams['font.family'] = 'sans-serif'
matplotlib.rcParams['axes.unicode_minus'] = False

#=================================== é…ç½®å‚æ•° ===================================

def load_sample_labels():
    """ä»Labels.xlsåŠ è½½æ ·æœ¬æ ‡ç­¾ä¿¡æ¯"""
    try:
        labels_path = '/mnt/bz25t/bzhy/zhanglikang/project/QAS/Labels.xls'
        labels_df = pd.read_excel(labels_path)
        
        # æå–æ­£å¸¸æ ·æœ¬å’Œæ•…éšœæ ·æœ¬
        normal_samples = labels_df[labels_df['Label'] == 0]['Num'].astype(str).tolist()
        fault_samples = labels_df[labels_df['Label'] == 1]['Num'].astype(str).tolist()
        
        print(f"ğŸ“Š ä»Labels.xlsåŠ è½½æ ·æœ¬æ ‡ç­¾:")
        print(f"   æ­£å¸¸æ ·æœ¬: {len(normal_samples)} ä¸ª")
        print(f"   æ•…éšœæ ·æœ¬: {len(fault_samples)} ä¸ª")
        print(f"   æ€»æ ·æœ¬æ•°: {len(labels_df)} ä¸ª")
        
        return normal_samples, fault_samples, labels_df
    except Exception as e:
        print(f"âŒ åŠ è½½Labels.xlså¤±è´¥: {e}")
        print("ğŸ”„ ä½¿ç”¨é»˜è®¤æ ·æœ¬é…ç½®")
        # è¿”å›é»˜è®¤é…ç½®
        normal_samples = [str(i) for i in range(0, 50)]
        fault_samples = [str(i) for i in range(340, 360)]
        return normal_samples, fault_samples, None

# åŠ è½½æ ·æœ¬æ ‡ç­¾
normal_samples, fault_samples, labels_df = load_sample_labels()

# æ­£è´Ÿåé¦ˆæ··åˆè®­ç»ƒé…ç½®
PN_HYBRID_FEEDBACK_CONFIG = {
    # æ ·æœ¬é…ç½®ï¼ˆä»Labels.xlsåŠ¨æ€åŠ è½½ï¼‰
    'train_samples': normal_samples[:100],  # å‰100ä¸ªæ­£å¸¸æ ·æœ¬ä½œä¸ºåŸºç¡€è®­ç»ƒ
    'positive_feedback_samples': normal_samples[100:120] if len(normal_samples) > 100 else normal_samples[-20:],  # æ­£åé¦ˆæ ·æœ¬(æ­£å¸¸)
    'negative_feedback_samples': fault_samples[:20] if len(fault_samples) >= 20 else fault_samples,  # è´Ÿåé¦ˆæ ·æœ¬(æ•…éšœ)
    
    # è®­ç»ƒé˜¶æ®µé…ç½®
    'training_phases': {
        'phase1_transformer': {
            'epochs': 50,
            'description': 'åŸºç¡€Transformerè®­ç»ƒ'
        },
        'phase2_mcae': {
            'epochs': 80,
            'description': 'MC-AEè®­ç»ƒ(ä½¿ç”¨Transformerå¢å¼ºæ•°æ®)'
        },
        'phase3_feedback': {
            'epochs': 30,
            'description': 'æ­£è´Ÿåé¦ˆæ··åˆä¼˜åŒ–'
        }
    },
    
    # æ­£åé¦ˆé…ç½®
    'positive_feedback': {
        'enable': True,
        'weight': 0.3,              # æ­£åé¦ˆæƒé‡
        'start_epoch': 10,          # å¼€å§‹è½®æ¬¡
        'frequency': 5,             # è¯„ä¼°é¢‘ç‡
        'target_fpr': 0.01,         # ç›®æ ‡å‡é˜³æ€§ç‡ 1%
        'adjustment_factor': 0.1    # è°ƒæ•´å› å­
    },
    
    # è´Ÿåé¦ˆé…ç½®
    'negative_feedback': {
        'enable': True,
        'alpha': 0.4,               # æ­£å¸¸æ ·æœ¬æŸå¤±æƒé‡
        'beta': 1.2,                # æ•…éšœæ ·æœ¬æŸå¤±æƒé‡  
        'margin': 0.15,             # å¯¹æ¯”å­¦ä¹ è¾¹ç•Œ
        'start_epoch': 20,          # å¼€å§‹è½®æ¬¡
        'evaluation_frequency': 3,   # è¯„ä¼°é¢‘ç‡
        'min_separation': 0.1       # æœ€å°åˆ†ç¦»åº¦è¦æ±‚
    },
    
    # æ¨¡å‹ä¿å­˜è·¯å¾„
    'save_base_path': '/mnt/bz25t/bzhy/datasave/Transformer/models/PN_model/',
    
    # 4Ã—A100è®­ç»ƒå‚æ•°ä¼˜åŒ–
    'batch_size': 4096,  # å¤šGPUç¯å¢ƒï¼Œå¢å¤§batch_sizeæé«˜å¹¶è¡Œæ•ˆç‡
    'learning_rate': 0.001,
    'device': 'cuda:0' if torch.cuda.is_available() else 'cpu'
}

print("Training Configuration - Positive-Negative Hybrid Feedback:")
print(f"   Train samples: {len(PN_HYBRID_FEEDBACK_CONFIG['train_samples'])} (normal)")
print(f"   Positive feedback samples: {len(PN_HYBRID_FEEDBACK_CONFIG['positive_feedback_samples'])} (normal)")
print(f"   Negative feedback samples: {len(PN_HYBRID_FEEDBACK_CONFIG['negative_feedback_samples'])} (fault)")
print(f"   Model save path: {PN_HYBRID_FEEDBACK_CONFIG['save_base_path']}")

if labels_df is not None:
    print(f"\nSample Distribution Statistics:")
    print(f"   Total normal samples: {len(normal_samples)}")
    print(f"   Total fault samples: {len(fault_samples)}")
    print(f"   Train sample examples: {PN_HYBRID_FEEDBACK_CONFIG['train_samples'][:5]}...")
    print(f"   Fault sample examples: {PN_HYBRID_FEEDBACK_CONFIG['negative_feedback_samples'][:5]}...")

# ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
os.makedirs(PN_HYBRID_FEEDBACK_CONFIG['save_base_path'], exist_ok=True)

#=================================== è®¾å¤‡é…ç½® ===================================

device = torch.device(PN_HYBRID_FEEDBACK_CONFIG['device'])
print(f"\nDevice Configuration: {device}")

if torch.cuda.is_available():
    print(f"   GPU count: {torch.cuda.device_count()}")
    for i in range(torch.cuda.device_count()):
        props = torch.cuda.get_device_properties(i)
        print(f"   GPU {i}: {props.name} ({props.total_memory/1024**3:.1f}GB)")

#=================================== è¾…åŠ©å‡½æ•° ===================================

def print_gpu_memory():
    """Print GPU memory usage"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"   GPU Memory: allocated {allocated:.2f}GB, reserved {reserved:.2f}GB")

def setup_fonts():
    """Setup fonts (silent mode to avoid font warnings)"""
    import warnings
    import matplotlib
    
    # Suppress font warnings temporarily
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")
        
    system = platform.system()
    if system == "Linux":
        # Linux server environment, use simple config to avoid font issues
        try:
            # Use matplotlib default fonts directly, avoid Chinese font search
            plt.rcParams['font.family'] = 'sans-serif'
            plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans']
            plt.rcParams['axes.unicode_minus'] = False
            print("   Font config: Using system default fonts (avoid font warnings)")
            return
        except:
            pass
    
    # Font config for other systems
    system_fonts = {
        "Windows": ['Arial', 'Calibri', 'Tahoma'],
        "Darwin": ['Arial', 'Helvetica', 'Geneva'],
        "Linux": ['DejaVu Sans', 'Liberation Sans', 'Arial']
    }.get(system, ['DejaVu Sans'])
    
    for font in system_fonts:
        try:
            plt.rcParams['font.sans-serif'] = [font]
            plt.rcParams['axes.unicode_minus'] = False
            break
        except:
            continue

def check_data_validity(data, data_name="data"):
    """Check data validity"""
    if data is None:
        print(f"   ERROR: {data_name} is None")
        return False
    
    # Check data type first
    print(f"   INFO: {data_name} type: {type(data)}")
    
    # If list, try to convert to numpy array
    if isinstance(data, list):
        try:
            data = np.array(data)
            print(f"   INFO: {data_name} converted from list to array: {data.shape}")
        except Exception as e:
            print(f"   ERROR: {data_name} list conversion failed: {e}")
            return False
    
    # If dict or other complex structure
    if isinstance(data, dict):
        print(f"   INFO: {data_name} is dict, keys: {list(data.keys())}")
        
        # Special handling for targets dict format (contains terminal_voltages and pack_socs)
        if 'terminal_voltages' in data and 'pack_socs' in data:
            print(f"   SUCCESS: {data_name} is standard targets format")
            # Check validity of two key data
            voltage_valid = check_data_validity(data['terminal_voltages'], f"{data_name}['terminal_voltages']")
            soc_valid = check_data_validity(data['pack_socs'], f"{data_name}['pack_socs']")
            return voltage_valid and soc_valid
        
        # Try to extract main data
        elif 'data' in data:
            return check_data_validity(data['data'], f"{data_name}['data']")
        elif len(data) == 1:
            key = list(data.keys())[0]
            return check_data_validity(data[key], f"{data_name}['{key}']")
        else:
            print(f"   ERROR: {data_name} dict structure is complex, cannot auto-process")
            return False
    
    # æ£€æŸ¥æ˜¯å¦æœ‰shapeå±æ€§
    if hasattr(data, 'shape'):
        if len(data.shape) == 0 or data.shape[0] == 0:
            print(f"   âŒ {data_name}ä¸ºç©º: {data.shape}")
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«NaNæˆ–Inf
        if hasattr(data, 'detach'):
            data_np = data.detach().cpu().numpy()
        else:
            data_np = np.array(data)
        
        if np.isnan(data_np).any():
            print(f"   âš ï¸ {data_name}åŒ…å«NaNå€¼")
        
        if np.isinf(data_np).any():
            print(f"   âš ï¸ {data_name}åŒ…å«Infå€¼")
        
        print(f"   âœ… {data_name}æœ‰æ•ˆ: {data.shape}")
        return True
    else:
        # å°è¯•è½¬æ¢ä¸ºnumpyæ•°ç»„
        try:
            data_array = np.array(data)
            print(f"   ğŸ”„ {data_name}è½¬æ¢ä¸ºæ•°ç»„: {data_array.shape}")
            return True
        except Exception as e:
            print(f"   âŒ {data_name}æ— æ³•è½¬æ¢ä¸ºæ•°ç»„: {e}")
            return False

def physics_based_data_processing_silent(data, feature_type='general'):
    """é™é»˜çš„åŸºäºç‰©ç†çº¦æŸçš„æ•°æ®å¤„ç†"""
    if isinstance(data, torch.Tensor):
        data_np = data.detach().cpu().numpy()
        is_tensor = True
        original_dtype = data.dtype
        original_device = data.device
    else:
        data_np = np.array(data)
        is_tensor = False
    
    if data_np.size == 0:
        return data if not is_tensor else torch.tensor(data_np, dtype=original_dtype, device=original_device)
    
    # å¤„ç†NaNå’ŒInf
    for col in range(data_np.shape[1] if len(data_np.shape) > 1 else 1):
        if len(data_np.shape) > 1:
            col_data = data_np[:, col]
        else:
            col_data = data_np
            
        # å¤„ç†NaN
        if np.isnan(col_data).any():
            valid_mask = ~np.isnan(col_data)
            if valid_mask.any():
                median_val = np.median(col_data[valid_mask])
                if len(data_np.shape) > 1:
                    data_np[~valid_mask, col] = median_val
                else:
                    data_np[~valid_mask] = median_val
        
        # å¤„ç†Inf
        if np.isinf(col_data).any():
            finite_mask = np.isfinite(col_data)
            if finite_mask.any():
                max_finite = np.max(col_data[finite_mask])
                min_finite = np.min(col_data[finite_mask])
                if len(data_np.shape) > 1:
                    data_np[col_data == np.inf, col] = max_finite
                    data_np[col_data == -np.inf, col] = min_finite
                else:
                    data_np[col_data == np.inf] = max_finite
                    data_np[col_data == -np.inf] = min_finite
    
    # åº”ç”¨ç‰©ç†çº¦æŸ
    if feature_type == 'voltage':
        data_np = np.clip(data_np, 2.5, 4.2)
    elif feature_type == 'soc':
        data_np = np.clip(data_np, 0.0, 1.0)
    elif feature_type == 'temperature':
        data_np = np.clip(data_np, -40, 80)
    
    if is_tensor:
        return torch.tensor(data_np, dtype=original_dtype, device=original_device)
    else:
        return data_np

#=================================== å¯¹æ¯”æŸå¤±å‡½æ•° ===================================

class ContrastiveMCAELoss(nn.Module):
    """å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œç”¨äºMC-AEè´Ÿåé¦ˆè®­ç»ƒ"""
    
    def __init__(self, alpha=0.4, beta=1.2, margin=0.15):
        super(ContrastiveMCAELoss, self).__init__()
        self.alpha = alpha      # æ­£å¸¸æ ·æœ¬æƒé‡
        self.beta = beta        # æ•…éšœæ ·æœ¬æƒé‡
        self.margin = margin    # å¯¹æ¯”è¾¹ç•Œ
        self.mse_loss = nn.MSELoss(reduction='mean')
    
    def forward(self, recon_normal, target_normal, recon_fault=None, target_fault=None):
        # æ­£å¸¸æ ·æœ¬é‡æ„æŸå¤±ï¼ˆå¸Œæœ›æœ€å°åŒ–ï¼‰
        positive_loss = self.mse_loss(recon_normal, target_normal)
        
        if recon_fault is not None and target_fault is not None:
            # æ•…éšœæ ·æœ¬é‡æ„æŸå¤±ï¼ˆå¸Œæœ›æœ€å¤§åŒ–ï¼Œä½†æœ‰è¾¹ç•Œï¼‰
            fault_loss = self.mse_loss(recon_fault, target_fault)
            
            # å¯¹æ¯”æŸå¤±ï¼šé¼“åŠ±æ•…éšœæ ·æœ¬æœ‰æ›´é«˜çš„é‡æ„è¯¯å·®
            negative_loss = torch.clamp(self.margin - fault_loss, min=0.0)
            
            # æ€»æŸå¤±
            total_loss = self.alpha * positive_loss + self.beta * negative_loss
            
            return total_loss, positive_loss, negative_loss
        else:
            return positive_loss, positive_loss, torch.tensor(0.0, device=positive_loss.device)

#=================================== Transformeræ¨¡å‹ ===================================

class TransformerPredictor(nn.Module):
    """åŸºäºTransformerçš„é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, input_size=7, d_model=128, nhead=8, num_layers=3, output_size=2):
        super(TransformerPredictor, self).__init__()
        self.input_size = input_size
        self.d_model = d_model
        self.output_size = output_size
        
        # è¾“å…¥æŠ•å½±å±‚
        self.input_projection = nn.Linear(input_size, d_model)
        
        # Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 4,
            dropout=0.1,
            activation='relu',
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # è¾“å‡ºå±‚
        self.output_projection = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(d_model // 2, output_size)
        )
        
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.constant_(module.bias, 0)
    
    def forward(self, x):
        # x: [batch, input_size]
        batch_size = x.size(0)
        
        # æŠ•å½±åˆ°transformerç»´åº¦
        x = self.input_projection(x)  # [batch, d_model]
        
        # æ·»åŠ åºåˆ—ç»´åº¦
        x = x.unsqueeze(1)  # [batch, 1, d_model]
        
        # Transformerç¼–ç 
        x = self.transformer(x)  # [batch, 1, d_model]
        
        # ç§»é™¤åºåˆ—ç»´åº¦å¹¶è¾“å‡º
        x = x.squeeze(1)  # [batch, d_model]
        output = self.output_projection(x)  # [batch, output_size]
        
        return output

#=================================== æ•°æ®åŠ è½½å‡½æ•° ===================================

def load_sample_data(sample_id, data_type='train'):
    """åŠ è½½å•ä¸ªæ ·æœ¬æ•°æ®"""
    try:
        # æ‰€æœ‰æ ·æœ¬éƒ½ä»æœåŠ¡å™¨QASç›®å½•åŠ è½½
        base_path = '/mnt/bz25t/bzhy/zhanglikang/project/QAS'
        sample_path = f"{base_path}/{sample_id}"
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        required_files = ['vin_1.pkl', 'vin_2.pkl', 'vin_3.pkl', 'targets.pkl']
        for file_name in required_files:
            file_path = f"{sample_path}/{file_name}"
            if not os.path.exists(file_path):
                print(f"   âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
        
        # åŠ è½½æ•°æ®æ–‡ä»¶
        vin_1 = pickle.load(open(f"{sample_path}/vin_1.pkl", 'rb'))
        vin_2 = pickle.load(open(f"{sample_path}/vin_2.pkl", 'rb'))
        vin_3 = pickle.load(open(f"{sample_path}/vin_3.pkl", 'rb'))
        targets = pickle.load(open(f"{sample_path}/targets.pkl", 'rb'))
        
        # è°ƒè¯•ï¼šæ£€æŸ¥åŸå§‹æ•°æ®ç±»å‹å’Œç»“æ„
        print(f"   ğŸ” åŸå§‹æ•°æ®ç±»å‹:")
        print(f"      vin_1: {type(vin_1)}")
        print(f"      vin_2: {type(vin_2)}")
        print(f"      vin_3: {type(vin_3)}")
        print(f"      targets: {type(targets)}")
        
        # å¤„ç†targetsæ•°æ®çš„ç‰¹æ®Šæƒ…å†µï¼ˆæ ¹æ®Train_Transformer.pyçš„å¤„ç†æ–¹å¼ï¼‰
        if isinstance(targets, dict):
            print(f"   ğŸ“‹ targetsæ˜¯å­—å…¸ï¼Œé”®: {list(targets.keys())}")
            # æ ¹æ®Train_Transformer.pyçš„é€»è¾‘ï¼Œtargetsåº”è¯¥åŒ…å«terminal_voltageså’Œpack_socs
            if 'terminal_voltages' in targets and 'pack_socs' in targets:
                print(f"   âœ… æ‰¾åˆ°æ ‡å‡†targetsæ ¼å¼ï¼šterminal_voltageså’Œpack_socs")
                # ä¿æŒå­—å…¸æ ¼å¼ï¼Œåç»­ä½¿ç”¨æ—¶å†æå–
                pass
            elif 'data' in targets:
                targets = targets['data']
                print(f"   ğŸ”„ ä½¿ç”¨targets['data']")
            elif len(targets) == 1:
                key = list(targets.keys())[0]
                targets = targets[key]
                print(f"   ğŸ”„ ä½¿ç”¨targets['{key}']")
            else:
                print(f"   âš ï¸ æœªçŸ¥çš„targetså­—å…¸æ ¼å¼")
        
        if isinstance(targets, list):
            print(f"   ğŸ“‹ targetsæ˜¯åˆ—è¡¨ï¼Œé•¿åº¦: {len(targets)}")
            try:
                targets = np.array(targets)
                print(f"   ğŸ”„ targetsè½¬æ¢ä¸ºæ•°ç»„: {targets.shape}")
            except Exception as e:
                print(f"   âŒ targetsåˆ—è¡¨è½¬æ¢å¤±è´¥: {e}")
                return None
        
        # æœ€ç»ˆæ•°æ®ç±»å‹è½¬æ¢å’Œæ¸…ç†
        def clean_data_for_torch(data, data_name):
            """æ¸…ç†æ•°æ®ä»¥é€‚é…PyTorch"""
            if data is None:
                return None
            
            # è½¬æ¢ä¸ºnumpy
            if hasattr(data, 'detach'):
                data_np = data.detach().cpu().numpy()
            else:
                data_np = np.array(data)
            
            # å¤„ç†objectç±»å‹
            if data_np.dtype == np.object_:
                print(f"   âš ï¸ {data_name}åŒ…å«objectç±»å‹ï¼Œè¿›è¡Œæ¸…ç†...")
                try:
                    # å°è¯•è½¬æ¢ä¸ºfloat32
                    if data_np.ndim == 1:
                        cleaned = []
                        for item in data_np:
                            try:
                                if isinstance(item, (int, float, np.integer, np.floating)):
                                    cleaned.append(float(item))
                                elif hasattr(item, 'item'):
                                    cleaned.append(float(item.item()))
                                else:
                                    cleaned.append(0.0)
                            except:
                                cleaned.append(0.0)
                        data_np = np.array(cleaned, dtype=np.float32)
                    else:
                        # å¤šç»´æ•°ç»„å±•å¹³å¤„ç†
                        original_shape = data_np.shape
                        flat_cleaned = []
                        for item in data_np.flat:
                            try:
                                if isinstance(item, (int, float, np.integer, np.floating)):
                                    flat_cleaned.append(float(item))
                                elif hasattr(item, 'item'):
                                    flat_cleaned.append(float(item.item()))
                                else:
                                    flat_cleaned.append(0.0)
                            except:
                                flat_cleaned.append(0.0)
                        data_np = np.array(flat_cleaned, dtype=np.float32).reshape(original_shape)
                    
                    print(f"   âœ… {data_name}æ¸…ç†å®Œæˆ: {data_np.shape}, dtype={data_np.dtype}")
                
                except Exception as e:
                    print(f"   âŒ {data_name}æ¸…ç†å¤±è´¥: {e}")
                    # åˆ›å»ºé›¶æ•°ç»„ä½œä¸ºå¤‡é€‰
                    if hasattr(data_np, 'shape'):
                        data_np = np.zeros(data_np.shape, dtype=np.float32)
                    else:
                        data_np = np.array([0.0], dtype=np.float32)
                    print(f"   ğŸ”„ {data_name}ä½¿ç”¨é›¶æ•°ç»„æ›¿ä»£")
            
            # ç¡®ä¿æ•°æ®ç±»å‹å…¼å®¹PyTorch
            if not data_np.dtype.kind in ['f', 'i', 'u', 'b']:  # float, int, uint, bool
                try:
                    data_np = data_np.astype(np.float32)
                    print(f"   ğŸ”„ {data_name}è½¬æ¢ä¸ºfloat32: {data_np.dtype}")
                except Exception as e:
                    print(f"   âŒ {data_name}ç±»å‹è½¬æ¢å¤±è´¥: {e}")
                    data_np = np.zeros_like(data_np, dtype=np.float32)
            
            return data_np
        
        # æ¸…ç†æ‰€æœ‰æ•°æ®
        vin_1 = clean_data_for_torch(vin_1, "vin_1")
        vin_2 = clean_data_for_torch(vin_2, "vin_2")
        vin_3 = clean_data_for_torch(vin_3, "vin_3")
        
        # targetsç‰¹æ®Šå¤„ç†
        if isinstance(targets, dict):
            # ä¿æŒå­—å…¸æ ¼å¼ä½†æ¸…ç†å†…éƒ¨æ•°æ®
            cleaned_targets = {}
            for key, value in targets.items():
                cleaned_targets[key] = clean_data_for_torch(value, f"targets['{key}']")
            targets = cleaned_targets
        else:
            targets = clean_data_for_torch(targets, "targets")
        
        return {
            'vin_1': vin_1,
            'vin_2': vin_2, 
            'vin_3': vin_3,
            'targets': targets,
            'sample_id': sample_id
        }
    except Exception as e:
        print(f"   âŒ åŠ è½½æ ·æœ¬ {sample_id} å¤±è´¥: {e}")
        return None

def verify_sample_exists(sample_id):
    """éªŒè¯æ ·æœ¬æ˜¯å¦å­˜åœ¨"""
    base_path = '/mnt/bz25t/bzhy/zhanglikang/project/QAS'
    sample_path = f"{base_path}/{sample_id}"
    
    required_files = ['vin_1.pkl', 'vin_2.pkl', 'vin_3.pkl', 'targets.pkl']
    for file_name in required_files:
        file_path = f"{sample_path}/{file_name}"
        if not os.path.exists(file_path):
            return False
    return True

def filter_existing_samples(sample_ids, sample_type="æ ·æœ¬"):
    """è¿‡æ»¤å‡ºå®é™…å­˜åœ¨çš„æ ·æœ¬"""
    print(f"ğŸ” éªŒè¯{sample_type}æ˜¯å¦å­˜åœ¨...")
    existing_samples = []
    
    for sample_id in sample_ids:
        if verify_sample_exists(sample_id):
            existing_samples.append(sample_id)
    
    print(f"   åŸå§‹{sample_type}: {len(sample_ids)}ä¸ª")
    print(f"   å­˜åœ¨çš„{sample_type}: {len(existing_samples)}ä¸ª")
    
    if len(existing_samples) < len(sample_ids):
        missing_samples = set(sample_ids) - set(existing_samples)
        print(f"   ç¼ºå¤±{sample_type}: {list(missing_samples)}")
    
    return existing_samples

def load_training_data(sample_ids):
    """åŠ è½½è®­ç»ƒæ•°æ®"""
    print(f"\nğŸ“Š åŠ è½½è®­ç»ƒæ•°æ® ({len(sample_ids)}ä¸ªæ ·æœ¬)...")
    
    all_vin1, all_targets = [], []
    successful_samples = []
    
    for sample_id in tqdm(sample_ids, desc="åŠ è½½è®­ç»ƒæ ·æœ¬"):
        data = load_sample_data(sample_id, 'train')
        if data is not None:
            # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
            if (check_data_validity(data['vin_1'], f"æ ·æœ¬{sample_id}_vin1") and 
                check_data_validity(data['targets'], f"æ ·æœ¬{sample_id}_targets")):
                all_vin1.append(data['vin_1'])
                all_targets.append(data['targets'])
                successful_samples.append(sample_id)
            else:
                print(f"   âš ï¸ æ ·æœ¬{sample_id}æ•°æ®æ— æ•ˆï¼Œè·³è¿‡")
    
    if not all_vin1:
        raise ValueError("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•è®­ç»ƒæ ·æœ¬ï¼")
    
    # åˆå¹¶æ•°æ® - å¤„ç†tensorã€numpyå’Œobjectç±»å‹æ··åˆæƒ…å†µ
    processed_vin1 = []
    processed_targets = []
    
    def safe_convert_to_numpy(data, data_name):
        """å®‰å…¨è½¬æ¢æ•°æ®ä¸ºnumpyï¼Œå¤„ç†å„ç§ç±»å‹é—®é¢˜"""
        if data is None:
            return None
        
        # è½¬æ¢tensorä¸ºnumpy
        if hasattr(data, 'detach'):
            data = data.detach().cpu().numpy()
        
        # ç¡®ä¿æ˜¯numpyæ•°ç»„
        if not isinstance(data, np.ndarray):
            try:
                data = np.array(data)
            except Exception as e:
                print(f"   âš ï¸ {data_name}è½¬æ¢ä¸ºæ•°ç»„å¤±è´¥: {e}")
                return None
        
        # å¤„ç†objectç±»å‹
        if data.dtype == np.object_:
            print(f"   âš ï¸ {data_name}åŒ…å«objectç±»å‹ï¼Œè¿›è¡Œä¿®å¤...")
            try:
                # å±•å¹³å¹¶æ¸…ç†
                flat_data = []
                for item in data.flat:
                    try:
                        if isinstance(item, (int, float, np.integer, np.floating)):
                            flat_data.append(float(item))
                        elif hasattr(item, 'item'):
                            flat_data.append(float(item.item()))
                        else:
                            flat_data.append(0.0)
                    except:
                        flat_data.append(0.0)
                
                # é‡å¡‘ä¸ºåŸå§‹å½¢çŠ¶
                data = np.array(flat_data, dtype=np.float32).reshape(data.shape)
                print(f"   âœ… {data_name}objectç±»å‹ä¿®å¤å®Œæˆ")
            
            except Exception as e:
                print(f"   âŒ {data_name}objectä¿®å¤å¤±è´¥: {e}")
                # åˆ›å»ºé›¶æ•°ç»„æ›¿ä»£
                data = np.zeros(data.shape, dtype=np.float32)
                print(f"   ğŸ”„ {data_name}ä½¿ç”¨é›¶æ•°ç»„æ›¿ä»£")
        
        # ç¡®ä¿æ•°æ®ç±»å‹å…¼å®¹
        if data.dtype.kind not in ['f', 'i', 'u', 'b']:
            try:
                data = data.astype(np.float32)
            except Exception as e:
                print(f"   âŒ {data_name}ç±»å‹è½¬æ¢å¤±è´¥: {e}")
                data = np.zeros_like(data, dtype=np.float32)
        
        return data
    
    for i, (vin1, targets) in enumerate(zip(all_vin1, all_targets)):
        # å®‰å…¨è½¬æ¢æ•°æ®
        vin1_converted = safe_convert_to_numpy(vin1, f"æ ·æœ¬{i}_vin1")
        
        # targetsç‰¹æ®Šå¤„ç†
        if isinstance(targets, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼Œéœ€è¦æå–æˆ–è½¬æ¢
            if 'terminal_voltages' in targets and 'pack_socs' in targets:
                # æ ‡å‡†æ ¼å¼ï¼Œåˆå¹¶ç”µå‹å’ŒSOC
                try:
                    voltages = safe_convert_to_numpy(targets['terminal_voltages'], f"æ ·æœ¬{i}_voltages")
                    socs = safe_convert_to_numpy(targets['pack_socs'], f"æ ·æœ¬{i}_socs")
                    
                    if voltages is not None and socs is not None:
                        # åˆå¹¶ä¸º2åˆ—ï¼š[ç”µå‹, SOC]
                        min_len = min(len(voltages), len(socs))
                        targets_converted = np.column_stack([voltages[:min_len], socs[:min_len]])
                    else:
                        print(f"   âš ï¸ æ ·æœ¬{i}çš„targetså­—å…¸æ•°æ®æ— æ•ˆï¼Œè·³è¿‡")
                        continue
                except Exception as e:
                    print(f"   âŒ æ ·æœ¬{i}çš„targetså­—å…¸å¤„ç†å¤±è´¥: {e}")
                    continue
            else:
                print(f"   âš ï¸ æ ·æœ¬{i}çš„targetså­—å…¸æ ¼å¼æœªçŸ¥ï¼Œè·³è¿‡")
                continue
        else:
            targets_converted = safe_convert_to_numpy(targets, f"æ ·æœ¬{i}_targets")
        
        if vin1_converted is not None and targets_converted is not None:
            processed_vin1.append(vin1_converted)
            processed_targets.append(targets_converted)
        else:
            print(f"   âš ï¸ æ ·æœ¬{i}æ•°æ®è½¬æ¢å¤±è´¥ï¼Œè·³è¿‡")
    
    try:
        vin1_combined = np.vstack(processed_vin1)
        targets_combined = np.vstack(processed_targets)
    except ValueError as e:
        print(f"   âš ï¸ æ•°æ®å½¢çŠ¶ä¸åŒ¹é…ï¼Œå°è¯•é€ä¸€æ£€æŸ¥...")
        # æ£€æŸ¥æ¯ä¸ªæ•°æ®çš„å½¢çŠ¶
        for i, (vin1, targets) in enumerate(zip(processed_vin1, processed_targets)):
            print(f"   æ ·æœ¬{i}: vin1 {vin1.shape}, targets {targets.shape}")
        
        # å°è¯•ä½¿ç”¨concatenate
        vin1_combined = np.concatenate(processed_vin1, axis=0)
        targets_combined = np.concatenate(processed_targets, axis=0)
    
    print(f"   âœ… æˆåŠŸåŠ è½½ {len(successful_samples)} ä¸ªæ ·æœ¬")
    print(f"   æ•°æ®å½¢çŠ¶: vin1 {vin1_combined.shape}, targets {targets_combined.shape}")
    
    return vin1_combined, targets_combined, successful_samples

def load_feedback_data(sample_ids, data_type='feedback'):
    """åŠ è½½åé¦ˆæ•°æ®"""
    print(f"\nğŸ“Š åŠ è½½{data_type}æ•°æ® ({len(sample_ids)}ä¸ªæ ·æœ¬)...")
    
    all_data = []
    successful_samples = []
    
    for sample_id in tqdm(sample_ids, desc=f"åŠ è½½{data_type}æ ·æœ¬"):
        # åé¦ˆæ ·æœ¬ä»QASç›®å½•åŠ è½½
        data = load_sample_data(sample_id, 'feedback')
        if data is not None:
            all_data.append(data)
            successful_samples.append(sample_id)
    
    print(f"   âœ… æˆåŠŸåŠ è½½ {len(successful_samples)} ä¸ª{data_type}æ ·æœ¬")
    return all_data, successful_samples

#=================================== æ•°æ®é›†ç±» ===================================

class TransformerDataset(Dataset):
    """Transformerè®­ç»ƒæ•°æ®é›†"""
    
    def __init__(self, vin1_data, targets_data):
        # ç¡®ä¿è¾“å…¥æ•°æ®æ˜¯2Dçš„
        if isinstance(vin1_data, np.ndarray):
            if vin1_data.ndim == 1:
                vin1_data = vin1_data.reshape(1, -1)  # [features] -> [1, features]
            elif vin1_data.ndim > 2:
                vin1_data = vin1_data.reshape(vin1_data.shape[0], -1)  # å±•å¹³åˆ°2D
        
        if isinstance(targets_data, np.ndarray):
            if targets_data.ndim == 1:
                targets_data = targets_data.reshape(1, -1)  # [features] -> [1, features]
            elif targets_data.ndim > 2:
                targets_data = targets_data.reshape(targets_data.shape[0], -1)  # å±•å¹³åˆ°2D
        
        print(f"   ğŸ“Š Datasetè¾“å…¥å½¢çŠ¶: vin1 {np.array(vin1_data).shape}, targets {np.array(targets_data).shape}")
        
        self.vin1_data = torch.FloatTensor(vin1_data)
        self.targets_data = torch.FloatTensor(targets_data)
        
        print(f"   ğŸ“Š Dataset tensorå½¢çŠ¶: vin1 {self.vin1_data.shape}, targets {self.targets_data.shape}")
        
        # æ•°æ®å¤„ç†
        self.vin1_data = physics_based_data_processing_silent(self.vin1_data, 'general')
        self.targets_data = physics_based_data_processing_silent(self.targets_data, 'general')
    
    def __len__(self):
        return len(self.vin1_data)
    
    def __getitem__(self, idx):
        return self.vin1_data[idx], self.targets_data[idx]

class MCDataset(Dataset):
    """MC-AEè®­ç»ƒæ•°æ®é›†"""
    
    def __init__(self, x, y, z, q):
        self.x = torch.FloatTensor(x)
        self.y = torch.FloatTensor(y) 
        self.z = torch.FloatTensor(z)
        self.q = torch.FloatTensor(q)
    
    def __len__(self):
        return len(self.x)
    
    def __getitem__(self, idx):
        return self.x[idx], self.y[idx], self.z[idx], self.q[idx]

#=================================== è¯„ä¼°å‡½æ•° ===================================

def evaluate_mcae_discrimination(mcae_model, normal_data, fault_data, device):
    """è¯„ä¼°MC-AEçš„åŒºåˆ†èƒ½åŠ›"""
    mcae_model.eval()
    
    normal_errors, fault_errors = [], []
    
    with torch.no_grad():
        # æ­£å¸¸æ ·æœ¬é‡æ„è¯¯å·®
        for data in normal_data:
            x, y = data[:2], data[2:]
            x, y = x.to(device), y.to(device)
            
            recon_x, recon_y = mcae_model(x, y)
            error = F.mse_loss(torch.cat([recon_x, recon_y], dim=1), 
                              torch.cat([x, y], dim=1), reduction='none').mean(dim=1)
            normal_errors.extend(error.cpu().numpy())
        
        # æ•…éšœæ ·æœ¬é‡æ„è¯¯å·®
        for data in fault_data:
            x, y = data[:2], data[2:]
            x, y = x.to(device), y.to(device)
            
            recon_x, recon_y = mcae_model(x, y)
            error = F.mse_loss(torch.cat([recon_x, recon_y], dim=1),
                              torch.cat([x, y], dim=1), reduction='none').mean(dim=1)
            fault_errors.extend(error.cpu().numpy())
    
    normal_errors = np.array(normal_errors)
    fault_errors = np.array(fault_errors)
    
    # è®¡ç®—åˆ†ç¦»åº¦æŒ‡æ ‡
    normal_mean = np.mean(normal_errors)
    fault_mean = np.mean(fault_errors)
    separation = (fault_mean - normal_mean) / (np.std(normal_errors) + np.std(fault_errors) + 1e-8)
    
    return {
        'normal_mean': normal_mean,
        'fault_mean': fault_mean,
        'separation': separation,
        'normal_errors': normal_errors,
        'fault_errors': fault_errors
    }

#=================================== æŠ¥å‘Šç”Ÿæˆå‡½æ•° ===================================

def generate_training_report(config, results_summary, transformer_losses, net_losses, netx_losses, 
                           normal_samples, fault_samples, n_components, FAI, T2_99_limit, SPE_99_limit):
    """ç”Ÿæˆè¯¦ç»†çš„è®­ç»ƒæŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰"""
    
    # è·å–å½“å‰æ—¶é—´
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # æ„å»ºæŠ¥å‘Šå†…å®¹
    report_content = f"""# æ­£è´Ÿåé¦ˆæ··åˆè®­ç»ƒæŠ¥å‘Š

## ğŸ“Š è®­ç»ƒæ¦‚è§ˆ

**è®­ç»ƒæ—¶é—´**: {current_time}  
**è®­ç»ƒç±»å‹**: æ­£è´Ÿåé¦ˆæ··åˆTransformerè®­ç»ƒ  
**è®¾å¤‡**: {config['device']}  

---

## ğŸ¯ è®­ç»ƒç›®æ ‡

æœ¬æ¬¡è®­ç»ƒé‡‡ç”¨æ­£è´Ÿåé¦ˆæ··åˆç­–ç•¥ï¼Œæ—¨åœ¨ï¼š
- æé«˜ç”µæ± æ•…éšœæ£€æµ‹çš„å‡†ç¡®æ€§
- é™ä½å‡é˜³æ€§ç‡ï¼ˆæ­£åé¦ˆä¼˜åŒ–ï¼‰
- å¢å¼ºæ•…éšœæ ·æœ¬åŒºåˆ†åº¦ï¼ˆè´Ÿåé¦ˆä¼˜åŒ–ï¼‰
- å®ç°Transformerä¸MC-AEçš„ååŒä¼˜åŒ–

---

## ğŸ“‹ æ ·æœ¬é…ç½®

### æ ·æœ¬æ¥æº
- **æ ‡ç­¾æ–‡ä»¶**: `/mnt/bz25t/bzhy/zhanglikang/project/QAS/Labels.xls`
- **æ•°æ®è·¯å¾„**: `/mnt/bz25t/bzhy/zhanglikang/project/QAS/`

### æ ·æœ¬åˆ†å¸ƒ
- **æ€»æ­£å¸¸æ ·æœ¬**: {len(normal_samples)} ä¸ª (Label=0)
- **æ€»æ•…éšœæ ·æœ¬**: {len(fault_samples)} ä¸ª (Label=1)

### è®­ç»ƒæ ·æœ¬é…ç½®
| æ ·æœ¬ç±»å‹ | æ•°é‡ | ç”¨é€” | æ ·æœ¬æ ‡ç­¾ |
|---------|------|------|----------|
| åŸºç¡€è®­ç»ƒæ ·æœ¬ | {len(results_summary['sample_info']['used_train_samples'])} | TransformeråŸºç¡€è®­ç»ƒ | æ­£å¸¸æ ·æœ¬ (Label=0) |
| æ­£åé¦ˆæ ·æœ¬ | {len(results_summary['sample_info']['used_positive_samples'])} | é™ä½å‡é˜³æ€§ç‡ | æ­£å¸¸æ ·æœ¬ (Label=0) |
| è´Ÿåé¦ˆæ ·æœ¬ | {len(results_summary['sample_info']['used_negative_samples'])} | å¢å¼ºåŒºåˆ†åº¦ | æ•…éšœæ ·æœ¬ (Label=1) |

### ä½¿ç”¨çš„æ ·æœ¬ç¼–å·
**è®­ç»ƒæ ·æœ¬**: {', '.join(results_summary['sample_info']['used_train_samples'][:10])}{'...' if len(results_summary['sample_info']['used_train_samples']) > 10 else ''}  
**æ­£åé¦ˆæ ·æœ¬**: {', '.join(results_summary['sample_info']['used_positive_samples'])}  
**è´Ÿåé¦ˆæ ·æœ¬**: {', '.join(results_summary['sample_info']['used_negative_samples'])}  

---

## âš™ï¸ æ¨¡å‹æ¶æ„

### Transformeré¢„æµ‹å™¨
- **è¾“å…¥ç»´åº¦**: 7
- **éšè—ç»´åº¦**: 128
- **æ³¨æ„åŠ›å¤´æ•°**: 8
- **ç¼–ç å™¨å±‚æ•°**: 3
- **è¾“å‡ºç»´åº¦**: 2 (ç”µå‹é¢„æµ‹ + SOCé¢„æµ‹)

### MC-AEè‡ªç¼–ç å™¨
- **MC-AE1 (ç”µå‹)**: è¾“å…¥ç»´åº¦ 2 â†’ è¾“å‡ºç»´åº¦ 110
- **MC-AE2 (SOC)**: è¾“å…¥ç»´åº¦ 2 â†’ è¾“å‡ºç»´åº¦ 110
- **æ¿€æ´»å‡½æ•°**: MC-AE1ä½¿ç”¨custom_activationï¼ŒMC-AE2ä½¿ç”¨sigmoid

---

## ğŸ”§ è®­ç»ƒå‚æ•°

### åŸºç¡€å‚æ•°
- **æ‰¹æ¬¡å¤§å°**: {config['batch_size']}
- **å­¦ä¹ ç‡**: {config['learning_rate']}
- **ä¼˜åŒ–å™¨**: Adam

### è®­ç»ƒé˜¶æ®µé…ç½®
| é˜¶æ®µ | è½®æ¬¡ | æè¿° |
|------|------|------|
| Phase 1 | {config['training_phases']['phase1_transformer']['epochs']} | TransformeråŸºç¡€è®­ç»ƒ |
| Phase 2 | {config['training_phases']['phase2_mcae']['epochs']} | MC-AEè®­ç»ƒ(ä½¿ç”¨Transformerå¢å¼ºæ•°æ®) |
| Phase 3 | {config['training_phases']['phase3_feedback']['epochs']} | æ­£è´Ÿåé¦ˆæ··åˆä¼˜åŒ– |

### æ­£åé¦ˆé…ç½®
- **å¯ç”¨çŠ¶æ€**: {config['positive_feedback']['enable']}
- **æƒé‡**: {config['positive_feedback']['weight']}
- **å¼€å§‹è½®æ¬¡**: {config['positive_feedback']['start_epoch']}
- **è¯„ä¼°é¢‘ç‡**: {config['positive_feedback']['frequency']}
- **ç›®æ ‡å‡é˜³æ€§ç‡**: {config['positive_feedback']['target_fpr']}

### è´Ÿåé¦ˆé…ç½®
- **å¯ç”¨çŠ¶æ€**: {config['negative_feedback']['enable']}
- **æ­£å¸¸æ ·æœ¬æƒé‡**: {config['negative_feedback']['alpha']}
- **æ•…éšœæ ·æœ¬æƒé‡**: {config['negative_feedback']['beta']}
- **å¯¹æ¯”è¾¹ç•Œ**: {config['negative_feedback']['margin']}
- **å¼€å§‹è½®æ¬¡**: {config['negative_feedback']['start_epoch']}

---

## ğŸ“ˆ è®­ç»ƒç»“æœ

### æŸå¤±å‡½æ•°æ”¶æ•›æƒ…å†µ
- **Transformeræœ€ç»ˆæŸå¤±**: {results_summary['training_results']['transformer_final_loss']:.6f}
- **MC-AE1æœ€ç»ˆæŸå¤±**: {results_summary['training_results']['mcae1_final_loss']:.6f}
- **MC-AE2æœ€ç»ˆæŸå¤±**: {results_summary['training_results']['mcae2_final_loss']:.6f}

### æŸå¤±å˜åŒ–è¶‹åŠ¿
**TransformeræŸå¤±**:
- åˆå§‹æŸå¤±: {transformer_losses[0]:.6f}
- æœ€ç»ˆæŸå¤±: {transformer_losses[-1]:.6f}
- é™å¹…: {((transformer_losses[0] - transformer_losses[-1]) / transformer_losses[0] * 100):.2f}%

**MC-AEæŸå¤±**:
- MC-AE1 åˆå§‹â†’æœ€ç»ˆ: {net_losses[0]:.6f} â†’ {net_losses[-1]:.6f} (é™å¹…: {((net_losses[0] - net_losses[-1]) / net_losses[0] * 100):.2f}%)
- MC-AE2 åˆå§‹â†’æœ€ç»ˆ: {netx_losses[0]:.6f} â†’ {netx_losses[-1]:.6f} (é™å¹…: {((netx_losses[0] - netx_losses[-1]) / netx_losses[0] * 100):.2f}%)

---

## ğŸ”¬ PCAåˆ†æç»“æœ

### ä¸»æˆåˆ†åˆ†æ
- **é€‰æ‹©çš„ä¸»æˆåˆ†æ•°é‡**: {n_components}
- **ç´¯è®¡æ–¹å·®è§£é‡Šæ¯”ä¾‹**: â‰¥ 90%

### æ§åˆ¶é™è®¾å®š
- **TÂ²-99%æ§åˆ¶é™**: {T2_99_limit:.4f}
- **SPE-99%æ§åˆ¶é™**: {SPE_99_limit:.4f}

### æ•…éšœæŒ‡æ ‡(FAI)ç»Ÿè®¡
- **FAIå‡å€¼**: {results_summary['training_results']['fai_mean']:.4f}
- **FAIæ ‡å‡†å·®**: {results_summary['training_results']['fai_std']:.4f}
- **FAIèŒƒå›´**: [{np.min(FAI):.4f}, {np.max(FAI):.4f}]
- **å¼‚å¸¸æ ·æœ¬æ¯”ä¾‹**: {(np.sum(FAI > 1.0) / len(FAI) * 100):.2f}% (FAI > 1.0)

---

## ğŸ’¾ è¾“å‡ºæ–‡ä»¶

### æ¨¡å‹æ–‡ä»¶
- **Transformeræ¨¡å‹**: `transformer_model_pn.pth`
- **MC-AE1æ¨¡å‹**: `net_model_pn.pth`
- **MC-AE2æ¨¡å‹**: `netx_model_pn.pth`

### å‚æ•°æ–‡ä»¶
- **PCAå‚æ•°**: `pca_params_pn.pkl`
- **è®­ç»ƒé…ç½®**: `training_summary_pn.json`

### å¯è§†åŒ–æ–‡ä»¶
- **è®­ç»ƒç»“æœå›¾**: `pn_training_results.png`
- **è®­ç»ƒæŠ¥å‘Š**: `training_report_pn.md` (æœ¬æ–‡ä»¶)

---

## ğŸ¯ æ··åˆåé¦ˆç­–ç•¥

### æ•°æ®å¢å¼ºç­–ç•¥
æœ¬æ¬¡è®­ç»ƒé‡‡ç”¨äº†åˆ›æ–°çš„æ··åˆåé¦ˆæ•°æ®å¢å¼ºç­–ç•¥ï¼š

1. **Transformeré¢„æµ‹æ›¿æ¢**: ç”¨è®­ç»ƒå¥½çš„Transformeré¢„æµ‹å€¼æ›¿æ¢åŸå§‹æ•°æ®ä¸­çš„BiLSTMé¢„æµ‹éƒ¨åˆ†
   - `vin2_modified[:, 0] = transformer_predictions[:, 0]` (ç”µå‹é¢„æµ‹)
   - `vin3_modified[:, 0] = transformer_predictions[:, 1]` (SOCé¢„æµ‹)

2. **Packå»ºæ¨¡ç‰¹å¾ä¿æŒ**: ä¿æŒåŸå§‹Packå»ºæ¨¡ç‰¹å¾ä¸å˜
   - `vin2_modified[:, 1:]` å’Œ `vin3_modified[:, 1:]` ä¿æŒåŸå€¼

3. **æ—¶é—´åºåˆ—å¯¹åº”å…³ç³»**:
   - kæ—¶åˆ»è¾“å…¥æ•°æ® â†’ k+1æ—¶åˆ»é¢„æµ‹è¾“å‡º
   - ç¡®ä¿æ—¶é—´åºåˆ—çš„å› æœå…³ç³»æ­£ç¡®

### æ­£åé¦ˆä¼˜åŒ–
- ä½¿ç”¨é¢å¤–çš„æ­£å¸¸æ ·æœ¬è¿›è¡Œæ¨¡å‹å¾®è°ƒ
- ç›®æ ‡ï¼šé™ä½å‡é˜³æ€§ç‡è‡³{config['positive_feedback']['target_fpr']}ä»¥ä¸‹
- ç­–ç•¥ï¼šå¢å¼ºæ¨¡å‹å¯¹æ­£å¸¸æ ·æœ¬çš„è¯†åˆ«èƒ½åŠ›

### è´Ÿåé¦ˆä¼˜åŒ–  
- ä½¿ç”¨æ•…éšœæ ·æœ¬è¿›è¡Œå¯¹æ¯”å­¦ä¹ 
- ç›®æ ‡ï¼šå¢å¤§æ­£å¸¸æ ·æœ¬ä¸æ•…éšœæ ·æœ¬çš„åŒºåˆ†åº¦
- ç­–ç•¥ï¼šé‡‡ç”¨å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ•…éšœæ ·æœ¬æœ‰æ›´é«˜çš„é‡æ„è¯¯å·®

---

## ğŸ“Š æ€§èƒ½è¯„ä¼°

### è®­ç»ƒç¨³å®šæ€§
- **æ”¶æ•›æ€§**: {'è‰¯å¥½' if transformer_losses[-1] < transformer_losses[0] * 0.1 else 'ä¸€èˆ¬'}
- **æŸå¤±æ³¢åŠ¨**: {'ç¨³å®š' if np.std(transformer_losses[-10:]) < 0.001 else 'æœ‰æ³¢åŠ¨'}

### æ¨¡å‹å¤æ‚åº¦
- **æ€»è®­ç»ƒè½®æ¬¡**: {config['training_phases']['phase1_transformer']['epochs'] + config['training_phases']['phase2_mcae']['epochs']} è½®

---

## âœ… è®­ç»ƒæ€»ç»“

### æˆåŠŸæŒ‡æ ‡
- âœ… æ‰€æœ‰è®­ç»ƒé˜¶æ®µé¡ºåˆ©å®Œæˆ
- âœ… æŸå¤±å‡½æ•°æˆåŠŸæ”¶æ•›
- âœ… PCAåˆ†æç»“æœåˆç†
- âœ… æ··åˆåé¦ˆç­–ç•¥æˆåŠŸå®æ–½
- âœ… æ¨¡å‹æ–‡ä»¶æˆåŠŸä¿å­˜

### å…³é”®æˆæœ
1. **æ¨¡å‹èåˆ**: æˆåŠŸå®ç°Transformerä¸MC-AEçš„ååŒè®­ç»ƒ
2. **æ•°æ®å¢å¼º**: é€šè¿‡æ··åˆåé¦ˆç­–ç•¥æå‡äº†æ•°æ®è´¨é‡
3. **æ€§èƒ½ä¼˜åŒ–**: æ­£è´Ÿåé¦ˆæœºåˆ¶æœ‰æ•ˆæ”¹å–„äº†æ¨¡å‹æ€§èƒ½
4. **å¯è§£é‡Šæ€§**: PCAåˆ†ææä¾›äº†æ¸…æ™°çš„æ•…éšœæ£€æµ‹é˜ˆå€¼

### å»ºè®®ä¸å±•æœ›
1. **æ¨¡å‹éƒ¨ç½²**: å¯ç›´æ¥ç”¨äºç”µæ± æ•…éšœæ£€æµ‹ç³»ç»Ÿ
2. **æŒç»­ä¼˜åŒ–**: å¯æ ¹æ®å®é™…åº”ç”¨æ•ˆæœè°ƒæ•´æ­£è´Ÿåé¦ˆå‚æ•°
3. **æ‰©å±•åº”ç”¨**: å¯æ¨å¹¿åˆ°å…¶ä»–æ—¶åºæ•…éšœæ£€æµ‹åœºæ™¯

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {current_time}  
**ç”Ÿæˆå·¥å…·**: æ­£è´Ÿåé¦ˆæ··åˆè®­ç»ƒç³»ç»Ÿ v1.0  
**æŠ€æœ¯æ”¯æŒ**: åŸºäºPyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶  

---
*æœ¬æŠ¥å‘Šç”±ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼Œè¯¦ç»†è®°å½•äº†æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„å‚æ•°é…ç½®ã€è®­ç»ƒç»“æœå’Œå…³é”®æŒ‡æ ‡ã€‚*
"""
    
    return report_content

#=================================== ä¸»è®­ç»ƒå‡½æ•° ===================================

def main():
    """Main training function"""
    print("="*80)
    print("Starting Positive-Negative Hybrid Feedback Training")
    print("="*80)
    
    config = PN_HYBRID_FEEDBACK_CONFIG
    
    # Setup fonts
    setup_fonts()
    
    #=== Stage 1: Load training data ===
    print("\n" + "="*50)
    print("Stage 1: Data Loading")
    print("="*50)
    
    # Filter existing samples
    existing_train_samples = filter_existing_samples(config['train_samples'], "train samples")
    existing_positive_samples = filter_existing_samples(config['positive_feedback_samples'], "positive feedback samples")
    existing_negative_samples = filter_existing_samples(config['negative_feedback_samples'], "negative feedback samples")
    
    # Ensure sufficient samples for training
    if len(existing_train_samples) < 10:
        print(f"ERROR: Insufficient training samples, only {len(existing_train_samples)}, recommend at least 10")
        return
    
    # åŠ è½½åŸºç¡€è®­ç»ƒæ•°æ®
    train_vin1, train_targets, successful_train = load_training_data(existing_train_samples)
    
    # åŠ è½½æ­£åé¦ˆæ•°æ®
    positive_data, successful_positive = load_feedback_data(
        existing_positive_samples, 'æ­£åé¦ˆ'
    )
    
    # åŠ è½½è´Ÿåé¦ˆæ•°æ®  
    negative_data, successful_negative = load_feedback_data(
        existing_negative_samples, 'è´Ÿåé¦ˆ'
    )
    
    print(f"\nğŸ“ˆ æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"   è®­ç»ƒæ ·æœ¬: {len(successful_train)} ä¸ª")
    print(f"   æ­£åé¦ˆæ ·æœ¬: {len(successful_positive)} ä¸ª") 
    print(f"   è´Ÿåé¦ˆæ ·æœ¬: {len(successful_negative)} ä¸ª")
    
    #=== ç¬¬2é˜¶æ®µ: TransformeråŸºç¡€è®­ç»ƒ ===
    print("\n" + "="*50)
    print("ğŸ¤– ç¬¬2é˜¶æ®µ: TransformeråŸºç¡€è®­ç»ƒ")
    print("="*50)
    
    # æ•°æ®ç»´åº¦éªŒè¯å’Œä¿®æ­£
    print(f"   ğŸ“Š åŸå§‹æ•°æ®å½¢çŠ¶: train_vin1 {train_vin1.shape}, train_targets {train_targets.shape}")
    
    # ç¡®ä¿æ•°æ®è‡³å°‘æ˜¯2D
    if train_vin1.ndim == 1:
        train_vin1 = train_vin1.reshape(1, -1)
        print(f"   ğŸ”„ ä¿®æ­£vin1å½¢çŠ¶ä¸º: {train_vin1.shape}")
    
    if train_targets.ndim == 1:
        train_targets = train_targets.reshape(1, -1)
        print(f"   ğŸ”„ ä¿®æ­£targetså½¢çŠ¶ä¸º: {train_targets.shape}")
    
    # æ•°æ®ç»´åº¦é—®é¢˜è¯Šæ–­å’Œä¿®æ­£
    print(f"   ğŸ” è¯¦ç»†åˆ†ææ•°æ®ç»´åº¦:")
    print(f"      train_vin1.shape = {train_vin1.shape}")
    print(f"      train_targets.shape = {train_targets.shape}")
    
    # ä»é”™è¯¯ä¿¡æ¯çœ‹ï¼Œæ•°æ®ç»´åº¦éœ€è¦é‡æ–°ç†è§£
    # é”™è¯¯æ˜¾ç¤º: (512x7 and 1x128) - è¯´æ˜è¾“å…¥æ˜¯512ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬7ä¸ªç‰¹å¾
    # ä½†å½“å‰å½¢çŠ¶å¯èƒ½æ˜¯ (3417341, 7) - è¯´æ˜æ ·æœ¬æ•°è¿‡å¤šï¼Œç‰¹å¾æ•°æ˜¯7
    
    # 4å¼ A100 GPUé›†ç¾¤ - å…¨æ•°æ®é›†è®­ç»ƒé…ç½®
    print(f"   ğŸš€ 4Ã—A100 GPUé›†ç¾¤ç¯å¢ƒï¼Œä½¿ç”¨å…¨æ•°æ®é›†è®­ç»ƒ")
    print(f"   ğŸ“Š åŸå§‹æ ·æœ¬æ•°: {train_vin1.shape[0]:,}")
    print(f"   ğŸ’¡ ä½¿ç”¨å…¨éƒ¨æ ·æœ¬è¿›è¡Œå¤§è§„æ¨¡è®­ç»ƒï¼Œå……åˆ†åˆ©ç”¨GPUé›†ç¾¤æ€§èƒ½")
    print(f"   ğŸ“ˆ é¢„è®¡æ‰¹æ¬¡æ•°é‡: {train_vin1.shape[0] // config['batch_size']:,} batches/epoch")
    
    # æ˜¾ç¤ºGPUé›†ç¾¤é…ç½®
    if torch.cuda.device_count() >= 2:
        print(f"   ğŸ”¥ æ£€æµ‹åˆ°{torch.cuda.device_count()}å¼ GPUï¼Œå¯ç”¨æ•°æ®å¹¶è¡Œè®­ç»ƒ")
        for i in range(min(torch.cuda.device_count(), 2)):  # ä½¿ç”¨GPU0å’ŒGPU1
            print(f"      GPU{i}: {torch.cuda.get_device_name(i)}")
    else:
        print(f"   âš ï¸ ä»…æ£€æµ‹åˆ°{torch.cuda.device_count()}å¼ GPU")
    
    # æ˜¾ç¤ºå†…å­˜é¢„ä¼°
    memory_per_sample_mb = 7 * 4 / (1024*1024)  # 7ä¸ªfloat32ç‰¹å¾
    estimated_memory_mb = train_vin1.shape[0] * memory_per_sample_mb
    print(f"   ğŸ’¾ é¢„ä¼°æ•°æ®å†…å­˜ä½¿ç”¨: {estimated_memory_mb:.1f} MB")
    
    # æ ¹æ®å‚è€ƒä»£ç ï¼Œä½¿ç”¨å›ºå®šçš„æ¨¡å‹ç»´åº¦é…ç½®
    # TransformeræœŸæœ›: input_size=7, output_size=2
    model_input_size = 7
    model_output_size = 2
    
    print(f"   ğŸ“Š æ•°æ®ç»´åº¦åˆ†æ:")
    print(f"      train_vin1åŸå§‹å½¢çŠ¶: {train_vin1.shape}")
    print(f"      train_targetsåŸå§‹å½¢çŠ¶: {train_targets.shape}")
    print(f"      æ¨¡å‹æœŸæœ›: input_size={model_input_size}, output_size={model_output_size}")
    
    # è°ƒæ•´æ•°æ®ä»¥åŒ¹é…æ¨¡å‹æœŸæœ›
    # é¦–å…ˆç¡®ä¿æ•°æ®æ˜¯2Dçš„
    if train_vin1.ndim > 2:
        print(f"   ğŸ”§ å±•å¹³vin1ä»{train_vin1.shape}åˆ°2D")
        train_vin1 = train_vin1.reshape(train_vin1.shape[0], -1)
    
    if train_targets.ndim > 2:
        print(f"   ğŸ”§ å±•å¹³targetsä»{train_targets.shape}åˆ°2D")
        train_targets = train_targets.reshape(train_targets.shape[0], -1)
    
    print(f"   ğŸ“Š å±•å¹³åå½¢çŠ¶: vin1 {train_vin1.shape}, targets {train_targets.shape}")
    
    # è°ƒæ•´vin1ç‰¹å¾ç»´åº¦
    if train_vin1.shape[1] != model_input_size:
        if train_vin1.shape[1] > model_input_size:
            # æˆªå–å‰7ä¸ªç‰¹å¾
            train_vin1 = train_vin1[:, :model_input_size]
            print(f"   ğŸ”§ æˆªå–vin1å‰{model_input_size}ä¸ªç‰¹å¾: {train_vin1.shape}")
        else:
            # è¡¥é›¶åˆ°7ä¸ªç‰¹å¾
            padding_shape = (train_vin1.shape[0], model_input_size - train_vin1.shape[1])
            padding = np.zeros(padding_shape, dtype=train_vin1.dtype)
            train_vin1 = np.concatenate([train_vin1, padding], axis=1)
            print(f"   ğŸ”§ è¡¥é›¶vin1åˆ°{model_input_size}ä¸ªç‰¹å¾: {train_vin1.shape}")
    
    # è°ƒæ•´targetsè¾“å‡ºç»´åº¦
    if train_targets.shape[1] != model_output_size:
        if train_targets.shape[1] > model_output_size:
            # æˆªå–å‰2ä¸ªè¾“å‡º
            train_targets = train_targets[:, :model_output_size]
            print(f"   ğŸ”§ æˆªå–targetså‰{model_output_size}ä¸ªè¾“å‡º: {train_targets.shape}")
        else:
            # è¡¥é›¶åˆ°2ä¸ªè¾“å‡º
            padding_shape = (train_targets.shape[0], model_output_size - train_targets.shape[1])
            padding = np.zeros(padding_shape, dtype=train_targets.dtype)
            train_targets = np.concatenate([train_targets, padding], axis=1)
            print(f"   ğŸ”§ è¡¥é›¶targetsåˆ°{model_output_size}ä¸ªè¾“å‡º: {train_targets.shape}")
    
    print(f"   ğŸ“Š æœ€ç»ˆæ•°æ®å½¢çŠ¶: vin1 {train_vin1.shape}, targets {train_targets.shape}")
    print(f"   ğŸ“Š æ ·æœ¬æ•°é‡: {train_vin1.shape[0]}")
    
    # æ•°æ®è´¨é‡æ£€æŸ¥å’Œæ¸…ç†
    if np.isnan(train_vin1).any() or np.isinf(train_vin1).any():
        print(f"   âš ï¸ æ¸…ç†vin1å¼‚å¸¸å€¼...")
        train_vin1 = np.nan_to_num(train_vin1, nan=0.0, posinf=1.0, neginf=0.0)
    
    if np.isnan(train_targets).any() or np.isinf(train_targets).any():
        print(f"   âš ï¸ æ¸…ç†targetså¼‚å¸¸å€¼...")
        train_targets = np.nan_to_num(train_targets, nan=0.0, posinf=1.0, neginf=0.0)
    
    print(f"   ğŸ“ˆ vin1èŒƒå›´: [{train_vin1.min():.6f}, {train_vin1.max():.6f}]")
    print(f"   ğŸ“ˆ targetsèŒƒå›´: [{train_targets.min():.6f}, {train_targets.max():.6f}]")
    
    # åˆ›å»ºTransformeræ¨¡å‹ - ä½¿ç”¨å›ºå®šç»´åº¦
    transformer = TransformerPredictor(
        input_size=model_input_size, 
        d_model=128, 
        nhead=8, 
        num_layers=3, 
        output_size=model_output_size
    ).to(device)
    
    # å¤šGPUæ•°æ®å¹¶è¡Œæ”¯æŒ
    if torch.cuda.device_count() >= 2:
        print(f"   ğŸ”¥ å¯ç”¨DataParallelï¼Œä½¿ç”¨GPU: 0, 1")
        transformer = nn.DataParallel(transformer, device_ids=[0, 1])
        print(f"   âœ… æ•°æ®å¹¶è¡Œæ¨¡å‹åˆ›å»ºå®Œæˆï¼Œå°†åœ¨2å¼ GPUä¸Šåˆ†å¸ƒå¼è®­ç»ƒ")
    else:
        print(f"   âœ… å•GPUæ¨¡å‹åˆ›å»ºå®Œæˆ: input_size={model_input_size}, output_size={model_output_size}")
    
    # æ˜¾ç¤ºæ¨¡å‹å‚æ•°é‡
    total_params = sum(p.numel() for p in transformer.parameters())
    trainable_params = sum(p.numel() for p in transformer.parameters() if p.requires_grad)
    print(f"   ğŸ“Š æ¨¡å‹å‚æ•°é‡: {total_params:,} (å¯è®­ç»ƒ: {trainable_params:,})")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ - å¤šGPUä¼˜åŒ–
    train_dataset = TransformerDataset(train_vin1, train_targets)
    train_loader = DataLoader(
        train_dataset, 
        batch_size=config['batch_size'], 
        shuffle=True,
        num_workers=8,  # å¤šè¿›ç¨‹åŠ è½½ï¼Œå……åˆ†åˆ©ç”¨CPU
        pin_memory=True,  # åŠ é€ŸGPUä¼ è¾“
        persistent_workers=True  # ä¿æŒworkerè¿›ç¨‹ï¼Œå‡å°‘é‡å¯å¼€é”€
    )
    
    print(f"   ğŸ“Š æ•°æ®åŠ è½½å™¨é…ç½®: batch_size={config['batch_size']}, num_workers=8")
    
    # è®­ç»ƒé…ç½®
    transformer_optimizer = optim.Adam(transformer.parameters(), lr=config['learning_rate'])
    transformer_criterion = nn.MSELoss()
    transformer_scheduler = optim.lr_scheduler.StepLR(transformer_optimizer, step_size=20, gamma=0.8)
    
    # è®­ç»ƒå¾ªç¯
    transformer_losses = []
    phase1_epochs = config['training_phases']['phase1_transformer']['epochs']
    
    print(f"å¼€å§‹Transformerè®­ç»ƒ ({phase1_epochs} è½®)...")
    
    for epoch in range(phase1_epochs):
        transformer.train()
        epoch_losses = []
        
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{phase1_epochs}")
        for batch_vin1, batch_targets in pbar:
            batch_vin1 = batch_vin1.to(device)
            batch_targets = batch_targets.to(device)
            
            # æ£€æŸ¥å¹¶ä¿®å¤tensorç»´åº¦
            if batch_vin1.dim() == 1:
                batch_vin1 = batch_vin1.unsqueeze(0)  # [features] -> [1, features]
            elif batch_vin1.dim() > 2:
                # å¦‚æœç»´åº¦è¶…è¿‡2ï¼Œå±•å¹³åˆ°2D
                batch_size = batch_vin1.size(0)
                batch_vin1 = batch_vin1.view(batch_size, -1)
            
            if batch_targets.dim() == 1:
                batch_targets = batch_targets.unsqueeze(0)  # [features] -> [1, features]
            elif batch_targets.dim() > 2:
                batch_size = batch_targets.size(0)
                batch_targets = batch_targets.view(batch_size, -1)
            
            # åªåœ¨ç¬¬ä¸€ä¸ªbatchæ—¶æ‰“å°è°ƒè¯•ä¿¡æ¯
            if epoch == 0 and hasattr(pbar, 'n') and pbar.n == 0:
                print(f"   ğŸ“Š ç¬¬ä¸€ä¸ªbatchå½¢çŠ¶: batch_vin1 {batch_vin1.shape}, batch_targets {batch_targets.shape}")
            
            # å‰å‘ä¼ æ’­
            transformer_optimizer.zero_grad()
            predictions = transformer(batch_vin1)
            loss = transformer_criterion(predictions, batch_targets)
            
            # åå‘ä¼ æ’­
            loss.backward()
            torch.nn.utils.clip_grad_norm_(transformer.parameters(), max_norm=1.0)
            transformer_optimizer.step()
            
            epoch_losses.append(loss.item())
            pbar.set_postfix({'Loss': f'{loss.item():.6f}'})
        
        avg_loss = np.mean(epoch_losses)
        transformer_losses.append(avg_loss)
        transformer_scheduler.step()
        
        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch+1}: Loss={avg_loss:.6f}, LR={transformer_scheduler.get_last_lr()[0]:.6f}")
            print_gpu_memory()
    
    print("âœ… TransformeråŸºç¡€è®­ç»ƒå®Œæˆ")
    
    # ä¿å­˜Transformeræ¨¡å‹
    transformer_save_path = os.path.join(config['save_base_path'], 'transformer_model_pn.pth')
    torch.save(transformer.state_dict(), transformer_save_path)
    print(f"   æ¨¡å‹å·²ä¿å­˜: {transformer_save_path}")
    
    #=== ç¬¬3é˜¶æ®µ: ç”Ÿæˆå¢å¼ºæ•°æ®å¹¶è®­ç»ƒMC-AE ===
    print("\n" + "="*50)
    print("ğŸ”§ ç¬¬3é˜¶æ®µ: MC-AEè®­ç»ƒ(ä½¿ç”¨Transformerå¢å¼ºæ•°æ®)")
    print("="*50)
    
    # ä½¿ç”¨è®­ç»ƒå¥½çš„Transformerç”Ÿæˆé¢„æµ‹æ•°æ®
    transformer.eval()
    enhanced_vin2_data, enhanced_vin3_data = [], []
    
    print("ç”ŸæˆTransformerå¢å¼ºæ•°æ®...")
    with torch.no_grad():
        for batch_vin1, _ in tqdm(train_loader, desc="ç”Ÿæˆå¢å¼ºæ•°æ®"):
            batch_vin1 = batch_vin1.to(device)
            
            # æ£€æŸ¥å¹¶ä¿®å¤tensorç»´åº¦
            if batch_vin1.dim() == 1:
                batch_vin1 = batch_vin1.unsqueeze(0)  # [features] -> [1, features]
            elif batch_vin1.dim() > 2:
                # å¦‚æœç»´åº¦è¶…è¿‡2ï¼Œå±•å¹³åˆ°2D
                batch_size = batch_vin1.size(0)
                batch_vin1 = batch_vin1.view(batch_size, -1)
            
            predictions = transformer(batch_vin1)
            
            # åˆ†ç¦»ç”µå‹å’ŒSOCé¢„æµ‹
            volt_pred = predictions[:, 0:1]  # ç”µå‹é¢„æµ‹
            soc_pred = predictions[:, 1:2]   # SOCé¢„æµ‹
            
            enhanced_vin2_data.append(volt_pred.cpu().numpy())
            enhanced_vin3_data.append(soc_pred.cpu().numpy())
    
    # åˆå¹¶å¢å¼ºæ•°æ®
    enhanced_vin2 = np.vstack(enhanced_vin2_data)
    enhanced_vin3 = np.vstack(enhanced_vin3_data)
    
    print(f"å¢å¼ºæ•°æ®ç”Ÿæˆå®Œæˆ: vin2 {enhanced_vin2.shape}, vin3 {enhanced_vin3.shape}")
    
    # å‡†å¤‡MC-AEè®­ç»ƒæ•°æ®
    # è¿™é‡Œéœ€è¦æ ¹æ®åŸå§‹ä»£ç çš„æ•°æ®åˆ‡ç‰‡é€»è¾‘æ¥å‡†å¤‡x, y, z, qæ•°æ®
    # æš‚æ—¶ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦æ ¹æ®å…·ä½“æ•°æ®ç»“æ„è°ƒæ•´
    
    print("å‡†å¤‡MC-AEè®­ç»ƒæ•°æ®...")
    # ä»ç¬¬ä¸€ä¸ªè®­ç»ƒæ ·æœ¬è·å–æ•°æ®ç»“æ„ä¿¡æ¯
    sample_data = load_sample_data(successful_train[0], 'train')
    vin_2_sample = sample_data['vin_2']
    vin_3_sample = sample_data['vin_3']
    
    print(f"æ ·æœ¬æ•°æ®å½¢çŠ¶: vin_2 {vin_2_sample.shape}, vin_3 {vin_3_sample.shape}")
    
    # æ•°æ®ç»´åº¦ä¿¡æ¯ï¼ˆæ ¹æ®æºä»£ç è®¾å®šï¼‰
    dim_x, dim_y, dim_z, dim_q = 2, 110, 110, 3
    dim_x2, dim_y2, dim_z2, dim_q2 = 2, 110, 110, 4
    
    # è½¬æ¢ä¸ºnumpyæ ¼å¼
    if hasattr(vin_2_sample, 'detach'):
        vin_2_sample = vin_2_sample.detach().cpu().numpy()
    else:
        vin_2_sample = np.array(vin_2_sample)
    
    if hasattr(vin_3_sample, 'detach'):
        vin_3_sample = vin_3_sample.detach().cpu().numpy()
    else:
        vin_3_sample = np.array(vin_3_sample)
    
    # æ£€æŸ¥æ•°æ®ç»´åº¦æ˜¯å¦ç¬¦åˆé¢„æœŸ
    print(f"   æ£€æŸ¥æ•°æ®ç»´åº¦å…¼å®¹æ€§...")
    if vin_2_sample.shape[1] < (dim_x + dim_y + dim_z + dim_q):
        print(f"   âš ï¸ vin_2ç»´åº¦ä¸è¶³: æœŸæœ›{dim_x + dim_y + dim_z + dim_q}, å®é™…{vin_2_sample.shape[1]}")
        # è°ƒæ•´ç»´åº¦è®¾ç½®
        available_dims = vin_2_sample.shape[1]
        if available_dims >= dim_x + dim_y:
            dim_z = min(dim_z, available_dims - dim_x - dim_y - 1)
            dim_q = max(1, available_dims - dim_x - dim_y - dim_z)
        print(f"   ğŸ”„ è°ƒæ•´vin_2ç»´åº¦: x={dim_x}, y={dim_y}, z={dim_z}, q={dim_q}")
    
    if vin_3_sample.shape[1] < (dim_x2 + dim_y2 + dim_z2 + dim_q2):
        print(f"   âš ï¸ vin_3ç»´åº¦ä¸è¶³: æœŸæœ›{dim_x2 + dim_y2 + dim_z2 + dim_q2}, å®é™…{vin_3_sample.shape[1]}")
        # è°ƒæ•´ç»´åº¦è®¾ç½®
        available_dims = vin_3_sample.shape[1]
        if available_dims >= dim_x2 + dim_y2:
            dim_z2 = min(dim_z2, available_dims - dim_x2 - dim_y2 - 1)
            dim_q2 = max(1, available_dims - dim_x2 - dim_y2 - dim_z2)
        print(f"   ğŸ”„ è°ƒæ•´vin_3ç»´åº¦: x={dim_x2}, y={dim_y2}, z={dim_z2}, q={dim_q2}")
    
    # æ­£ç¡®çš„æ•°æ®åˆ‡ç‰‡ï¼ˆåŸºäºæºä»£ç é€»è¾‘ï¼‰
    try:
        # vin_2åˆ‡ç‰‡: [x_recovered, y_recovered, z_recovered, q_recovered]
        x_recovered = vin_2_sample[:, :dim_x]                                    # å‰2ç»´
        y_recovered = vin_2_sample[:, dim_x:dim_x + dim_y]                      # 110ç»´çœŸå®å•ä½“ç”µå‹
        z_recovered = vin_2_sample[:, dim_x + dim_y: dim_x + dim_y + dim_z]     # 110ç»´ç‰¹å¾
        q_recovered = vin_2_sample[:, dim_x + dim_y + dim_z:dim_x + dim_y + dim_z + dim_q]  # 3ç»´ç‰¹å¾
        
        # vin_3åˆ‡ç‰‡: [x_recovered2, y_recovered2, z_recovered2, q_recovered2]
        x_recovered2 = vin_3_sample[:, :dim_x2]                                # å‰2ç»´
        y_recovered2 = vin_3_sample[:, dim_x2:dim_x2 + dim_y2]                # 110ç»´çœŸå®å•ä½“SOC
        z_recovered2 = vin_3_sample[:, dim_x2 + dim_y2: dim_x2 + dim_y2 + dim_z2]  # 110ç»´ç‰¹å¾
        q_recovered2 = vin_3_sample[:, dim_x2 + dim_y2 + dim_z2:dim_x2 + dim_y2 + dim_z2 + dim_q2]  # 4ç»´ç‰¹å¾
        
    except Exception as e:
        print(f"   âŒ æ•°æ®åˆ‡ç‰‡å¤±è´¥: {e}")
        print(f"   ä½¿ç”¨ç®€åŒ–åˆ‡ç‰‡ç­–ç•¥...")
        # ç®€åŒ–åˆ‡ç‰‡ç­–ç•¥
        x_recovered = vin_2_sample[:, :2]
        y_recovered = vin_2_sample[:, 2:112] if vin_2_sample.shape[1] >= 112 else vin_2_sample[:, 2:]
        z_recovered = np.zeros((vin_2_sample.shape[0], 110))  # å¡«å……é›¶
        q_recovered = np.ones((vin_2_sample.shape[0], 3))     # å¡«å……ä¸€
        
        x_recovered2 = vin_3_sample[:, :2]
        y_recovered2 = vin_3_sample[:, 2:112] if vin_3_sample.shape[1] >= 112 else vin_3_sample[:, 2:]
        z_recovered2 = np.zeros((vin_3_sample.shape[0], 110)) # å¡«å……é›¶
        q_recovered2 = np.ones((vin_3_sample.shape[0], 4))    # å¡«å……ä¸€
    
    print(f"åˆ‡ç‰‡åæ•°æ®å½¢çŠ¶:")
    print(f"   x_recovered: {x_recovered.shape}, y_recovered: {y_recovered.shape}")
    print(f"   z_recovered: {z_recovered.shape}, q_recovered: {q_recovered.shape}")
    print(f"   x_recovered2: {x_recovered2.shape}, y_recovered2: {y_recovered2.shape}")
    print(f"   z_recovered2: {z_recovered2.shape}, q_recovered2: {q_recovered2.shape}")
    
    # ä½¿ç”¨çœŸå®æ•°æ®è¿›è¡ŒMC-AEè®­ç»ƒ
    # æ··åˆåé¦ˆï¼šç”¨Transformeré¢„æµ‹æ›¿æ¢BiLSTMé¢„æµ‹éƒ¨åˆ†
    x_recovered_modified = x_recovered.copy()
    x_recovered2_modified = x_recovered2.copy()
    
    # æ›¿æ¢BiLSTMé¢„æµ‹ï¼ˆç´¢å¼•0ï¼‰ä¸ºTransformeré¢„æµ‹
    # éœ€è¦ç¡®ä¿æ•°æ®é•¿åº¦åŒ¹é…
    min_len_v = min(enhanced_vin2.shape[0], x_recovered.shape[0])
    min_len_s = min(enhanced_vin3.shape[0], x_recovered2.shape[0])
    
    if min_len_v > 0:
        x_recovered_modified[:min_len_v, 0] = enhanced_vin2[:min_len_v, 0]  # æ›¿æ¢ç”µå‹é¢„æµ‹
        print(f"   âœ… æ›¿æ¢ç”µå‹é¢„æµ‹: {min_len_v} ä¸ªæ—¶é—´æ­¥")
    
    if min_len_s > 0:
        x_recovered2_modified[:min_len_s, 0] = enhanced_vin3[:min_len_s, 0]  # æ›¿æ¢SOCé¢„æµ‹
        print(f"   âœ… æ›¿æ¢SOCé¢„æµ‹: {min_len_s} ä¸ªæ—¶é—´æ­¥")
    
    print("âœ… å®Œæˆæ··åˆåé¦ˆæ•°æ®å¢å¼ºï¼šTransformeré¢„æµ‹æ›¿æ¢BiLSTMé¢„æµ‹")
    
    print("å‡†å¤‡MC-AEè®­ç»ƒæ•°æ®...")
    
    # è·¯1ï¼ˆvin_2 â†’ net_modelï¼‰ï¼šè¾“å…¥xã€å¢é‡dxã€è¾…åŠ©qï¼Œç›®æ ‡ä¸ºy
    mc_x_data = x_recovered_modified
    mc_y_data = y_recovered
    mc_z_data = z_recovered
    mc_q_data = q_recovered

    # è·¯2ï¼ˆvin_3 â†’ netx_modelï¼‰ï¼šè¾“å…¥x2ã€å¢é‡dx2ã€è¾…åŠ©q2ï¼Œç›®æ ‡ä¸ºy2
    mc2_x_data = x_recovered2_modified
    mc2_y_data = y_recovered2
    mc2_z_data = z_recovered2
    mc2_q_data = q_recovered2
    
    print(f"ç¬¬ä¸€è·¯MC-AEæ•°æ®å½¢çŠ¶ (net_model):")
    print(f"   mc_x_data: {mc_x_data.shape} (è¾“å…¥x)")
    print(f"   mc_y_data: {mc_y_data.shape} (ç›®æ ‡y)")
    print(f"   mc_z_data: {mc_z_data.shape} (å¢é‡dx)")
    print(f"   mc_q_data: {mc_q_data.shape} (è¾…åŠ©q)")
    
    print(f"ç¬¬äºŒè·¯MC-AEæ•°æ®å½¢çŠ¶ (netx_model):")
    print(f"   mc2_x_data: {mc2_x_data.shape} (è¾“å…¥x2)")
    print(f"   mc2_y_data: {mc2_y_data.shape} (ç›®æ ‡y2)")
    print(f"   mc2_z_data: {mc2_z_data.shape} (å¢é‡dx2)")
    print(f"   mc2_q_data: {mc2_q_data.shape} (è¾…åŠ©q2)")
    
    # åˆ›å»ºMC-AEæ¨¡å‹
    net_model = CombinedAE(
        input_size=dim_x, 
        encode2_input_size=dim_q,  # ä¿®æ­£ï¼šä½¿ç”¨qçš„ç»´åº¦(3)è€Œä¸æ˜¯yçš„ç»´åº¦(110)
        output_size=110,
        activation_fn=custom_activation,
        use_dx_in_forward=True
    ).to(device)
    
    netx_model = CombinedAE(
        input_size=dim_x2,
        encode2_input_size=dim_q2,  # ä¿®æ­£ï¼šä½¿ç”¨q2çš„ç»´åº¦(4)è€Œä¸æ˜¯y2çš„ç»´åº¦(110)
        output_size=110,
        activation_fn=torch.sigmoid,
        use_dx_in_forward=True
    ).to(device)
    
    # å¤šGPUæ•°æ®å¹¶è¡Œæ”¯æŒ - MC-AEæ¨¡å‹
    if torch.cuda.device_count() >= 2:
        print(f"   ğŸ”¥ MC-AEæ¨¡å‹å¯ç”¨DataParallel")
        net_model = nn.DataParallel(net_model, device_ids=[0, 1])
        netx_model = nn.DataParallel(netx_model, device_ids=[0, 1])
        print(f"   âœ… MC-AEæ•°æ®å¹¶è¡Œæ¨¡å‹åˆ›å»ºå®Œæˆ")
    
    # æ˜¾ç¤ºMC-AEæ¨¡å‹å‚æ•°é‡
    net_params = sum(p.numel() for p in net_model.parameters())
    netx_params = sum(p.numel() for p in netx_model.parameters())
    print(f"   ğŸ“Š MC-AE1å‚æ•°é‡: {net_params:,}")
    print(f"   ğŸ“Š MC-AE2å‚æ•°é‡: {netx_params:,}")
    
    # MC-AEè®­ç»ƒæ•°æ®é›†
    mc_dataset = MCDataset(mc_x_data, mc_y_data, mc_z_data, mc_q_data)
    mc_loader = DataLoader(
        mc_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=8,
        pin_memory=True,
        persistent_workers=True
    )

    # ç¬¬äºŒè·¯æ•°æ®åŠ è½½å™¨ï¼ˆvin_3 â†’ netx_modelï¼‰
    mc_dataset2 = MCDataset(mc2_x_data, mc2_y_data, mc2_z_data, mc2_q_data)
    mc_loader2 = DataLoader(
        mc_dataset2,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=8,
        pin_memory=True,
        persistent_workers=True
    )
    
    # MC-AEè®­ç»ƒé…ç½®
    net_optimizer = optim.Adam(net_model.parameters(), lr=config['learning_rate'])
    netx_optimizer = optim.Adam(netx_model.parameters(), lr=config['learning_rate'])
    
    # è´Ÿåé¦ˆæŸå¤±å‡½æ•°
    contrastive_loss = ContrastiveMCAELoss(
        alpha=config['negative_feedback']['alpha'],
        beta=config['negative_feedback']['beta'],
        margin=config['negative_feedback']['margin']
    )
    
    phase2_epochs = config['training_phases']['phase2_mcae']['epochs']
    net_losses, netx_losses = [], []
    
    print(f"å¼€å§‹MC-AEè®­ç»ƒ ({phase2_epochs} è½®)...")
    
    for epoch in range(phase2_epochs):
        net_model.train()
        netx_model.train()
        
        epoch_net_losses, epoch_netx_losses = [], []
        
        pbar = tqdm(mc_loader, desc=f"MC-AE Epoch {epoch+1}/{phase2_epochs}")
        mc_iter2 = iter(mc_loader2)
        batch_count = 0
        for batch_x, batch_y, batch_z, batch_q in pbar:
            batch_x2, batch_y2, batch_z2, batch_q2 = next(mc_iter2)
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device) 
            batch_z = batch_z.to(device)
            batch_q = batch_q.to(device)
            batch_x2 = batch_x2.to(device)
            batch_y2 = batch_y2.to(device)
            batch_z2 = batch_z2.to(device)
            batch_q2 = batch_q2.to(device)
            
            # æ‰“å°ç¬¬ä¸€ä¸ªbatchçš„è°ƒè¯•ä¿¡æ¯
            if epoch == 0 and batch_count == 0:
                print(f"\nğŸ” ç¬¬ä¸€ä¸ªbatchè°ƒè¯•ä¿¡æ¯:")
                print(f"   ç¬¬ä¸€è·¯batchå½¢çŠ¶å’Œç±»å‹:")
                print(f"      batch_x: {batch_x.shape}, dtype={batch_x.dtype}")
                print(f"      batch_y: {batch_y.shape}, dtype={batch_y.dtype}")
                print(f"      batch_z: {batch_z.shape}, dtype={batch_z.dtype}")
                print(f"      batch_q: {batch_q.shape}, dtype={batch_q.dtype}")
                print(f"   ç¬¬äºŒè·¯batchå½¢çŠ¶å’Œç±»å‹:")
                print(f"      batch_x2: {batch_x2.shape}, dtype={batch_x2.dtype}")
                print(f"      batch_y2: {batch_y2.shape}, dtype={batch_y2.dtype}")
                print(f"      batch_z2: {batch_z2.shape}, dtype={batch_z2.dtype}")
                print(f"      batch_q2: {batch_q2.shape}, dtype={batch_q2.dtype}")
            
            batch_count += 1
            
            # è®­ç»ƒnet_model (MC-AE1)
            net_optimizer.zero_grad()
            recon_y_pred, _ = net_model(batch_x, batch_z, batch_q)
            
            # ä½¿ç”¨è´Ÿåé¦ˆæŸå¤±
            if (epoch >= config['negative_feedback']['start_epoch'] and 
                config['negative_feedback']['enable'] and
                len(negative_data) > 0):
                
                # è¿™é‡Œåº”è¯¥åŠ è½½è´Ÿåé¦ˆæ ·æœ¬æ•°æ®ï¼Œæš‚æ—¶ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
                net_loss, pos_loss, neg_loss = contrastive_loss(
                    recon_y_pred,
                    batch_y
                )
            else:
                net_loss = F.mse_loss(recon_y_pred, batch_y)
            
            net_loss.backward()
            net_optimizer.step()
            epoch_net_losses.append(net_loss.item())
            
            # è®­ç»ƒnetx_model (MC-AE2)
            netx_optimizer.zero_grad()
            recon_y2_pred, _ = netx_model(batch_x2, batch_z2, batch_q2)
            
            if (epoch >= config['negative_feedback']['start_epoch'] and 
                config['negative_feedback']['enable'] and
                len(negative_data) > 0):
                
                netx_loss, pos_loss, neg_loss = contrastive_loss(
                    recon_y2_pred,
                    batch_y2
                )
            else:
                netx_loss = F.mse_loss(recon_y2_pred, batch_y2)
            
            netx_loss.backward()
            netx_optimizer.step()
            epoch_netx_losses.append(netx_loss.item())
            
            pbar.set_postfix({
                'Net Loss': f'{net_loss.item():.6f}',
                'NetX Loss': f'{netx_loss.item():.6f}'
            })
        
        avg_net_loss = np.mean(epoch_net_losses)
        avg_netx_loss = np.mean(epoch_netx_losses)
        net_losses.append(avg_net_loss)
        netx_losses.append(avg_netx_loss)
        
        if (epoch + 1) % 10 == 0:
            print(f"MC-AE Epoch {epoch+1}: Net Loss={avg_net_loss:.6f}, NetX Loss={avg_netx_loss:.6f}")
            print_gpu_memory()
    
    print("âœ… MC-AEè®­ç»ƒå®Œæˆ")
    
    # ä¿å­˜MC-AEæ¨¡å‹
    net_save_path = os.path.join(config['save_base_path'], 'net_model_pn.pth')
    netx_save_path = os.path.join(config['save_base_path'], 'netx_model_pn.pth')
    
    # å…¼å®¹DataParallelä¿å­˜
    net_to_save = net_model.module if isinstance(net_model, nn.DataParallel) else net_model
    netx_to_save = netx_model.module if isinstance(netx_model, nn.DataParallel) else netx_model
    torch.save(net_to_save.state_dict(), net_save_path)
    torch.save(netx_to_save.state_dict(), netx_save_path)
    
    print(f"   MC-AE1æ¨¡å‹å·²ä¿å­˜: {net_save_path}")
    print(f"   MC-AE2æ¨¡å‹å·²ä¿å­˜: {netx_save_path}")
    
    #=== ç¬¬4é˜¶æ®µ: PCAåˆ†æå’Œé˜ˆå€¼è®¡ç®— ===
    print("\n" + "="*50)
    print("ğŸ“Š ç¬¬4é˜¶æ®µ: PCAåˆ†æå’Œé˜ˆå€¼è®¡ç®—")
    print("="*50)
    
    # è®¡ç®—é‡æ„è¯¯å·®ç‰¹å¾
    print("è®¡ç®—é‡æ„è¯¯å·®ç‰¹å¾...")
    net_model.eval()
    netx_model.eval()
    
    all_features = []
    with torch.no_grad():
        mc_iter2 = iter(mc_loader2)
        for batch_x, batch_y, batch_z, batch_q in tqdm(mc_loader, desc="è®¡ç®—ç‰¹å¾"):
            batch_x2, batch_y2, batch_z2, batch_q2 = next(mc_iter2)
            batch_x = batch_x.to(device)
            batch_y = batch_y.to(device)
            batch_z = batch_z.to(device) 
            batch_q = batch_q.to(device)
            batch_x2 = batch_x2.to(device)
            batch_y2 = batch_y2.to(device)
            batch_z2 = batch_z2.to(device)
            batch_q2 = batch_q2.to(device)
            
            # MC-AE1é‡æ„è¯¯å·®
            recon_y_pred, _ = net_model(batch_x, batch_z, batch_q)
            error1 = F.mse_loss(recon_y_pred, batch_y, reduction='none').mean(dim=1)
            
            # MC-AE2é‡æ„è¯¯å·®
            recon_y2_pred, _ = netx_model(batch_x2, batch_z2, batch_q2)
            error2 = F.mse_loss(recon_y2_pred, batch_y2, reduction='none').mean(dim=1)
            
            # åˆå¹¶ç‰¹å¾
            features = torch.stack([error1, error2], dim=1)
            all_features.append(features.cpu().numpy())
    
    # åˆå¹¶æ‰€æœ‰ç‰¹å¾
    features_combined = np.vstack(all_features)
    print(f"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {features_combined.shape}")
    
    # PCAåˆ†æ
    print("æ‰§è¡ŒPCAåˆ†æ...")
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features_combined)
    
    pca = PCA()
    pca_features = pca.fit_transform(features_scaled)
    
    # é€‰æ‹©ä¸»æˆåˆ†æ•°é‡(ä¿ç•™90%æ–¹å·®)
    cumsum_ratio = np.cumsum(pca.explained_variance_ratio_)
    n_components = np.argmax(cumsum_ratio >= 0.90) + 1
    
    print(f"PCAåˆ†æå®Œæˆ:")
    print(f"   ä¸»æˆåˆ†æ•°é‡: {n_components}")
    print(f"   æ–¹å·®è§£é‡Šæ¯”ä¾‹: {cumsum_ratio[n_components-1]:.4f}")
    
    # è®¡ç®—æ§åˆ¶é™
    pca_reduced = pca_features[:, :n_components]
    
    # TÂ²ç»Ÿè®¡é‡
    eigenvalues = pca.explained_variance_[:n_components]
    T2_stats = np.sum((pca_reduced ** 2) / eigenvalues, axis=1)
    
    # SPEç»Ÿè®¡é‡  
    reconstructed = pca_reduced @ pca.components_[:n_components]
    residuals = features_scaled - reconstructed
    SPE_stats = np.sum(residuals ** 2, axis=1)
    
    # è®¡ç®—æ§åˆ¶é™
    T2_99_limit = np.percentile(T2_stats, 99)
    SPE_99_limit = np.percentile(SPE_stats, 99)
    
    # ç»¼åˆæ•…éšœæŒ‡æ ‡
    FAI = (T2_stats / T2_99_limit + SPE_stats / SPE_99_limit) / 2
    
    print(f"æ§åˆ¶é™è®¡ç®—å®Œæˆ:")
    print(f"   TÂ²-99%æ§åˆ¶é™: {T2_99_limit:.4f}")
    print(f"   SPE-99%æ§åˆ¶é™: {SPE_99_limit:.4f}")
    print(f"   FAIèŒƒå›´: [{np.min(FAI):.4f}, {np.max(FAI):.4f}]")
    
    # ä¿å­˜PCAå‚æ•°
    pca_params = {
        'pca_model': pca,
        'scaler': scaler,
        'n_components': n_components,
        'T2_99_limit': T2_99_limit,
        'SPE_99_limit': SPE_99_limit,
        'eigenvalues': eigenvalues,
        'explained_variance_ratio': pca.explained_variance_ratio_,
        'components': pca.components_
    }
    
    pca_save_path = os.path.join(config['save_base_path'], 'pca_params_pn.pkl')
    with open(pca_save_path, 'wb') as f:
        pickle.dump(pca_params, f)
    print(f"   PCAå‚æ•°å·²ä¿å­˜: {pca_save_path}")
    
    #=== ç¬¬5é˜¶æ®µ: è®­ç»ƒç»“æœå¯è§†åŒ– ===
    print("\n" + "="*50)
    print("ğŸ“ˆ ç¬¬5é˜¶æ®µ: è®­ç»ƒç»“æœå¯è§†åŒ–")
    print("="*50)
    
    # åˆ›å»ºè®­ç»ƒæŸå¤±å›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Transformer Loss
    axes[0, 0].plot(transformer_losses, 'b-', linewidth=2)
    axes[0, 0].set_title('Transformer Training Loss', fontsize=14)
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].grid(True, alpha=0.3)
    
    # MC-AE Loss
    axes[0, 1].plot(net_losses, 'r-', label='MC-AE1', linewidth=2)
    axes[0, 1].plot(netx_losses, 'g-', label='MC-AE2', linewidth=2)
    axes[0, 1].set_title('MC-AE Training Loss', fontsize=14)
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Loss')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # FAI Distribution
    axes[1, 0].hist(FAI, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
    axes[1, 0].axvline(1.0, color='red', linestyle='--', linewidth=2, label='Threshold=1.0')
    axes[1, 0].set_title('FAI Distribution', fontsize=14)
    axes[1, 0].set_xlabel('FAI Value')
    axes[1, 0].set_ylabel('Frequency')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # PCA Variance Ratio
    axes[1, 1].plot(range(1, len(cumsum_ratio)+1), cumsum_ratio, 'mo-', linewidth=2)
    axes[1, 1].axhline(0.90, color='red', linestyle='--', linewidth=2, label='90% Threshold')
    axes[1, 1].axvline(n_components, color='green', linestyle='--', linewidth=2, 
                      label=f'Selected {n_components} Components')
    axes[1, 1].set_title('PCA Cumulative Variance Ratio', fontsize=14)
    axes[1, 1].set_xlabel('Number of Components')
    axes[1, 1].set_ylabel('Cumulative Variance Ratio')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾åƒ
    plot_save_path = os.path.join(config['save_base_path'], 'pn_training_results.png')
    plt.savefig(plot_save_path, dpi=300, bbox_inches='tight')
    plt.close()  # å…³é—­å›¾åƒï¼Œé‡Šæ”¾å†…å­˜
    print(f"   è®­ç»ƒç»“æœå›¾å·²ä¿å­˜: {plot_save_path}")
    
    #=== è®­ç»ƒå®Œæˆæ€»ç»“ ===
    print("\n" + "="*80)
    print("ğŸ‰ æ­£è´Ÿåé¦ˆæ··åˆè®­ç»ƒå®Œæˆï¼")
    print("="*80)
    
    print("ğŸ“Š è®­ç»ƒæ€»ç»“:")
    print(f"   è®­ç»ƒæ ·æœ¬: {len(successful_train)} ä¸ª (0-100)")
    print(f"   æ­£åé¦ˆæ ·æœ¬: {len(successful_positive)} ä¸ª (101-120)")
    print(f"   è´Ÿåé¦ˆæ ·æœ¬: {len(successful_negative)} ä¸ª (340-350)")
    print(f"   Transformeræœ€ç»ˆæŸå¤±: {transformer_losses[-1]:.6f}")
    print(f"   MC-AE1æœ€ç»ˆæŸå¤±: {net_losses[-1]:.6f}")
    print(f"   MC-AE2æœ€ç»ˆæŸå¤±: {netx_losses[-1]:.6f}")
    print(f"   PCAä¸»æˆåˆ†æ•°é‡: {n_components}")
    print(f"   FAIå¹³å‡å€¼: {np.mean(FAI):.4f}")
    
    print(f"\nğŸ’¾ è¾“å‡ºæ–‡ä»¶:")
    print(f"   ğŸ“¦ æ¨¡å‹æ–‡ä»¶:")
    print(f"      - Transformer: {transformer_save_path}")
    print(f"      - MC-AE1: {net_save_path}")
    print(f"      - MC-AE2: {netx_save_path}")
    print(f"   ğŸ“Š å‚æ•°æ–‡ä»¶:")
    print(f"      - PCAå‚æ•°: {pca_save_path}")
    print(f"   ğŸ“ˆ å¯è§†åŒ–æ–‡ä»¶:")
    print(f"      - è®­ç»ƒç»“æœå›¾: {plot_save_path}")
    print(f"   ğŸ“ æŠ¥å‘Šæ–‡ä»¶:")
    print(f"      - è®­ç»ƒæŠ¥å‘Š: training_report_pn.md (å³å°†ç”Ÿæˆ)")
    
    # Save training history for visualization compatibility
    training_history = {
        'losses': transformer_losses,
        'mcae1_losses': net_losses,
        'mcae2_losses': netx_losses,
        'epochs': config['training_phases']['phase1_transformer']['epochs'],
        'mcae_epochs': config['training_phases']['phase2_mcae']['epochs'],
        'final_loss': transformer_losses[-1] if transformer_losses else 0.0,
        'mcae1_final_loss': net_losses[-1] if net_losses else 0.0,
        'mcae2_final_loss': netx_losses[-1] if netx_losses else 0.0,
        'model_config': {
            'input_size': 7,
            'output_size': 2,
            'd_model': 128,
            'nhead': 8,
            'num_layers': 3
        },
        'training_config': {
            'batch_size': config['batch_size'],
            'learning_rate': config['learning_rate'],
            'optimizer': 'Adam',
            'scheduler': 'StepLR',
            'device': str(device)
        },
        'pca_results': {
            'n_components': n_components,
            'T2_99_limit': float(T2_99_limit),
            'SPE_99_limit': float(SPE_99_limit),
            'fai_mean': float(np.mean(FAI)),
            'fai_std': float(np.std(FAI))
        },
        'data_info': {
            'train_samples': len(successful_train),
            'positive_samples': len(successful_positive),
            'negative_samples': len(successful_negative),
            'total_normal_samples': len(normal_samples),
            'total_fault_samples': len(fault_samples)
        },
        'timestamp': datetime.now().strftime('%Y%m%d_%H%M%S')
    }
    
    # Save to multiple locations for compatibility
    history_save_paths = [
        os.path.join(config['save_base_path'], 'hybrid_feedback_training_history.pkl'),
        '/mnt/bz25t/bzhy/datasave/hybrid_feedback_training_history.pkl',
        './hybrid_feedback_training_history.pkl'
    ]
    
    for history_path in history_save_paths:
        try:
            # Ensure directory exists
            os.makedirs(os.path.dirname(history_path), exist_ok=True)
            
            with open(history_path, 'wb') as f:
                pickle.dump(training_history, f)
            print(f"   Training history saved: {history_path}")
        except Exception as e:
            print(f"   Failed to save training history to {history_path}: {e}")
    
    # ä¿å­˜è®­ç»ƒé…ç½®å’Œç»“æœ
    results_summary = {
        'config': config,
        'sample_info': {
            'total_normal_samples': len(normal_samples),
            'total_fault_samples': len(fault_samples),
            'used_train_samples': successful_train,
            'used_positive_samples': successful_positive,
            'used_negative_samples': successful_negative,
            'train_sample_labels': [0] * len(successful_train),  # è®­ç»ƒæ ·æœ¬éƒ½æ˜¯æ­£å¸¸æ ·æœ¬
            'positive_sample_labels': [0] * len(successful_positive),  # æ­£åé¦ˆæ ·æœ¬éƒ½æ˜¯æ­£å¸¸æ ·æœ¬
            'negative_sample_labels': [1] * len(successful_negative)   # è´Ÿåé¦ˆæ ·æœ¬éƒ½æ˜¯æ•…éšœæ ·æœ¬
        },
        'training_results': {
            'transformer_final_loss': transformer_losses[-1],
            'mcae1_final_loss': net_losses[-1],
            'mcae2_final_loss': netx_losses[-1],
            'pca_components': n_components,
            'fai_mean': float(np.mean(FAI)),
            'fai_std': float(np.std(FAI)),
            'T2_99_limit': float(T2_99_limit),
            'SPE_99_limit': float(SPE_99_limit)
        },
        'training_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    # è½¬æ¢NumPyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹ï¼Œé¿å…JSONåºåˆ—åŒ–é”™è¯¯
    def convert_numpy_types(obj):
        """é€’å½’è½¬æ¢NumPyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹"""
        import numpy as np
        if isinstance(obj, dict):
            return {key: convert_numpy_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [convert_numpy_types(item) for item in obj]
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return obj
    
    # è½¬æ¢results_summaryä¸­çš„NumPyç±»å‹
    results_summary_clean = convert_numpy_types(results_summary)
    
    summary_save_path = os.path.join(config['save_base_path'], 'training_summary_pn.json')
    with open(summary_save_path, 'w', encoding='utf-8') as f:
        json.dump(results_summary_clean, f, ensure_ascii=False, indent=2)
    
    print(f"   è®­ç»ƒæ€»ç»“: {summary_save_path}")
    
    #=== ç”Ÿæˆè¯¦ç»†çš„Markdownè®­ç»ƒæŠ¥å‘Š ===
    print("\nğŸ“ ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š...")
    try:
        report_content = generate_training_report(
            config, results_summary, transformer_losses, net_losses, netx_losses,
            normal_samples, fault_samples, n_components, FAI, T2_99_limit, SPE_99_limit
        )
        
        report_save_path = os.path.join(config['save_base_path'], 'training_report_pn.md')
        with open(report_save_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"   è®­ç»ƒæŠ¥å‘Š: {report_save_path}")
        print("   âœ… è¯¦ç»†çš„è®­ç»ƒæŠ¥å‘Šå·²ç”Ÿæˆï¼ŒåŒ…å«å®Œæ•´çš„å‚æ•°é…ç½®ã€è®­ç»ƒè¿‡ç¨‹å’Œç»“æœåˆ†æ")
        
    except Exception as e:
        print(f"   âš ï¸ ç”Ÿæˆè®­ç»ƒæŠ¥å‘Šå¤±è´¥: {e}")
    
    print("\nğŸš€ è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²å‡†å¤‡å°±ç»ªï¼")

if __name__ == "__main__":
    main()