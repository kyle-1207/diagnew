#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›†æˆTransformerè®­ç»ƒæµ‹è¯•ç³»ç»Ÿ
ç›´æ¥è°ƒç”¨ç°æœ‰å‡½æ•°ï¼Œä¸é‡å¤å®ç°
"""

# å¯¼å…¥ç°æœ‰æ¨¡å—
from Function_ import *
from Class_ import *
from Comprehensive_calculation import Comprehensive_calculation
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import os
import pickle
import time
from datetime import datetime
from sklearn.metrics import roc_curve, auc, confusion_matrix
from scipy.stats import chi2

# è®¾ç½®ä¸­æ–‡å­—ä½“
def setup_chinese_fonts():
    """è®¾ç½®ä¸­æ–‡å­—ä½“æ˜¾ç¤º"""
    try:
        # å°è¯•å¸¸è§çš„ä¸­æ–‡å­—ä½“
        chinese_fonts = [
            'SimHei', 'Microsoft YaHei', 'DejaVu Sans', 
            'WenQuanYi Micro Hei', 'Noto Sans CJK SC'
        ]
        
        for font in chinese_fonts:
            try:
                plt.rcParams['font.sans-serif'] = [font]
                plt.rcParams['axes.unicode_minus'] = False
                # æµ‹è¯•ä¸­æ–‡æ˜¾ç¤º
                fig, ax = plt.subplots(figsize=(1, 1))
                ax.text(0.5, 0.5, 'æµ‹è¯•', fontsize=12)
                plt.close(fig)
                print(f"âœ… ä½¿ç”¨ä¸­æ–‡å­—ä½“: {font}")
                return True
            except:
                continue
        
        # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨è‹±æ–‡
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        print("âš ï¸  ä¸­æ–‡å­—ä½“ä¸å¯ç”¨ï¼Œä½¿ç”¨è‹±æ–‡æ ‡ç­¾")
        return False
        
    except Exception as e:
        print(f"âŒ å­—ä½“è®¾ç½®å¤±è´¥: {e}")
        return False

# è®¾ç½®å­—ä½“
use_chinese = setup_chinese_fonts()
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.size'] = 10

# å®éªŒé…ç½®
EXPERIMENT_CONFIGS = {
    'original': {
        'name': 'åŸå§‹å‚æ•°è§„æ¨¡' if use_chinese else 'Original Parameters',
        'd_model': 128,      # æ¢å¤åˆ°åŸå§‹çš„128
        'n_heads': 8,        # æ¢å¤åˆ°åŸå§‹çš„8
        'n_layers': 3,       # æ¢å¤åˆ°åŸå§‹çš„3
        'd_ff': 512,         # æ¢å¤åˆ°åŸå§‹çš„512 (d_model*4)
        'dropout': 0.1,
        'save_suffix': '_original'
    },
    'enhanced': {
        'name': 'å¢å¼ºå‚æ•°è§„æ¨¡(+50%)' if use_chinese else 'Enhanced Parameters (+50%)',
        'd_model': 192,      # 128 * 1.5
        'n_heads': 12,       # 8 * 1.5  
        'n_layers': 3,       # ä¿æŒä¸å˜
        'd_ff': 768,         # 512 * 1.5
        'dropout': 0.2,      # å¢åŠ dropouté˜²æ­¢è¿‡æ‹Ÿåˆ
        'save_suffix': '_enhanced'
    }
}

# æ•°æ®é…ç½® - ä¿®æ”¹ä¸ºæ··åˆåé¦ˆç­–ç•¥
TRAIN_SAMPLES = list(range(8))      # è®­ç»ƒæ ·æœ¬ï¼šQAS 0-7ï¼ˆ8ä¸ªæ­£å¸¸æ ·æœ¬ï¼‰
FEEDBACK_SAMPLES = [8, 9]           # åé¦ˆæ ·æœ¬ï¼šQAS 8-9ï¼ˆ2ä¸ªæ­£å¸¸æ ·æœ¬ï¼‰
TEST_SAMPLES = {
    'normal': ['10', '11'],      # æµ‹è¯•æ­£å¸¸æ ·æœ¬
    'fault': ['335', '336']      # æµ‹è¯•æ•…éšœæ ·æœ¬
}

# æ··åˆåé¦ˆç­–ç•¥é…ç½®
FEEDBACK_CONFIG = {
    'train_samples': TRAIN_SAMPLES,
    'feedback_samples': FEEDBACK_SAMPLES,
    'min_epochs_before_feedback': 10,    # å‡å°‘åˆ°10ä¸ªepoch
    'base_feedback_interval': 10,        # å‡å°‘åé¦ˆé—´éš”
    'adaptive_threshold': 0.03,          # è‡ªé€‚åº”è§¦å‘é˜ˆå€¼ï¼ˆå‡é˜³æ€§ç‡ï¼‰- è°ƒæ•´ä¸º3%
    'max_feedback_interval': 15,         # å‡å°‘æœ€å¤§åé¦ˆé—´éš”
    'feedback_weight': 0.2,              # åé¦ˆæƒé‡
    'mcae_feedback_weight': 0.8,         # MC-AEåé¦ˆæƒé‡
    'transformer_feedback_weight': 0.2,  # Transformeråé¦ˆæƒé‡
    # æ–°å¢åˆ†çº§é˜ˆå€¼
    'warning_threshold': 0.01,           # 1%é¢„è­¦é˜ˆå€¼ï¼ˆä»…è®°å½•ï¼Œä¸åé¦ˆï¼‰
    'mild_threshold': 0.03,              # 3%è½»åº¦é˜ˆå€¼ï¼ˆæ ‡å‡†åé¦ˆï¼‰
    'severe_threshold': 0.05,            # 5%ä¸¥é‡é˜ˆå€¼ï¼ˆå¼ºåŒ–åé¦ˆï¼‰
    'emergency_threshold': 0.10          # 10%ç´§æ€¥é˜ˆå€¼ï¼ˆç«‹å³åé¦ˆï¼‰
}

# ä¸‰çª—å£é…ç½®
WINDOW_CONFIG = {
    "detection_window": 100,     # æ£€æµ‹çª—å£ï¼š100ä¸ªé‡‡æ ·ç‚¹
    "verification_window": 50,   # éªŒè¯çª—å£ï¼š50ä¸ªé‡‡æ ·ç‚¹  
    "marking_window": 50        # æ ‡è®°çª—å£ï¼šå‰åå„50ä¸ªé‡‡æ ·ç‚¹
}

# è®¾å¤‡é…ç½® - ä¼˜å…ˆä½¿ç”¨GPUï¼Œå¦‚æœå†…å­˜ä¸è¶³åˆ™å›é€€åˆ°CPU
if torch.cuda.is_available():
    device = torch.device('cuda')
    print(f"ğŸ”§ å°è¯•ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
    print(f"ğŸ”§ GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory/1024**3:.1f}GB")
else:
    device = torch.device('cpu')
    print(f"ğŸ”§ ä½¿ç”¨CPUè®­ç»ƒ")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

#=============================Transformeræ¨¡å‹å®šä¹‰=============================

class TransformerPredictor(nn.Module):
    """Transformeré¢„æµ‹å™¨"""
    def __init__(self, input_size, d_model, nhead, num_layers, d_ff, dropout=0.1, output_size=2):
        super().__init__()
        self.input_size = input_size
        self.d_model = d_model
        self.output_size = output_size
        
        # è¾“å…¥æŠ•å½±å±‚
        self.input_projection = nn.Linear(input_size, d_model)
        
        # ä½ç½®ç¼–ç 
        self.pos_encoder = PositionalEncoding(d_model, dropout)
        
        # Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_ff,
            dropout=dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # è¾“å‡ºå±‚
        self.output_projection = nn.Linear(d_model, output_size)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        # x shape: [batch_size, seq_len, input_size]
        x = self.input_projection(x)  # [batch_size, seq_len, d_model]
        x = self.pos_encoder(x)
        x = self.transformer(x)  # [batch_size, seq_len, d_model]
        x = self.dropout(x)
        x = self.output_projection(x)  # [batch_size, seq_len, output_size]
        return x

class PositionalEncoding(nn.Module):
    """ä½ç½®ç¼–ç """
    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super().__init__()
        self.dropout = nn.Dropout(p=dropout)
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)
        
    def forward(self, x):
        x = x + self.pe[:x.size(1), :].transpose(0, 1)
        return self.dropout(x)

#=============================åå‘ä¼ æ’­æœºåˆ¶=============================

#=============================æ··åˆåé¦ˆç­–ç•¥æ ¸å¿ƒå‡½æ•°=============================

def calculate_feedback_metrics(model, feedback_samples, device):
    """
    è®¡ç®—åé¦ˆæŒ‡æ ‡
    
    Args:
        model: å½“å‰è®­ç»ƒçš„æ¨¡å‹
        feedback_samples: åé¦ˆæ ·æœ¬IDåˆ—è¡¨
        device: è®¡ç®—è®¾å¤‡
    
    Returns:
        feedback_metrics: åé¦ˆæŒ‡æ ‡å­—å…¸
    """
    metrics = {
        'false_positive_rate': 0.0,
        'feedback_loss': 0.0,
        'feature_drift': 0.0,
        'sample_metrics': {}
    }
    
    model.eval()
    
    try:
        for sample_id in feedback_samples:
            # åŠ è½½åé¦ˆæ ·æœ¬æ•°æ®
            sample_data = load_sample_data(sample_id)
            
            if sample_data[0] is None:
                continue
            
            # å‡†å¤‡æ•°æ®
            X_test = prepare_single_sample(*sample_data)
            if X_test is None:
                continue
            
            # æ¨¡å‹é¢„æµ‹
            with torch.no_grad():
                predictions = model(X_test)
                pred_np = predictions.cpu().numpy()
            
            # è®¡ç®—ç»¼åˆè¯Šæ–­æŒ‡æ ‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            fai_values = calculate_diagnosis_simple(pred_np, get_true_values(sample_id, 'normal'))
            
            # è®¡ç®—é˜ˆå€¼
            threshold = np.mean(fai_values) + 2 * np.std(fai_values)
            
            # ç»Ÿè®¡å‡é˜³æ€§ç‡
            false_positives = np.sum(fai_values > threshold)
            total_points = len(fai_values)
            false_positive_rate = false_positives / total_points
            
            # è®°å½•æ ·æœ¬æŒ‡æ ‡
            metrics['sample_metrics'][sample_id] = {
                'false_positive_rate': false_positive_rate,
                'fai_mean': np.mean(fai_values),
                'fai_std': np.std(fai_values),
                'threshold': threshold
            }
            
            # ç´¯è®¡æŒ‡æ ‡
            metrics['false_positive_rate'] += false_positive_rate
            metrics['feedback_loss'] += np.mean(fai_values)
        
        # å¹³å‡æŒ‡æ ‡
        if len(feedback_samples) > 0:
            metrics['false_positive_rate'] /= len(feedback_samples)
            metrics['feedback_loss'] /= len(feedback_samples)
        
        model.train()
        return metrics
        
    except Exception as e:
        print(f"âŒ è®¡ç®—åé¦ˆæŒ‡æ ‡å¤±è´¥: {e}")
        model.train()
        return metrics

def should_trigger_feedback(epoch, last_feedback_epoch, feedback_metrics, config):
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘åé¦ˆï¼ˆæ”¯æŒåˆ†çº§é˜ˆå€¼ï¼‰
    
    Args:
        epoch: å½“å‰epoch
        last_feedback_epoch: ä¸Šæ¬¡åé¦ˆçš„epoch
        feedback_metrics: åé¦ˆæŒ‡æ ‡
        config: åé¦ˆé…ç½®
    
    Returns:
        should_feedback: æ˜¯å¦åº”è¯¥åé¦ˆ
        trigger_reason: è§¦å‘åŸå› 
        feedback_intensity: åé¦ˆå¼ºåº¦ (0-1)
    """
    # æ£€æŸ¥æœ€å°è®­ç»ƒepoch
    if epoch < config['min_epochs_before_feedback']:
        return False, "è®­ç»ƒepochä¸è¶³", 0.0
    
    time_since_last = epoch - last_feedback_epoch
    false_positive_rate = feedback_metrics.get('false_positive_rate', 0.0)
    
    # åˆ†çº§é˜ˆå€¼åˆ¤æ–­
    feedback_intensity = 0.2  # é»˜è®¤åé¦ˆå¼ºåº¦
    
    # æ¡ä»¶1: ç´§æ€¥è§¦å‘ï¼ˆå‡é˜³æ€§ç‡>=10%ï¼‰
    if false_positive_rate >= config['emergency_threshold']:
        return True, f"ç´§æ€¥è§¦å‘ï¼ˆå‡é˜³æ€§ç‡{false_positive_rate:.1%}>=10%ï¼‰", 1.0
    
    # æ¡ä»¶2: ä¸¥é‡è§¦å‘ï¼ˆå‡é˜³æ€§ç‡>=5%ï¼‰
    elif (false_positive_rate >= config['severe_threshold'] and 
          time_since_last >= 3):  # æ›´çŸ­é—´éš”
        return True, f"ä¸¥é‡è§¦å‘ï¼ˆå‡é˜³æ€§ç‡{false_positive_rate:.1%}>=5%ï¼‰", 0.6
    
    # æ¡ä»¶3: æ ‡å‡†è‡ªé€‚åº”è§¦å‘ï¼ˆå‡é˜³æ€§ç‡>=3%ï¼‰
    elif (false_positive_rate >= config['mild_threshold'] and 
          time_since_last >= 5):  # è‡³å°‘é—´éš”5ä¸ªepoch
        return True, f"æ ‡å‡†è§¦å‘ï¼ˆå‡é˜³æ€§ç‡{false_positive_rate:.1%}>=3%ï¼‰", 0.3
    
    # æ¡ä»¶4: å›ºå®šé—´éš”è§¦å‘
    elif time_since_last >= config['base_feedback_interval']:
        return True, "å›ºå®šé—´éš”è§¦å‘", 0.2
    
    # æ¡ä»¶5: å…œåº•è§¦å‘ï¼ˆé˜²æ­¢å¤ªä¹…ä¸åé¦ˆï¼‰
    elif time_since_last >= config['max_feedback_interval']:
        return True, "å…œåº•è§¦å‘", 0.2
    
    # é¢„è­¦è®°å½•ï¼ˆ1%é˜ˆå€¼ï¼‰
    elif false_positive_rate >= config['warning_threshold']:
        # ä¸è§¦å‘åé¦ˆï¼Œä½†è®°å½•é¢„è­¦
        print(f"   âš ï¸  é¢„è­¦ï¼šå‡é˜³æ€§ç‡{false_positive_rate:.1%}è¾¾åˆ°1%é˜ˆå€¼")
        return False, "é¢„è­¦é˜ˆå€¼ï¼ˆä¸åé¦ˆï¼‰", 0.0
    
    return False, "æ— éœ€åé¦ˆ", 0.0

def mcae_feedback_loss(reconstruction_error, normal_error_distribution, feedback_weight=0.8):
    """
    MC-AEåé¦ˆæŸå¤±ï¼šè®©å‡é˜³æ€§æ ·æœ¬çš„é‡æ„è¯¯å·®æ›´æ¥è¿‘æ­£å¸¸åˆ†å¸ƒ
    
    Args:
        reconstruction_error: é‡æ„è¯¯å·®
        normal_error_distribution: æ­£å¸¸æ ·æœ¬è¯¯å·®åˆ†å¸ƒ
        feedback_weight: åé¦ˆæƒé‡
    
    Returns:
        feedback_loss: åé¦ˆæŸå¤±
    """
    try:
        # è®¡ç®—æ­£å¸¸æ ·æœ¬çš„é‡æ„è¯¯å·®åˆ†å¸ƒ
        normal_mean = np.mean(normal_error_distribution)
        normal_std = np.std(normal_error_distribution)
        
        # ç›®æ ‡ï¼šè®©å‡é˜³æ€§æ ·æœ¬çš„é‡æ„è¯¯å·®è½åœ¨æ­£å¸¸èŒƒå›´å†…
        target_error = normal_mean + 0.5 * normal_std  # ä¿å®ˆç›®æ ‡
        
        # æŸå¤±å‡½æ•°ï¼šé¼“åŠ±é‡æ„è¯¯å·®æ¥è¿‘ç›®æ ‡
        feedback_loss = torch.mean((reconstruction_error - target_error)**2)
        
        return feedback_weight * feedback_loss
        
    except Exception as e:
        print(f"âŒ MC-AEåé¦ˆæŸå¤±è®¡ç®—å¤±è´¥: {e}")
        return torch.tensor(0.0, requires_grad=True)

def transformer_feature_feedback(transformer_features, normal_feature_center, feedback_weight=0.2):
    """
    Transformerç‰¹å¾åé¦ˆï¼šæ”¹å–„ç‰¹å¾è¡¨ç¤º
    
    Args:
        transformer_features: Transformerç‰¹å¾
        normal_feature_center: æ­£å¸¸ç‰¹å¾ä¸­å¿ƒ
        feedback_weight: åé¦ˆæƒé‡
    
    Returns:
        feedback_loss: åé¦ˆæŸå¤±
    """
    try:
        # è®¡ç®—ç‰¹å¾è·ç¦»æŸå¤±
        distance_loss = torch.mean(torch.norm(transformer_features - normal_feature_center, dim=1))
        
        # ç‰¹å¾å¤šæ ·æ€§æŸå¤±ï¼ˆé¿å…ç‰¹å¾åç¼©ï¼‰
        diversity_loss = -torch.mean(torch.std(transformer_features, dim=0))
        
        return feedback_weight * (distance_loss + 0.1 * diversity_loss)
        
    except Exception as e:
        print(f"âŒ Transformerç‰¹å¾åé¦ˆè®¡ç®—å¤±è´¥: {e}")
        return torch.tensor(0.0, requires_grad=True)

def calculate_normal_feature_center(feedback_samples, model, device):
    """
    è®¡ç®—æ­£å¸¸æ ·æœ¬çš„ç‰¹å¾ä¸­å¿ƒ
    
    Args:
        feedback_samples: åé¦ˆæ ·æœ¬IDåˆ—è¡¨
        model: æ¨¡å‹
        device: è®¡ç®—è®¾å¤‡
    
    Returns:
        normal_center: æ­£å¸¸ç‰¹å¾ä¸­å¿ƒ
    """
    try:
        all_features = []
        
        for sample_id in feedback_samples:
            # åŠ è½½æ ·æœ¬æ•°æ®
            sample_data = load_sample_data(sample_id)
            
            if sample_data[0] is None:
                continue
            
            # å‡†å¤‡æ•°æ®
            X_test = prepare_single_sample(*sample_data)
            if X_test is None:
                continue
            
            # è·å–Transformerç‰¹å¾
            with torch.no_grad():
                # è·å–ä¸­é—´å±‚ç‰¹å¾ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                features = model.input_projection(X_test)
                all_features.append(features.mean(dim=(0, 1)).cpu())  # [d_model]
        
        if all_features:
            # è®¡ç®—ç‰¹å¾ä¸­å¿ƒ
            normal_center = torch.stack(all_features).mean(dim=0)
            return normal_center.to(device)
        else:
            return None
            
    except Exception as e:
        print(f"âŒ è®¡ç®—æ­£å¸¸ç‰¹å¾ä¸­å¿ƒå¤±è´¥: {e}")
        return None

def identify_false_positives(feedback_samples, model, device, threshold_factor=2.0):
    """
    è¯†åˆ«å‡é˜³æ€§æ ·æœ¬
    
    Args:
        feedback_samples: åé¦ˆæ ·æœ¬IDåˆ—è¡¨
        model: æ¨¡å‹
        device: è®¡ç®—è®¾å¤‡
        threshold_factor: é˜ˆå€¼å› å­
    
    Returns:
        false_positive_samples: å‡é˜³æ€§æ ·æœ¬åˆ—è¡¨
    """
    false_positive_samples = []
    
    try:
        for sample_id in feedback_samples:
            # åŠ è½½æ ·æœ¬æ•°æ®
            sample_data = load_sample_data(sample_id)
            
            if sample_data[0] is None:
                continue
            
            # å‡†å¤‡æ•°æ®
            X_test = prepare_single_sample(*sample_data)
            if X_test is None:
                continue
            
            # æ¨¡å‹é¢„æµ‹
            with torch.no_grad():
                predictions = model(X_test)
                pred_np = predictions.cpu().numpy()
            
            # è®¡ç®—è¯Šæ–­æŒ‡æ ‡
            fai_values = calculate_diagnosis_simple(pred_np, get_true_values(sample_id, 'normal'))
            
            # è®¡ç®—é˜ˆå€¼
            threshold = np.mean(fai_values) + threshold_factor * np.std(fai_values)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå‡é˜³æ€§
            if np.mean(fai_values) > threshold:
                false_positive_samples.append({
                    'sample_id': sample_id,
                    'fai_values': fai_values,
                    'threshold': threshold,
                    'data': sample_data
                })
        
        return false_positive_samples
        
    except Exception as e:
        print(f"âŒ è¯†åˆ«å‡é˜³æ€§æ ·æœ¬å¤±è´¥: {e}")
        return []

def feedback_loss(transformer_output, normal_center, false_positive_mask, alpha=0.1):
    """
    è®¡ç®—åå‘ä¼ æ’­æŸå¤±ï¼ˆä¿ç•™åŸæœ‰å‡½æ•°ï¼Œç”¨äºå…¼å®¹ï¼‰
    
    Args:
        transformer_output: Transformerè¾“å‡ºç‰¹å¾ [N, seq_len, d_model]
        normal_center: æ­£å¸¸æ ·æœ¬ç‰¹å¾ä¸­å¿ƒ [d_model]
        false_positive_mask: å‡é˜³æ€§æ©ç  [N]
        alpha: åé¦ˆæƒé‡
    """
    if not false_positive_mask.any():
        return torch.tensor(0.0, device=transformer_output.device, requires_grad=True)
    
    # è·å–å‡é˜³æ€§æ ·æœ¬çš„ç‰¹å¾
    fp_features = transformer_output[false_positive_mask]  # [num_fp, seq_len, d_model]
    
    # è®¡ç®—æ—¶åºç‰¹å¾çš„å¹³å‡å€¼
    fp_mean_features = fp_features.mean(dim=1)  # [num_fp, d_model]
    
    # è·ç¦»æŸå¤±ï¼šè®©å‡é˜³æ€§ç‰¹å¾æ›´æ¥è¿‘æ­£å¸¸ä¸­å¿ƒ
    distance_loss = torch.mean(torch.norm(fp_mean_features - normal_center, dim=1))
    
    # å¯¹æ¯”æŸå¤±ï¼šå¢åŠ å‡é˜³æ€§æ ·æœ¬ä¹‹é—´çš„åŒºåˆ†åº¦
    if len(fp_mean_features) > 1:
        pairwise_sim = torch.mm(fp_mean_features, fp_mean_features.t())
        contrastive_loss = torch.mean(pairwise_sim) - torch.mean(torch.diag(pairwise_sim))
    else:
        contrastive_loss = torch.tensor(0.0, device=transformer_output.device)
    
    return alpha * (distance_loss + 0.1 * contrastive_loss)

#=============================æ•°æ®åŠ è½½å‡½æ•°=============================

def load_sample_data(sample_id, data_type='QAS'):
    """åŠ è½½æ ·æœ¬æ•°æ®"""
    try:
        # æ ¹æ®å®é™…è·¯å¾„ç»“æ„ä¿®å¤
        if data_type == "QAS":
            data_path = f"../QAS/{sample_id}/"
        else:
            data_path = f"../project/data/{data_type}/{sample_id}/"
        
        # åŠ è½½æ•°æ®æ–‡ä»¶ - ä½¿ç”¨pickle.loadè€Œä¸æ˜¯pd.read_pickle
        import pickle
        
        with open(f"{data_path}vin_1.pkl", 'rb') as f:
            vin1_data = pickle.load(f)
        with open(f"{data_path}vin_2.pkl", 'rb') as f:
            vin2_data = pickle.load(f)
        with open(f"{data_path}vin_3.pkl", 'rb') as f:
            vin3_data = pickle.load(f)
        
        return vin1_data, vin2_data, vin3_data
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ ·æœ¬ {sample_id} å¤±è´¥: {e}")
        return None, None, None

def prepare_training_data_v2(sample_ids, device):
    """å‡†å¤‡è®­ç»ƒæ•°æ® - ä½¿ç”¨TransformerBatteryDatasetè¿›è¡Œæ‰¹æ¬¡å¤„ç†"""
    print(f"ğŸ“¥ ä½¿ç”¨TransformerBatteryDatasetåŠ è½½è®­ç»ƒæ•°æ®ï¼Œæ ·æœ¬èŒƒå›´: {sample_ids}")
    
    try:
        # å¯¼å…¥æ•°æ®åŠ è½½å™¨
        from data_loader_transformer import TransformerBatteryDataset
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = TransformerBatteryDataset(data_path='../QAS', sample_ids=sample_ids)
        
        if len(dataset) == 0:
            print("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•è®­ç»ƒæ•°æ®")
            return None
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(dataset)} ä¸ªè®­ç»ƒæ•°æ®å¯¹")
        
        # æ˜¾ç¤ºæ•°æ®æ ¼å¼
        sample_input, sample_target = dataset[0]
        print(f"ğŸ“Š æ•°æ®æ ¼å¼:")
        print(f"   è¾“å…¥ç»´åº¦: {sample_input.shape} (vin_1å‰5ç»´ + ç”µå‹ + SOC)")
        print(f"   ç›®æ ‡ç»´åº¦: {sample_target.shape} (ä¸‹ä¸€æ—¶åˆ»ç”µå‹ + SOC)")
        
        return dataset
        
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None

def create_sequences(X, y, seq_len):
    """åˆ›å»ºæ—¶åºåºåˆ—"""
    X_seq = []
    y_seq = []
    
    for i in range(len(X) - seq_len):
        X_seq.append(X[i:i+seq_len])
        y_seq.append(y[i+seq_len])
    
    return np.array(X_seq), np.array(y_seq)

#=============================è®­ç»ƒå‡½æ•°=============================

def train_transformer_with_hybrid_feedback(config, train_dataset, save_dir):
    """è®­ç»ƒTransformeræ¨¡å‹ï¼ˆå¸¦æ··åˆåé¦ˆç­–ç•¥ï¼‰- ä½¿ç”¨æ‰¹æ¬¡è®­ç»ƒ"""
    
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ {config['name']} æ¨¡å‹ï¼ˆæ··åˆåé¦ˆç­–ç•¥ï¼‰...")
    print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬: {FEEDBACK_CONFIG['train_samples']}")
    print(f"ğŸ”„ åé¦ˆæ ·æœ¬: {FEEDBACK_CONFIG['feedback_samples']}")
    
    # åˆ›å»ºDataLoader
    BATCH_SIZE = 4000  # æ‰¹æ¬¡å¤§å°4000
    from torch.utils.data import DataLoader
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, 
                             num_workers=4, pin_memory=True)
    print(f"ğŸ“¦ æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆï¼Œæ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    
    # åˆ›å»ºæ¨¡å‹
    model = TransformerPredictor(
        input_size=7,  # æ ¹æ®å®é™…ç‰¹å¾æ•°è°ƒæ•´
        d_model=config['d_model'],
        nhead=config['n_heads'],
        num_layers=config['n_layers'],
        d_ff=config['d_ff'],
        dropout=config['dropout'],
        output_size=2
    ).to(device)
    
    # å¯ç”¨æ•°æ®å¹¶è¡Œ
    if torch.cuda.device_count() > 1:
        model = torch.nn.DataParallel(model)
        print(f"âœ… å¯ç”¨æ•°æ®å¹¶è¡Œï¼Œä½¿ç”¨ {torch.cuda.device_count()} å¼ GPU")
    else:
        print("âš ï¸  å•GPUæ¨¡å¼")
    
    print(f"ğŸ§  Transformeræ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
    print(f"ğŸ“ˆ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.MSELoss()
    
    # è®¾ç½®æ··åˆç²¾åº¦è®­ç»ƒ
    from torch.cuda.amp import GradScaler, autocast
    scaler = GradScaler()
    print("âœ… å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ (AMP)")
    
    epochs = 40  # è®­ç»ƒè½®æ•°
    
    # è®­ç»ƒè®°å½•
    train_losses = []
    
    print(f"ğŸ”§ è®­ç»ƒå‚æ•°:")
    print(f"   - è®­ç»ƒè½®æ•°: {epochs}")
    print(f"   - æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    print(f"   - å­¦ä¹ ç‡: 0.001")
    print(f"   - æ··åˆç²¾åº¦è®­ç»ƒ: å¯ç”¨")
    
    # å¼€å§‹è®­ç»ƒ
    print("\n" + "="*60)
    print("ğŸ¯ å¼€å§‹Transformerè®­ç»ƒ")
    print("="*60)
    
    model.train()
    
    for epoch in range(epochs):
        epoch_loss = 0
        batch_count = 0
        
        for batch_input, batch_target in train_loader:
            # æ•°æ®ç§»åˆ°è®¾å¤‡
            batch_input = batch_input.to(device)
            batch_target = batch_target.to(device)
            
            # æ¢¯åº¦æ¸…é›¶
            optimizer.zero_grad()
            
            # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
            with autocast():
                pred_output = model(batch_input)
                loss = criterion(pred_output, batch_target)
            
            # æ··åˆç²¾åº¦åå‘ä¼ æ’­
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            epoch_loss += loss.item()
            batch_count += 1
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = epoch_loss / batch_count
        train_losses.append(avg_loss)
        
        # æ‰“å°è®­ç»ƒè¿›åº¦
        if epoch % 5 == 0 or epoch == epochs - 1:
            print(f'Epoch: {epoch:3d} | Loss: {avg_loss:.6f}')
    
    print("\nâœ… Transformerè®­ç»ƒå®Œæˆ!")
    
    # æœ€ç»ˆæŸå¤±
    final_loss = train_losses[-1]
    print(f"ğŸ¯ æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_loss:.6f}")
    
    # æŸå¤±æ”¹å–„
    if len(train_losses) > 1:
        initial_loss = train_losses[0]
        improvement = (initial_loss - final_loss) / initial_loss * 100
        print(f"ğŸ“ˆ æŸå¤±æ”¹å–„: {improvement:.2f}% (ä» {initial_loss:.6f} åˆ° {final_loss:.6f})")
    
    # ä¿å­˜æ¨¡å‹
    model_path = f"{save_dir}/transformer_model.pth"
    torch.save(model.state_dict(), model_path)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    # æ„å»ºå†å²è®°å½•
    history = {
        'train_losses': train_losses,
        'final_loss': final_loss,
        'config': config
    }
    
    # ä¿å­˜è®­ç»ƒå†å²
    with open(f"{save_dir}/training_history.pkl", 'wb') as f:
        pickle.dump(history, f)
    
    return model, history

#=============================åé¦ˆå‡½æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰=============================

# åé¦ˆåŠŸèƒ½ç¨åå®ç°

def execute_feedback_step(model, feedback_config, feedback_metrics, device, feedback_intensity=0.2):
    """
    æ‰§è¡Œåé¦ˆæ­¥éª¤ï¼ˆæ”¯æŒåé¦ˆå¼ºåº¦ï¼‰
    
    Args:
        model: å½“å‰æ¨¡å‹
        feedback_config: åé¦ˆé…ç½®
        feedback_metrics: åé¦ˆæŒ‡æ ‡
        device: è®¡ç®—è®¾å¤‡
        feedback_intensity: åé¦ˆå¼ºåº¦ (0-1)
    
    Returns:
        total_feedback_loss: æ€»åé¦ˆæŸå¤±
    """
    total_feedback_loss = 0.0
    
    try:
        # 1. è®¡ç®—æ­£å¸¸ç‰¹å¾ä¸­å¿ƒ
        normal_center = calculate_normal_feature_center(
            feedback_config['feedback_samples'], 
            model, 
            device
        )
        
        # 2. è¯†åˆ«å‡é˜³æ€§æ ·æœ¬
        false_positive_samples = identify_false_positives(
            feedback_config['feedback_samples'], 
            model, 
            device
        )
        
        if not false_positive_samples:
            print("   âœ… æ— å‡é˜³æ€§æ ·æœ¬ï¼Œè·³è¿‡åé¦ˆ")
            return 0.0
        
        print(f"   ğŸ¯ è¯†åˆ«åˆ° {len(false_positive_samples)} ä¸ªå‡é˜³æ€§æ ·æœ¬")
        
        # 3. MC-AEåé¦ˆï¼ˆä¸»è¦åé¦ˆï¼‰
        if normal_center is not None:
            # è·å–å½“å‰è®­ç»ƒæ•°æ®çš„ç‰¹å¾
            model.eval()
            with torch.no_grad():
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä½¿ç”¨MC-AEçš„é‡æ„è¯¯å·®
                # æš‚æ—¶ä½¿ç”¨Transformerç‰¹å¾ä½œä¸ºæ›¿ä»£
                sample_data = load_sample_data(feedback_config['feedback_samples'][0])
                if sample_data[0] is not None:
                    X_test = prepare_single_sample(*sample_data)
                    if X_test is not None:
                        features = model.input_projection(X_test)
                        
                        # è®¡ç®—MC-AEåé¦ˆæŸå¤±ï¼ˆåº”ç”¨åé¦ˆå¼ºåº¦ï¼‰
                        mcae_weight = feedback_config['mcae_feedback_weight'] * feedback_intensity
                        mcae_loss = mcae_feedback_loss(
                            features.mean(dim=1),  # ç®€åŒ–çš„é‡æ„è¯¯å·®
                            torch.randn(100, features.shape[-1]),  # æ¨¡æ‹Ÿæ­£å¸¸åˆ†å¸ƒ
                            mcae_weight
                        )
                        
                        total_feedback_loss += mcae_loss
                        print(f"   ğŸ”§ MC-AEåé¦ˆæŸå¤±: {mcae_loss.item():.6f} (å¼ºåº¦: {feedback_intensity:.1f})")
            
            model.train()
        
        # 4. Transformerç‰¹å¾åé¦ˆï¼ˆè¾…åŠ©åé¦ˆï¼‰
        if normal_center is not None and len(false_positive_samples) > 0:
            # è·å–å‡é˜³æ€§æ ·æœ¬çš„ç‰¹å¾
            fp_features = []
            for fp_sample in false_positive_samples:
                sample_data = fp_sample['data']
                X_test = prepare_single_sample(*sample_data)
                if X_test is not None:
                    with torch.no_grad():
                        features = model.input_projection(X_test)
                        fp_features.append(features.mean(dim=1))
            
            if fp_features:
                fp_features = torch.cat(fp_features, dim=0)
                
                # è®¡ç®—Transformerç‰¹å¾åé¦ˆæŸå¤±ï¼ˆåº”ç”¨åé¦ˆå¼ºåº¦ï¼‰
                transformer_weight = feedback_config['transformer_feedback_weight'] * feedback_intensity
                transformer_loss = transformer_feature_feedback(
                    fp_features,
                    normal_center,
                    transformer_weight
                )
                
                total_feedback_loss += transformer_loss
                print(f"   ğŸ”§ Transformeråé¦ˆæŸå¤±: {transformer_loss.item():.6f} (å¼ºåº¦: {feedback_intensity:.1f})")
        
        return total_feedback_loss
        
    except Exception as e:
        print(f"âŒ åé¦ˆæ­¥éª¤æ‰§è¡Œå¤±è´¥: {e}")
        return 0.0

def train_transformer_with_feedback(config, train_data, save_dir):
    """è®­ç»ƒTransformeræ¨¡å‹ï¼ˆå¸¦åå‘ä¼ æ’­æœºåˆ¶ï¼‰- ä¿ç•™åŸæœ‰å‡½æ•°ç”¨äºå…¼å®¹"""
    return train_transformer_with_hybrid_feedback(config, train_data, save_dir)

#=============================æµ‹è¯•å‡½æ•°=============================

def test_model_comprehensive(model, config, save_dir):
    """ç»¼åˆæµ‹è¯•æ¨¡å‹"""
    
    print(f"ğŸ”¬ å¼€å§‹æµ‹è¯• {config['name']} æ¨¡å‹...")
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_results = {}
    
    for sample_type, sample_ids in TEST_SAMPLES.items():
        for sample_id in sample_ids:
            print(f"  æµ‹è¯•æ ·æœ¬: {sample_type}_{sample_id}")
            
            # åŠ è½½æ•°æ®
            vin1_data, vin2_data, vin3_data = load_sample_data(sample_id)
            
            if vin1_data is None:
                continue
            
            # å‡†å¤‡æµ‹è¯•æ•°æ®ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
            X_test = prepare_single_sample(vin1_data, vin2_data, vin3_data)
            
            if X_test is None:
                continue
            
            # æ¨¡å‹é¢„æµ‹
            model.eval()
            with torch.no_grad():
                predictions = model(X_test)
                
            # è½¬æ¢ä¸ºnumpyè¿›è¡Œåç»­åˆ†æ
            pred_np = predictions.cpu().numpy()
            
            # è¿™é‡Œéœ€è¦çœŸå®å€¼è¿›è¡Œå¯¹æ¯”ï¼ˆæ ¹æ®å®é™…æƒ…å†µè·å–ï¼‰
            true_values = get_true_values(sample_id, sample_type)
            
            if true_values is not None:
                # è®¡ç®—ç»¼åˆè¯Šæ–­æŒ‡æ ‡
                fai_values = calculate_diagnosis_simple(pred_np, true_values)
                
                # ä¸‰çª—å£æ•…éšœæ£€æµ‹
                fault_labels, detection_info = three_window_detection(fai_values, sample_type)
                
                test_results[f"{sample_type}_{sample_id}"] = {
                    'predictions': pred_np,
                    'true_values': true_values,
                    'fai_values': fai_values,
                    'fault_labels': fault_labels,
                    'detection_info': detection_info
                }
    
    # è®¡ç®—ROCæ›²çº¿
    roc_results = calculate_roc_metrics(test_results)
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    with open(f"{save_dir}/test_results.pkl", 'wb') as f:
        pickle.dump(test_results, f)
    
    # ç”Ÿæˆå¯è§†åŒ–
    create_visualizations(test_results, roc_results, config, save_dir)
    
    return test_results, roc_results

def prepare_single_sample(vin1_data, vin2_data, vin3_data):
    """å‡†å¤‡å•ä¸ªæ ·æœ¬çš„æµ‹è¯•æ•°æ®"""
    try:
        # æ„å»ºç‰¹å¾çŸ©é˜µï¼ˆæ ¹æ®å®é™…æ•°æ®ç»“æ„è°ƒæ•´ï¼‰
        features = np.column_stack([
            vin1_data.iloc[:, 0],
            vin2_data.iloc[:, 0], 
            vin3_data.iloc[:, 0],
            # æ·»åŠ æ›´å¤šç‰¹å¾...
        ])
        
        # åˆ›å»ºæ—¶åºæ•°æ®
        seq_len = 50
        if len(features) < seq_len:
            return None
            
        X_seq = []
        for i in range(len(features) - seq_len):
            X_seq.append(features[i:i+seq_len])
        
        X_tensor = torch.FloatTensor(X_seq).to(device)
        return X_tensor
        
    except Exception as e:
        print(f"âŒ å‡†å¤‡æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
        return None

def get_true_values(sample_id, sample_type):
    """è·å–çœŸå®å€¼ï¼ˆæ ¹æ®å®é™…æƒ…å†µå®ç°ï¼‰"""
    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®è·å–çœŸå®çš„ç”µå‹å’ŒSOCå€¼
    # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®
    return np.random.rand(100, 2)  # æ¨¡æ‹Ÿ100ä¸ªæ—¶é—´æ­¥çš„2ç»´çœŸå®å€¼

def calculate_diagnosis_simple(predictions, true_values):
    """ç®€åŒ–çš„è¯Šæ–­æŒ‡æ ‡è®¡ç®—"""
    # è®¡ç®—é¢„æµ‹è¯¯å·®
    errors = np.abs(predictions - true_values)
    voltage_errors = errors[:, 0]
    soc_errors = errors[:, 1]
    
    # ç®€åŒ–çš„ç»¼åˆæŒ‡æ ‡
    fai_values = np.sqrt(voltage_errors**2 + soc_errors**2)
    
    return fai_values

def three_window_detection(fai_values, sample_type):
    """ä¸‰çª—å£æ•…éšœæ£€æµ‹"""
    
    # è®¡ç®—é˜ˆå€¼ï¼ˆåŸºäºæ•°æ®ç»Ÿè®¡ç‰¹æ€§ï¼‰
    threshold1 = np.mean(fai_values) + 3 * np.std(fai_values)
    
    detection_window = WINDOW_CONFIG["detection_window"]
    verification_window = WINDOW_CONFIG["verification_window"]
    marking_window = WINDOW_CONFIG["marking_window"]
    
    fault_labels = np.zeros(len(fai_values), dtype=int)
    detection_info = {
        'threshold1': threshold1,
        'candidate_points': [],
        'verified_points': [],
        'marked_regions': []
    }
    
    # é˜¶æ®µ1ï¼šæ£€æµ‹å€™é€‰æ•…éšœç‚¹
    candidate_points = np.where(fai_values > threshold1)[0]
    detection_info['candidate_points'] = candidate_points.tolist()
    
    # é˜¶æ®µ2ï¼šéªŒè¯æŒç»­æ€§
    verified_points = []
    for candidate in candidate_points:
        start_verify = max(0, candidate - verification_window//2)
        end_verify = min(len(fai_values), candidate + verification_window//2)
        verify_data = fai_values[start_verify:end_verify]
        
        # æŒç»­æ€§åˆ¤æ–­
        continuous_ratio = np.sum(verify_data > threshold1) / len(verify_data)
        if continuous_ratio > 0.3:  # 30%ä»¥ä¸Šè¶…é˜ˆå€¼è®¤ä¸ºæ˜¯çœŸå®æ•…éšœ
            verified_points.append(candidate)
    
    detection_info['verified_points'] = verified_points
    
    # é˜¶æ®µ3ï¼šæ ‡è®°æ•…éšœåŒºåŸŸ
    for verified_point in verified_points:
        start_mark = max(0, verified_point - marking_window)
        end_mark = min(len(fai_values), verified_point + marking_window)
        fault_labels[start_mark:end_mark] = 1
        detection_info['marked_regions'].append((start_mark, end_mark))
    
    return fault_labels, detection_info

def calculate_roc_metrics(test_results):
    """è®¡ç®—ROCæŒ‡æ ‡"""
    
    all_true_labels = []
    all_predictions = []
    
    for sample_key, results in test_results.items():
        sample_type = sample_key.split('_')[0]
        
        # çœŸå®æ ‡ç­¾ï¼šæ­£å¸¸=0ï¼Œæ•…éšœ=1
        true_label = 1 if sample_type == 'fault' else 0
        fault_labels = results['fault_labels']
        
        # æ ·æœ¬çº§åˆ«çš„é¢„æµ‹ï¼šæ˜¯å¦æ£€æµ‹åˆ°æ•…éšœ
        sample_prediction = 1 if np.any(fault_labels == 1) else 0
        
        all_true_labels.append(true_label)
        all_predictions.append(sample_prediction)
    
    # è®¡ç®—ROCæŒ‡æ ‡
    try:
        fpr, tpr, thresholds = roc_curve(all_true_labels, all_predictions)
        roc_auc = auc(fpr, tpr)
        
        return {
            'fpr': fpr,
            'tpr': tpr, 
            'thresholds': thresholds,
            'auc': roc_auc,
            'true_labels': all_true_labels,
            'predictions': all_predictions
        }
    except Exception as e:
        print(f"âŒ ROCè®¡ç®—å¤±è´¥: {e}")
        return None

def create_visualizations(test_results, roc_results, config, save_dir):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    
    # åˆ›å»ºå¯è§†åŒ–ç›®å½•
    viz_dir = f"{save_dir}/visualizations"
    os.makedirs(viz_dir, exist_ok=True)
    
    # 1. ROCæ›²çº¿
    if roc_results:
        plt.figure(figsize=(8, 6))
        plt.plot(roc_results['fpr'], roc_results['tpr'], 
                label=f"ROC (AUC = {roc_results['auc']:.3f})")
        plt.plot([0, 1], [0, 1], 'k--', label='éšæœºé¢„æµ‹' if use_chinese else 'Random')
        plt.xlabel('å‡é˜³ç‡ (FPR)' if use_chinese else 'False Positive Rate')
        plt.ylabel('çœŸé˜³ç‡ (TPR)' if use_chinese else 'True Positive Rate') 
        plt.title(f"{config['name']} - ROCæ›²çº¿" if use_chinese else f"{config['name']} - ROC Curve")
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.savefig(f"{viz_dir}/roc_curve.png", dpi=300, bbox_inches='tight')
        plt.close()
    
    # 2. æ•…éšœæ£€æµ‹ç»“æœ
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle(f"{config['name']} - æ•…éšœæ£€æµ‹ç»“æœ" if use_chinese else f"{config['name']} - Fault Detection Results")
    
    plot_idx = 0
    for sample_key, results in test_results.items():
        if plot_idx >= 4:
            break
            
        row, col = plot_idx // 2, plot_idx % 2
        ax = axes[row, col]
        
        # ç»˜åˆ¶FAIå€¼å’Œæ•…éšœæ ‡ç­¾
        fai_values = results['fai_values']
        fault_labels = results['fault_labels']
        threshold = results['detection_info']['threshold1']
        
        time_steps = np.arange(len(fai_values))
        
        ax.plot(time_steps, fai_values, 'b-', alpha=0.7, label='FAIå€¼' if use_chinese else 'FAI Values')
        ax.axhline(y=threshold, color='r', linestyle='--', label='é˜ˆå€¼' if use_chinese else 'Threshold')
        
        # æ ‡è®°æ•…éšœåŒºåŸŸ
        fault_indices = np.where(fault_labels == 1)[0]
        if len(fault_indices) > 0:
            ax.scatter(fault_indices, fai_values[fault_indices], 
                      color='red', s=20, alpha=0.8, label='æ•…éšœç‚¹' if use_chinese else 'Fault Points')
        
        ax.set_title(f"æ ·æœ¬ {sample_key}" if use_chinese else f"Sample {sample_key}")
        ax.set_xlabel('æ—¶é—´æ­¥' if use_chinese else 'Time Steps')
        ax.set_ylabel('FAIå€¼' if use_chinese else 'FAI Values')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plot_idx += 1
    
    plt.tight_layout()
    plt.savefig(f"{viz_dir}/fault_detection_results.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³: {viz_dir}")

#=============================ä¸»å‡½æ•°=============================

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    
    print("ğŸš€ å¼€å§‹é›†æˆè®­ç»ƒæµ‹è¯•å®éªŒï¼ˆæ··åˆåé¦ˆç­–ç•¥ï¼‰...")
    print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬: QAS {TRAIN_SAMPLES} (å…±{len(TRAIN_SAMPLES)}ä¸ª)")
    print(f"ğŸ”„ åé¦ˆæ ·æœ¬: QAS {FEEDBACK_SAMPLES} (å…±{len(FEEDBACK_SAMPLES)}ä¸ª)")
    print(f"ğŸ§ª æµ‹è¯•æ ·æœ¬: æ­£å¸¸ {TEST_SAMPLES['normal']}, æ•…éšœ {TEST_SAMPLES['fault']}")
    
    print(f"\nğŸ”§ æ··åˆåé¦ˆç­–ç•¥é…ç½®:")
    print(f"   - è®­ç»ƒæ ·æœ¬: {FEEDBACK_CONFIG['train_samples']}")
    print(f"   - åé¦ˆæ ·æœ¬: {FEEDBACK_CONFIG['feedback_samples']}")
    print(f"   - æœ€å°è®­ç»ƒepoch: {FEEDBACK_CONFIG['min_epochs_before_feedback']}")
    print(f"   - åŸºç¡€åé¦ˆé—´éš”: {FEEDBACK_CONFIG['base_feedback_interval']}")
    print(f"   - è‡ªé€‚åº”é˜ˆå€¼: {FEEDBACK_CONFIG['adaptive_threshold']}")
    print(f"   - MC-AEåé¦ˆæƒé‡: {FEEDBACK_CONFIG['mcae_feedback_weight']}")
    print(f"   - Transformeråé¦ˆæƒé‡: {FEEDBACK_CONFIG['transformer_feedback_weight']}")
    
    all_results = {}
    
    # æ‰§è¡Œä¸¤ä¸ªå®éªŒé…ç½®
    for config_name, config in EXPERIMENT_CONFIGS.items():
        print(f"\n{'='*80}")
        print(f"ğŸ”¬ å®éªŒé…ç½®: {config['name']}")
        print(f"{'='*80}")
        
        try:
            # åˆ›å»ºä¿å­˜ç›®å½•
            save_dir = f"modelsfl{config['save_suffix']}"
            os.makedirs(save_dir, exist_ok=True)
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰è®­ç»ƒç»“æœ
            model_path = f"{save_dir}/transformer_model.pth"
            if os.path.exists(model_path):
                print(f"ğŸ”„ å‘ç°å·²è®­ç»ƒæ¨¡å‹ï¼Œè·³è¿‡è®­ç»ƒé˜¶æ®µ")
                
                # åŠ è½½æ¨¡å‹
                model = TransformerPredictor(
                    input_size=7,
                    d_model=config['d_model'],
                    nhead=config['n_heads'],
                    num_layers=config['n_layers'],
                    d_ff=config['d_ff'],
                    dropout=config['dropout'],
                    output_size=2
                ).to(device)
                
                model.load_state_dict(torch.load(model_path, map_location=device))
                
                # åŠ è½½è®­ç»ƒå†å²
                try:
                    with open(f"{save_dir}/training_history.pkl", 'rb') as f:
                        history = pickle.load(f)
                except:
                    history = {'train_losses': [], 'feedback_losses': []}
                    
            else:
                # å‡†å¤‡è®­ç»ƒæ•°æ®
                print("ğŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®...")
                train_dataset = prepare_training_data_v2(TRAIN_SAMPLES, device)
                
                if train_dataset is None:
                    print(f"âŒ è®­ç»ƒæ•°æ®å‡†å¤‡å¤±è´¥ï¼Œè·³è¿‡ {config['name']}")
                    continue
                
                # è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨æ‰¹æ¬¡è®­ç»ƒï¼‰
                model, history = train_transformer_with_hybrid_feedback(config, train_dataset, save_dir)
            
            # æµ‹è¯•æ¨¡å‹
            test_results, roc_results = test_model_comprehensive(model, config, save_dir)
            
            # ä¿å­˜å®Œæ•´ç»“æœ
            experiment_result = {
                'config': config,
                'model': model,
                'history': history,
                'test_results': test_results,
                'roc_results': roc_results,
                'feedback_config': FEEDBACK_CONFIG
            }
            
            all_results[config_name] = experiment_result
            
            # æ‰“å°ç»“æœæ‘˜è¦
            if roc_results:
                print(f"âœ… {config['name']} å®Œæˆ")
                print(f"   ROC AUC: {roc_results['auc']:.4f}")
                print(f"   æ£€æµ‹åˆ°æ•…éšœæ ·æœ¬æ•°: {sum(roc_results['predictions'])}")
                
                # æ˜¾ç¤ºåé¦ˆç»Ÿè®¡
                if 'feedback_count' in history:
                    print(f"   æ€»åé¦ˆæ¬¡æ•°: {history['feedback_count']}")
                if 'feedback_metrics_history' in history and history['feedback_metrics_history']:
                    final_metrics = history['feedback_metrics_history'][-1]
                    if 'false_positive_rate' in final_metrics:
                        print(f"   æœ€ç»ˆå‡é˜³æ€§ç‡: {final_metrics['false_positive_rate']:.4f}")
            
        except Exception as e:
            print(f"âŒ å®éªŒ {config['name']} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # å¯¹æ¯”åˆ†æ
    if len(all_results) >= 2:
        print(f"\n{'='*80}")
        print("ğŸ“Š å®éªŒå¯¹æ¯”åˆ†æ")
        print(f"{'='*80}")
        
        for config_name, results in all_results.items():
            config = results['config']
            roc_results = results.get('roc_results')
            history = results.get('history', {})
            
            if roc_results:
                print(f"{config['name']}:")
                print(f"  - ROC AUC: {roc_results['auc']:.4f}")
                print(f"  - å‚æ•°é‡ä¼°è®¡: ~{estimate_parameters(config):.1f}M")
                print(f"  - æ£€æµ‹å‡†ç¡®ç‡: {calculate_accuracy(roc_results):.2f}%")
                
                # åé¦ˆç»Ÿè®¡
                if 'feedback_count' in history:
                    print(f"  - åé¦ˆæ¬¡æ•°: {history['feedback_count']}")
                if 'feedback_metrics_history' in history and history['feedback_metrics_history']:
                    final_metrics = history['feedback_metrics_history'][-1]
                    if 'false_positive_rate' in final_metrics:
                        print(f"  - æœ€ç»ˆå‡é˜³æ€§ç‡: {final_metrics['false_positive_rate']:.4f}")
    
    print(f"\nğŸ‰ æ‰€æœ‰å®éªŒå®Œæˆï¼ç»“æœä¿å­˜åœ¨ modelsfl_* ç›®å½•ä¸­")
    print(f"\nğŸ“‹ å®éªŒæ€»ç»“:")
    print(f"   - ä½¿ç”¨äº†æ··åˆåé¦ˆç­–ç•¥")
    print(f"   - è®­ç»ƒæ ·æœ¬ä¸åé¦ˆæ ·æœ¬åˆ†ç¦»")
    print(f"   - è‡ªé€‚åº”åé¦ˆè§¦å‘æœºåˆ¶")
    print(f"   - åˆ†å±‚åé¦ˆï¼ˆMC-AE + Transformerï¼‰")

def estimate_parameters(config):
    """ä¼°è®¡æ¨¡å‹å‚æ•°é‡ï¼ˆç™¾ä¸‡ï¼‰"""
    d_model = config['d_model']
    d_ff = config['d_ff']
    n_layers = config['n_layers']
    n_heads = config['n_heads']
    
    # ç²—ç•¥ä¼°è®¡
    embed_params = 7 * d_model  # è¾“å…¥æŠ•å½±
    attention_params = n_layers * (4 * d_model * d_model + d_model * n_heads)  # æ³¨æ„åŠ›å±‚
    ff_params = n_layers * (2 * d_model * d_ff)  # å‰é¦ˆå±‚
    output_params = d_model * 2  # è¾“å‡ºå±‚
    
    total_params = embed_params + attention_params + ff_params + output_params
    return total_params / 1e6

def calculate_accuracy(roc_results):
    """è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡"""
    true_labels = roc_results['true_labels']
    predictions = roc_results['predictions']
    
    correct = sum(t == p for t, p in zip(true_labels, predictions))
    accuracy = correct / len(true_labels) * 100
    
    return accuracy

if __name__ == "__main__":
    main()