"""
Transformerшонч╗ГцХ░цНохКаш╜╜хЩи
хКаш╜╜vin_1хТМtargets.pklцЮДх╗║шонч╗ГцХ░цНохп╣
"""

import pickle
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader

class TransformerBatteryDataset(Dataset):
    """TransformerчФ╡ц▒ацХ░цНощЫЖ"""
    
    def __init__(self, data_path='./data/QAS', sample_ids=None):
        self.data_path = data_path
        self.training_pairs = []
        
        if sample_ids is None:
            # хжВцЮЬц▓бцЬЙцМЗхоЪца╖цЬмя╝Мф╜┐чФи0-20ф╜Ьф╕║щ╗Шшодшонч╗ГщЫЖ
            sample_ids = list(range(21))
        
        # хКаш╜╜цЙАцЬЙшонч╗ГцХ░цНохп╣
        for sample_id in sample_ids:
            pairs = self.load_sample_pairs(sample_id)
            if pairs:
                self.training_pairs.extend(pairs)
        
        print(f"ЁЯУК хКаш╜╜хоМцИР: {len(self.training_pairs)} ф╕кшонч╗ГцХ░цНохп╣")
    
    def load_sample_pairs(self, sample_id):
        """хКаш╜╜хНХф╕кца╖цЬмчЪДшонч╗ГцХ░цНохп╣"""
        try:
            # хКаш╜╜vin_1хТМtargets
            with open(f'{self.data_path}/{sample_id}/vin_1.pkl', 'rb') as f:
                vin_1 = pickle.load(f)
            with open(f'{self.data_path}/{sample_id}/targets.pkl', 'rb') as f:
                targets = pickle.load(f)
            
            # ш╜мцНвф╕║numpyцХ░ч╗Д
            if isinstance(vin_1, torch.Tensor):
                vin_1 = vin_1.cpu().numpy()
            
            pairs = []
            
            # цЮДх╗║шонч╗ГцХ░цНохп╣ (kцЧ╢хИ╗ш╛УхЕе -> k+1цЧ╢хИ╗чЫоцаЗ)
            for k in range(len(vin_1) - 1):
                # ш╛УхЕея╝ЪkцЧ╢хИ╗чЪД7ч╗┤чК╢цАБ
                input_7d = [
                    vin_1[k, 0, 0],  # хОЯхзЛч╗┤х║ж0-4
                    vin_1[k, 0, 1],
                    vin_1[k, 0, 2],
                    vin_1[k, 0, 3],
                    vin_1[k, 0, 4],
                    targets['terminal_voltages'][k],  # kцЧ╢хИ╗чФ╡хОЛчЬЯхоЮхА╝
                    targets['pack_socs'][k]           # kцЧ╢хИ╗SOCчЬЯхоЮхА╝
                ]
                
                # чЫоцаЗя╝Ъk+1цЧ╢хИ╗чЪД2ч╗┤щвДц╡Л
                target_2d = [
                    targets['terminal_voltages'][k+1],  # k+1цЧ╢хИ╗чФ╡хОЛчЬЯхоЮхА╝
                    targets['pack_socs'][k+1]           # k+1цЧ╢хИ╗SOCчЬЯхоЮхА╝
                ]
                
                pairs.append((input_7d, target_2d))
            
            return pairs
            
        except Exception as e:
            print(f"тЭМ хКаш╜╜ца╖цЬм {sample_id} хд▒ш┤е: {e}")
            return []
    
    def __len__(self):
        return len(self.training_pairs)
    
    def __getitem__(self, idx):
        input_data, target_data = self.training_pairs[idx]
        return torch.tensor(input_data, dtype=torch.float32), torch.tensor(target_data, dtype=torch.float32)

def create_transformer_dataloader(data_path='./data/QAS', sample_ids=None, batch_size=32, shuffle=True):
    """хИЫх╗║Transformerшонч╗ГцХ░цНохКаш╜╜хЩи"""
    dataset = TransformerBatteryDataset(data_path, sample_ids)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)
    return dataloader

# ф╛┐цН╖хЗ╜цХ░
def load_transformer_data(sample_id, data_path='./data/QAS'):
    """хКаш╜╜хНХф╕кца╖цЬмчЪДTransformerшонч╗ГцХ░цНо"""
    try:
        with open(f'{data_path}/{sample_id}/vin_1.pkl', 'rb') as f:
            vin_1 = pickle.load(f)
        with open(f'{data_path}/{sample_id}/targets.pkl', 'rb') as f:
            targets = pickle.load(f)
        return vin_1, targets
    except Exception as e:
        print(f"тЭМ хКаш╜╜ца╖цЬм {sample_id} хд▒ш┤е: {e}")
        return None, None

if __name__ == "__main__":
    # ц╡ЛшпХцХ░цНохКаш╜╜хЩи
    print("ЁЯзк ц╡ЛшпХTransformerцХ░цНохКаш╜╜хЩи...")
    
    # хИЫх╗║цХ░цНохКаш╜╜хЩия╝Иф╜┐чФица╖цЬм0-2ш┐ЫшбМц╡ЛшпХя╝Й
    dataloader = create_transformer_dataloader(sample_ids=[0, 1, 2], batch_size=4)
    
    # ц╡ЛшпХф╕Аф╕кbatch
    for batch_idx, (inputs, targets) in enumerate(dataloader):
        print(f"Batch {batch_idx}:")
        print(f"  ш╛УхЕех╜вчК╢: {inputs.shape}")  # [batch_size, 7]
        print(f"  чЫоцаЗх╜вчК╢: {targets.shape}")  # [batch_size, 2]
        print(f"  ш╛УхЕеца╖ф╛Л: {inputs[0]}")
        print(f"  чЫоцаЗца╖ф╛Л: {targets[0]}")
        
        if batch_idx >= 2:  # хПкцШ╛чд║хЙН3ф╕кbatch
            break
    
    print(f"\nтЬЕ цХ░цНохКаш╜╜хЩиц╡ЛшпХхоМцИР!") 